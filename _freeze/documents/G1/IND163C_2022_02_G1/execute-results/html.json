{
  "hash": "d0e02b1770dc6cc46e342e2f13b18e94",
  "result": {
    "markdown": "---\ntitle: \"Ejemplo resulto - Certamen #1\"\nrunningheader: \"Certamen #1\" # only for pdf output\nauthor: \"Eloy Alvarado Narváez\"\ndate: \"2022-09-22\"\noutput:\n  tufte::tufte_handout:\n    citation_package: natbib\n    latex_engine: xelatex\n  tufte::tufte_html: default\n  tufte::tufte_book:\n    citation_package: natbib\n    latex_engine: xelatex\nbibliography: skeleton.bib\nlink-citations: yes\n---\n\n\n\\renewcommand{\\figurename}{Fig.}\n\n\n\n\n\n# Introducción\n\nEn lo que sigue, se desarrolla en detalle una pregunta tipo certamen #1, con el fin de entregarles una idea de cómo será la primera evaluación. Se desarrolló en `R` sin embargo, todo lo expuesto puede ser realizado en `Python` análogamente. Adicionalmente al tipo de preguntas como la desarollada en este documento, preguntas teóricas y conceptuales podrán también ser incorporadas.\n\n# Pregunta tipo prueba\n\n<span class=\"newthought\">Publicidad</span> El conjunto de datos `Advertising` consiste en las ventas (`sales`) en miles de unidades de un producto en 200 mercados diferentes, junto con los presupuestos en dólares de publicidad en cada uno de estos mercados para tres medios diferentes: televisión (`TV`), `radio` y periódicos (`newspaper`).\n\n1. Realice un análisis exploratorio del conjunto de datos `Advertising`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse) \nlibrary(modelr)\nlibrary(broom)\nlibrary(readr)\nAdvertising <- read_csv(\"Advertising.csv\") %>% select(-X1)\n```\n:::\n\n<label for=\"tufte-mn-\" class=\"margin-toggle\">&#8853;</label><input type=\"checkbox\" id=\"tufte-mn-\" class=\"margin-toggle\"><span class=\"marginnote\">Cargamos algunos paquetes que serán útiles para el análisis, luego leémos el conjunto de datos y descartamos la primera columna (por ser una columna que no nos entrega información). Adicionalmente, imprimimos parte de los datos para verificar que están siendo correctamente ingresados.</span>\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(Advertising)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 x 4\n     TV radio newspaper sales\n  <dbl> <dbl>     <dbl> <dbl>\n1 230.   37.8      69.2  22.1\n2  44.5  39.3      45.1  10.4\n3  17.2  45.9      69.3   9.3\n4 152.   41.3      58.5  18.5\n5 181.   10.8      58.4  12.9\n6   8.7  48.9      75     7.2\n```\n:::\n:::\n\n\nPara realizar el análisis exploratorio de datos (**EDA** por sus siglas en inglés), existen varias formas de abarcar el problema. Una manera sencilla aunque **sólo preliminar** para realizar un **EDA** sistemático a un conjunto de datos, es usar el paquete `DataExplorer`\n\n\n::: {.cell fig.fullwidth='true'}\n\n```{.r .cell-code}\nlibrary(DataExplorer)\nplot_intro(Advertising)\n```\n\n::: {.cell-output-display}\n![Exploración del tipo de variables y datos faltantes](IND163C_2022_02_G1_files/figure-html/unnamed-chunk-6-1.png){width=960}\n:::\n:::\n\n\nLa función `plot_intro()` nos entrega el tipo de variables en las columnas y el porcentaje de datos faltantes. Alternativamente, se puede obtener la misma información en formato de tabla usando `introduce()`. \n\nEn el caso que existan datos faltantes a lo largo del conjunto de datos en distintas variables, es posible obtener el detalle del porcentaje de estos utilizando la función `plot_missing()`. El paquete `DataExplorer` entrega además **sugerencias** sobre la calidad de las variables conforme el nivel de datos faltantes presentes, sin embargo, la eliminación de columnas debe ser estudiada cuidadosamente y siempre dependerá del contexto del problema.\n\nEn el caso de que existan datos discretos, es posible visualizar la distribución de frecuencias para todas estas variables utilizando la función `plot_bar()`. De manera similar, es posible obtener los histogramas para las variables continuas utilizando la función `plot_histogram()`:\n\n\n::: {.cell fig.fullwidth='true'}\n\n```{.r .cell-code}\nplot_histogram(Advertising)\n```\n\n::: {.cell-output-display}\n![Histograma para las variables continuas](IND163C_2022_02_G1_files/figure-html/unnamed-chunk-8-1.png){width=960}\n:::\n\n```{.r .cell-code}\nplot_density(Advertising)\n```\n\n::: {.cell-output-display}\n![Histograma para las variables continuas](IND163C_2022_02_G1_files/figure-html/unnamed-chunk-8-2.png){width=960}\n:::\n:::\n\n\nLa primera función nos entrega los histogramas hechos sistemáticamente usando el paquete `ggplot2`, mientras que el segundo realiza una [**estimación de densidad por kernel**](https://en.wikipedia.org/wiki/Kernel_density_estimation), que vendría siendo *algo así* como una versión suavizada del histograma. Esta técnica tomará relevancia **más adelante** en el curso.\n\nPara comparar **visualmente** la distribución de las variables en estudio con distribuciones teóricas conocidas, es posible utilizar [**QQ-plot**](https://es.wikipedia.org/wiki/Gr%C3%A1fico_Q-Q) mediante la función `plot_qq()`.\n\n\n::: {.cell fig.fullwidth='true'}\n\n```{.r .cell-code}\nplot_qq(Advertising)\n```\n\n::: {.cell-output-display}\n![QQ plot de las variables](IND163C_2022_02_G1_files/figure-html/unnamed-chunk-10-1.png){width=960}\n:::\n:::\n\n\nPor defecto, el comando `plot_qq()` compara con una distribución normal, por lo que es una buena **herramienta visual** para el análisis de residuos bajo un modelo lineal. Adicionalmente, es posible agrupar las variables continuas graficadas por factores o variables categóricas mediante el argumento `plot_qq(... , by=\"\")`.\n\n\n\nPara realizar un análisis correlacional de las variables en estudio, es posible utilizar la función `plot_correlation()`\n\n\n\n::: {.cell fig.fullwidth='true'}\n\n```{.r .cell-code}\nplot_correlation(Advertising)\n```\n\n::: {.cell-output-display}\n![Análisis correlacional](IND163C_2022_02_G1_files/figure-html/unnamed-chunk-12-1.png){width=960}\n:::\n:::\n\n\n\nPara realizar un **análisis de componentes principales** (que veremos más adelante en detalle) se puede utilizar la función `plot_prcomp()`. Omitiremos estos gráficos por el momento.\n\n<label for=\"tufte-mn-\" class=\"margin-toggle\">&#8853;</label><input type=\"checkbox\" id=\"tufte-mn-\" class=\"margin-toggle\"><span class=\"marginnote\">Hay que ser particularmente cuidadoso en la interpretación de este análisis, pues se debe tener claro que tipo de correlación se está calculando (y graficando). Este comando utiliza la función cor(). Es posible, realizar este análisis para los dos tipos de variables: discretos y continuos. Se recomienda tratar los datos faltantes antes de realizar este proceso.</span>\n\nComo recordarán de cursos anteriores, uno de los mejores gráficos disponibles es el **boxplot** que puede ser calculado fácilmente utilizando la función `plot_boxplot(..., by=\"\")` si deseamos agrupar por alguna variable **categórica**. Para ver cada uno de manera **univariada** usamos la siguiente función.\n\n\n::: {.cell}\n\n```{.r .cell-code}\np <- ggplot(Advertising, aes(TV)) + geom_boxplot()\np \n```\n\n::: {.cell-output-display}\n![](IND163C_2022_02_G1_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n:::\n\n\n<label for=\"tufte-mn-\" class=\"margin-toggle\">&#8853;</label><input type=\"checkbox\" id=\"tufte-mn-\" class=\"margin-toggle\"><span class=\"marginnote\">Este tipo de gráficos toma más relevancia cuando podemos analizar una misma variable agrupada por una categórica, como veremos más adelante.</span>\n\nTambién es posible obtener los **gráficos de dispersión** de cada una de las variables en estudio mediante la función `plot_scatterplot(... ,by=\"\")` agrupada por una variable categórica. \n\nFinalmente, cabe mencionar que los estadísticos descriptivos (media, varianza, cuartiles, etc) también son parte del **EDA**. Todo el proceso anterior puede ser en su totalidad automatizado con el comando `create_report()`, este creo un archivo `.html` con las funciones que *puede* hacer con el conjunto de datos, sin embargo, hay que tomar atención a lo que hace en cada uno de los pasos pues es sólo un proceso sistematizado con parámetros por defecto. Se recomienda realizar cada paso por separado.\n\nEn este ejemplo introductorio, al no tener datos faltantes y categóricos, el **EDA** es bastante sencillo y se reduce a la creación de gráficos básicos y estadística descriptiva.\n\n2. Realice un ajuste lineal simple para las ventas (`sales`) medidas en miles de unidades vs cada uno de los tres medios utilizados. Explicite los ajustes realizados.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\np1<- ggplot(data = Advertising, mapping = aes(x = TV, y = sales)) + \n  geom_point() + geom_smooth(method = \"lm\", se = FALSE)\np2<- ggplot(data = Advertising, mapping = aes(x = radio, y = sales)) + \n  geom_point() + geom_smooth(method = \"lm\", se = FALSE)\np3<- ggplot(data = Advertising, mapping = aes(x = newspaper, y = sales)) + \n  geom_point() + geom_smooth(method = \"lm\", se = FALSE)\n```\n:::\n\n\nLa creación de gráficos utilizando `ggplot2` funciona de manera modular, primero se establece el conjunto de datos a utilizar, y se especifica que variables serán los ejes (`ggplot()`). Luego, se grafican los puntos (`geom_point()`) y finalmente la recta `geom_smooth()`, respectivamente.\n\n\n::: {.cell fig.fullwidth='true'}\n\n```{.r .cell-code}\nlibrary(gridExtra)\ngrid.arrange(p1, p2, p3, nrow = 1)\n```\n\n::: {.cell-output-display}\n![Ajuste lineal simple para las ventas en función de los tres medios utilizados](IND163C_2022_02_G1_files/figure-html/modelos-1.png){width=960}\n:::\n:::\n\n\nLos modelos de regresión ajustados tienen la forma:\n\n\n$$Y=\\beta_0+\\beta_1 X +\\epsilon$$\n\n\ndonde:\n\n- $Y$ representa las ventas en miles de unidades\n- $X$ representa el presupuesto en cada uno de los medios, respectivamente.\n- $\\beta_0$ es el intercepto\n- $\\beta_1$ es la pendiente, que representa la relación lineal\n- $\\epsilon$ es el término de error aleatorio con media cero.\n\nPara analizar el detalle de nuestro ajusto lineal, guardamos los modelos lineales en tres objetivos distintos:\n\n<label for=\"tufte-mn-\" class=\"margin-toggle\">&#8853;</label><input type=\"checkbox\" id=\"tufte-mn-\" class=\"margin-toggle\"><span class=\"marginnote\">El comando lm viene de linear models y existen versiones más generales y específicas dentro de R</span>\n\n::: {.cell}\n\n```{.r .cell-code}\nmodelo_1<-lm(sales ~ TV, data=Advertising)\nmodelo_2<-lm(sales ~ radio, data=Advertising)\nmodelo_3<-lm(sales ~ newspaper, data=Advertising)\n```\n:::\n\n\nLa función `lm()` utiliza por defecto el método de **mínimos cuadrados** para estimar los coeficientes de regresión, pero es posible definir otras metodologías utilizando la función `glm()`.\n\nLos ajustos especificos obtenidos (con sus estimaciones de los parámetros) los podemos obtener simplemente haciendo un `summary()` a los modelos calculados.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Sales vs TV \nsummary(modelo_1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = sales ~ TV, data = Advertising)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-8.3860 -1.9545 -0.1913  2.0671  7.2124 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 7.032594   0.457843   15.36   <2e-16 ***\nTV          0.047537   0.002691   17.67   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.259 on 198 degrees of freedom\nMultiple R-squared:  0.6119,\tAdjusted R-squared:  0.6099 \nF-statistic: 312.1 on 1 and 198 DF,  p-value: < 2.2e-16\n```\n:::\n\n```{.r .cell-code}\n# Sales vs radio\nsummary(modelo_2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = sales ~ radio, data = Advertising)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-15.7305  -2.1324   0.7707   2.7775   8.1810 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  9.31164    0.56290  16.542   <2e-16 ***\nradio        0.20250    0.02041   9.921   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.275 on 198 degrees of freedom\nMultiple R-squared:  0.332,\tAdjusted R-squared:  0.3287 \nF-statistic: 98.42 on 1 and 198 DF,  p-value: < 2.2e-16\n```\n:::\n\n```{.r .cell-code}\n# Sales vs newspaper\nsummary(modelo_3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = sales ~ newspaper, data = Advertising)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-11.2272  -3.3873  -0.8392   3.5059  12.7751 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 12.35141    0.62142   19.88  < 2e-16 ***\nnewspaper    0.05469    0.01658    3.30  0.00115 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.092 on 198 degrees of freedom\nMultiple R-squared:  0.05212,\tAdjusted R-squared:  0.04733 \nF-statistic: 10.89 on 1 and 198 DF,  p-value: 0.001148\n```\n:::\n:::\n\n\n3. ¿Qué modelo ajustado es mejor? Comente e interprete los resultados de este modelo.\n\nEs claro notar que el modelo que mejor se ajusta es el primero, las ventas (`sales`) vs `TV`, lo cual era esperable desde la figura exploratoria. El modelo ajustado corresponde a:\n\n\n$$Y=7.032594+0.047537 X + \\epsilon$$\n\n\nEn otras palabras, nuestra estimación del intercepto es 7.032594, por lo que cuando el presupuesto para el medio televisivo es cero, esperaremos ventas de 7032 unidades, y por cada $1000 dólares adicionales en el presupuesto esperaremos un incremento **promedio** en las ventas de 47 unidades. Además, es claro notar que ambos coeficientes son** estadísticamente significativos**, y podemos calcular sus intervalos de confianza como:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nconfint(modelo_1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                 2.5 %     97.5 %\n(Intercept) 6.12971927 7.93546783\nTV          0.04223072 0.05284256\n```\n:::\n:::\n\n\nDebido a que el cero no está incluido en el intervalo de confianza para el coeficiente de pendiente, podemos concluir que por cada $1000 dólares adicionales de presupuesto en el medio televisivo, esperaremos un incremento **promedio** en las ventas entre 42 y 52 unidades.\n\nPara justificar en detalle, podemos el R^2 del `modelo_1` es el mayor entre los realizados, y podemos realizar una tabla anova para verificar que mediante el test F, los coeficientes **no son nulos**:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nanova(modelo_1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Variance Table\n\nResponse: sales\n           Df Sum Sq Mean Sq F value    Pr(>F)    \nTV          1 3314.6  3314.6  312.14 < 2.2e-16 ***\nResiduals 198 2102.5    10.6                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n\nPor lo que, **de ser viable nuestro modelo realizado**, esto es, que cumpla con los supuestos de una regresión lineal, sería el modelo más adecuado entre los realizados. Para ello, primero visualizamos -nuevamente-:\n\n\n::: {.cell fig.fullwidth='true'}\n\n```{.r .cell-code}\nggplot(Advertising, aes(TV, sales)) +\n  geom_point() +\n  geom_smooth(method = \"lm\") +\n  geom_smooth(se = FALSE, color = \"red\")\n```\n\n::: {.cell-output-display}\n![Ajuste lineal simple para ventas vs TV](IND163C_2022_02_G1_files/figure-html/unnamed-chunk-26-1.png){width=960}\n:::\n:::\n\n\nPara ver el análisis de residuos, es posible utilizar el comando `plot(modelo_1)` el cual entregará 4 gráficos en formato básico. En lo que sigue, los creamos uno por uno utilizando el paquete `ggplot2`.\n\n\n::: {.cell fig.fullwidth='true'}\n\n```{.r .cell-code}\nggplot(modelo_1, aes(.fitted, .resid)) +\n  geom_ref_line(h = 0) +\n  geom_point() +\n  geom_smooth(se = FALSE) +\n  ggtitle(\"Residuos vs Ajuste\")\n```\n\n::: {.cell-output-display}\n![Gráfico de residuos vs ajuste](IND163C_2022_02_G1_files/figure-html/unnamed-chunk-28-1.png){width=960}\n:::\n:::\n\n\nUna forma de visualizar más claramente los residuos, es estandarizándolos y reescalándolos, respectivamente.\n\n\n::: {.cell fig.fullwidth='true'}\n\n```{.r .cell-code}\nmodelo_1_res <- augment(modelo_1, Advertising)\np4 <- ggplot(modelo_1_res, aes(.fitted, .std.resid)) +\n  geom_ref_line(h = 0) +\n  geom_point() +\n  geom_smooth(se = FALSE) +\n  ggtitle(\"Residuos Estadarizados vs Ajuste\")\n\np5 <- ggplot(modelo_1_res, aes(.fitted, sqrt(.std.resid))) +\n  geom_ref_line(h = 0) +\n  geom_point() +\n  geom_smooth(se = FALSE) +\n  ggtitle(\"Reescalamiento\")\n\ngridExtra::grid.arrange(p4, p5, nrow = 1)\n```\n\n::: {.cell-output-display}\n![Gráfico de residuos estandarizados y reescalados vs ajuste](IND163C_2022_02_G1_files/figure-html/unnamed-chunk-30-1.png){width=960}\n:::\n:::\n\n\nEn el primer gráfico podemos identificar fácilmente cuando un residuo se desvía por varias desviaciones estándar, en donde usualmente estamos en busca de los residuos que difieren por más de 3 desviaciones estándar. El segundo gráfico muestra si los residuos están dispersos equitativamente a lo largo del rango de los predictores. Luego, como hemos asumido normalidad en los errores, debemos realizar un **QQ plot**\n\n\n::: {.cell fig.fullwidth='true'}\n\n```{.r .cell-code}\nqq_plot <- qqnorm(modelo_1_res$.resid)\nqq_plot <- qqline(modelo_1_res$.resid)\n```\n\n::: {.cell-output-display}\n![QQ plot de los residuos](IND163C_2022_02_G1_files/figure-html/unnamed-chunk-32-1.png){width=960}\n:::\n:::\n\nComo lo cuantiles esperados se asemejan a los teóricos, podemos asumir normalidad. \n\nSiguiendo, si deseamos encontrar datos u observaciones anómales podemos calculos las distancias de cook de las observaciones y graficar los apalancamientos.\n\n\n::: {.cell fig.fullwidth='true'}\n\n```{.r .cell-code}\npar(mfrow=c(1, 2))\n\nplot(modelo_1, which = 4, id.n = 5)\nplot(modelo_1, which = 5, id.n = 5)\n```\n\n::: {.cell-output-display}\n![Distancias de Cook y apalancamientos](IND163C_2022_02_G1_files/figure-html/unnamed-chunk-34-1.png){width=960}\n:::\n:::\n\n\nEn el gráfico anterior, buscamos las observaciones que tienen mayor distancia de cook, y estas serán sospechosas de ser **outliers**, siendo esta sospecha reforzada si su apalancamiento está muy a la derecha en el gráfico respectivo. Para extraer las n observaciones con mayor distancia de cook, podemos escribir:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodelo_1_res %>%\n  top_n(3, wt = .cooksd)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 3 x 10\n     TV radio newspaper sales .fitted .resid   .hat .sigma .cooksd .std.resid\n  <dbl> <dbl>     <dbl> <dbl>   <dbl>  <dbl>  <dbl>  <dbl>   <dbl>      <dbl>\n1  263.   3.5      19.5  12      19.5  -7.53 0.0142   3.22  0.0389      -2.33\n2  291.   4.1       8.5  12.8    20.9  -8.05 0.0191   3.22  0.0605      -2.49\n3  277.   2.3      23.7  11.8    20.2  -8.39 0.0165   3.21  0.0563      -2.59\n```\n:::\n:::\n\n\nConforme lo anterior, se cumplen todos los supuestos del modelo de regresión lineal simple, por lo que la regresión ajustada es la mejor entre las realizadas.\n\n4. Ajustar mediante un ajuste de regresión múltiple las ventas en miles de unidades (`sales`), sin incorporar interacciones. Interprete los resultados.\n\nDe manera similar, podemos realizar un ajuste de regresión múltiple utilizando los presupuestos en los distintos medios de manera conjunta:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodelo_4<-lm(sales ~ TV + radio + newspaper, data= Advertising)\nsummary(modelo_4)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = sales ~ TV + radio + newspaper, data = Advertising)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-8.8277 -0.8908  0.2418  1.1893  2.8292 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  2.938889   0.311908   9.422   <2e-16 ***\nTV           0.045765   0.001395  32.809   <2e-16 ***\nradio        0.188530   0.008611  21.893   <2e-16 ***\nnewspaper   -0.001037   0.005871  -0.177     0.86    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.686 on 196 degrees of freedom\nMultiple R-squared:  0.8972,\tAdjusted R-squared:  0.8956 \nF-statistic: 570.3 on 3 and 196 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n\nLa interpretación de los coeficientes de regresión es similar a caso de la regresión simple. Primero, notamos que los coeficientes asociados a los presupuestos en televisión y radio son significativos bajo un test de hipótesis t (p-valor $< 0.05$), mientras que el coeficiente asociado al presupuesto en periódicos no lo es. Por lo que, bajo un modelo de regresión múltiple, cambios en el presupuesto en periódicos no pareciera tener una relación con los cambios en las ventas. Sin embargo, en el caso del presupuesto televisivo, si este aumenta en $1000 dólares y **se mantienen los otros predictores constantes**, esperaríamos un incremento de 45 unidades en las ventas, en promedio. Análogamente, para un aumento de igual monto en el presupuesto radial, se esperaría un aumento de 188 unidades en promedio.\n\n5. Investigue la viabilidad del modelo de regresión múltiple y compare los resultados con el mejor modelo de regresión lineal simple.  Obtenga intervalos de confianza para los parámetros de la regresión.\n\nDe manera similar al caso de regresión lineal simple, podemos calcular intervalos de confianza para los parámetros de regresión como:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nconfint(modelo_4)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                  2.5 %     97.5 %\n(Intercept)  2.32376228 3.55401646\nTV           0.04301371 0.04851558\nradio        0.17154745 0.20551259\nnewspaper   -0.01261595 0.01054097\n```\n:::\n:::\n\n\nLuego, podemos hacemos un análisis de residuos:\n\n\n::: {.cell fig.fullwidth='true'}\n\n```{.r .cell-code}\nmodelo_1_res <- modelo_1_res %>%\n  mutate(Model = \"Modelo de regresión lineal simple\")\n\nmodelo_4_res <- augment(modelo_4, Advertising) %>%\n  mutate(Model = \"Modelo de regresión lineal múltiple\") %>%\n  rbind(modelo_1_res)\n\nggplot(modelo_4_res, aes(.fitted, .resid)) +\n  geom_ref_line(h = 0) +\n  geom_point() +\n  geom_smooth(se = FALSE) +\n  facet_wrap(~ Model) +\n  ggtitle(\"Residuos vs Ajuste\")\n```\n\n::: {.cell-output-display}\n![Distancias de Cook y apalancamientos](IND163C_2022_02_G1_files/figure-html/unnamed-chunk-42-1.png){width=960}\n:::\n:::\n\n\nComo vemos, la variabilidad de los residuos pareciera ser más constante en el modelo de regresión lineal simple, por lo que sugiere que los supuestos sobre la varianza se cumple. Comparamos los QQ-plot:\n\n\n::: {.cell fig.fullwidth='true'}\n\n```{.r .cell-code}\npar(mfrow=c(1, 2))\n\n# Izquierda: Modelo de regresión lineal simple\nqqnorm(modelo_1_res$.resid); qqline(modelo_1_res$.resid)\n\n# Derecha: Modelo de regresión lineal múltiple\nqqnorm(modelo_4_res$.resid); qqline(modelo_4_res$.resid)\n```\n\n::: {.cell-output-display}\n![Distancias de Cook y apalancamientos](IND163C_2022_02_G1_files/figure-html/unnamed-chunk-44-1.png){width=960}\n:::\n:::\n\n\nSin embargo, en el caso de los supuestos distribucionales, lo contrario pareciera suceder. El modelo de regresión lineal múltiple pareciera tener colas de distribución más pesadas que una distribución normal, por lo que el supuesto de normalidad de los errores podría no estar cumpliéndose. \n\nLuego, podemos comparar las medidas de desempeño de ambos modelos de la forma:\n\n<label for=\"tufte-mn-\" class=\"margin-toggle\">&#8853;</label><input type=\"checkbox\" id=\"tufte-mn-\" class=\"margin-toggle\"><span class=\"marginnote\">El paquete stargazer es útil para exportar los resultados de modelos estadísticos de manera tabulada a LaTeX y otros formatos.</span>\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(stargazer)\nstargazer(modelo_1,modelo_4, type=\"latex\", header = FALSE)\n```\n\n\n\\begin{table}[!htbp] \\centering \n  \\caption{} \n  \\label{} \n\\begin{tabular}{@{\\extracolsep{5pt}}lcc} \n\\\\[-1.8ex]\\hline \n\\hline \\\\[-1.8ex] \n & \\multicolumn{2}{c}{\\textit{Dependent variable:}} \\\\ \n\\cline{2-3} \n\\\\[-1.8ex] & \\multicolumn{2}{c}{sales} \\\\ \n\\\\[-1.8ex] & (1) & (2)\\\\ \n\\hline \\\\[-1.8ex] \n TV & 0.048$^{***}$ & 0.046$^{***}$ \\\\ \n  & (0.003) & (0.001) \\\\ \n  & & \\\\ \n radio &  & 0.189$^{***}$ \\\\ \n  &  & (0.009) \\\\ \n  & & \\\\ \n newspaper &  & $-$0.001 \\\\ \n  &  & (0.006) \\\\ \n  & & \\\\ \n Constant & 7.033$^{***}$ & 2.939$^{***}$ \\\\ \n  & (0.458) & (0.312) \\\\ \n  & & \\\\ \n\\hline \\\\[-1.8ex] \nObservations & 200 & 200 \\\\ \nR$^{2}$ & 0.612 & 0.897 \\\\ \nAdjusted R$^{2}$ & 0.610 & 0.896 \\\\ \nResidual Std. Error & 3.259 (df = 198) & 1.686 (df = 196) \\\\ \nF Statistic & 312.145$^{***}$ (df = 1; 198) & 570.271$^{***}$ (df = 3; 196) \\\\ \n\\hline \n\\hline \\\\[-1.8ex] \n\\textit{Note:}  & \\multicolumn{2}{r}{$^{*}$p$<$0.1; $^{**}$p$<$0.05; $^{***}$p$<$0.01} \\\\ \n\\end{tabular} \n\\end{table} \n:::\n\n\nComo vemos, el modelo de regresión múltiple aumenta considerablemente nuestros $R^2$ y $R^2$ ajustado, de 0.612 a 0.897 y 0.61 a 0.896, sugiriendo que el modelo de regresión múltiple es más adecuado para modelar la venta de productos. Adicionalmente, nuestro estadístico F es mayor en el caso múltiple, sugiriendo un mayor ajuste de curva.\n<label for=\"tufte-mn-\" class=\"margin-toggle\">&#8853;</label><input type=\"checkbox\" id=\"tufte-mn-\" class=\"margin-toggle\"><span class=\"marginnote\">Estos criterios los veremos detalladamente más adelante en el curso</span>\nComplementariamente, es posible calcular los medidas de AIC (criterio de información de Akaike) y BIC (criterio de información Bayesiano), en las que el modelo de regresión múltiple también supera al modelo de regresión simple, al tener menor valor en estos indicadores.\n\n6. ¿Cómo se podría justificar -dentro del contexto del problema- una incorporación de interacción en el modelo de regresión múltiple? Proponga una modelo de regresión múltiple con interacción adecuado, analice y compare con los modelos anteriores.\n\nEs claro que en el modelo de regresión múltiple, los incrementos en las ventas se han interpretado **manteniendo los otros presupuestos constantes**, y que además, estos son independientes. Sin embargo, esto podría ser erróneo, pues es posible que aumentando el presupuesto de publicidad en radio, se aumente la efectividad de la publicidad en televisión, por lo que el coeficiente asociado a la variable `TV` se verá aumentado conforme la variable `radio` aumenta. Bajo este escenario, es posible que al tener un monto fijo de presupuesto, repartirlo en ambos medios (tv y radio) sea más efectivo que simplemente asignarlo a publicidad televisiva (como el modelo de regresión múltiple sin interacción sugiere). Así, una **segunda iteración** del modelo propuesto sería incorporar una interacción entre los dos medios de publicidad mencionados y además, descartar el medio de publicidad en periódicos pues este no fue significativo anteriormente. \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodelo_5<-lm(sales~ TV + radio + TV * radio, data= Advertising)\nsummary(modelo_5)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = sales ~ TV + radio + TV * radio, data = Advertising)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-6.3366 -0.4028  0.1831  0.5948  1.5246 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 6.750e+00  2.479e-01  27.233   <2e-16 ***\nTV          1.910e-02  1.504e-03  12.699   <2e-16 ***\nradio       2.886e-02  8.905e-03   3.241   0.0014 ** \nTV:radio    1.086e-03  5.242e-05  20.727   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.9435 on 196 degrees of freedom\nMultiple R-squared:  0.9678,\tAdjusted R-squared:  0.9673 \nF-statistic:  1963 on 3 and 196 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n<label for=\"tufte-mn-\" class=\"margin-toggle\">&#8853;</label><input type=\"checkbox\" id=\"tufte-mn-\" class=\"margin-toggle\"><span class=\"marginnote\">Alternativamente, se puede escribir solo TV * radio, y R interpretará el modelo de la misma manera</span>\n\n Notamos que todos nuestros coeficientes, incluida la interacción son estadísticamente significativos. Por lo que, tras un aumento de $1000 dólares en el presupuesto de televisión esperaremos, en promedio, un \n \n\n $$(\\beta_1+ \\beta_3 \\times radio) \\times 1000 = 19 + 1\\times radio$$\n\ny análogamente, ante un equitativo en el presupuesto de radio, se esperará:\n\n\n $$(\\beta_2+ \\beta_3 \\times TV) \\times 1000 = 28 + 1\\times radio$$\n\n \n \nLuego, comparamos nuestro nuevo modelo con los dos modelos anterior:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(stargazer)\nstargazer(modelo_1,modelo_4, modelo_5, type=\"latex\", header = FALSE)\n```\n\n\n\\begin{table}[!htbp] \\centering \n  \\caption{} \n  \\label{} \n\\begin{tabular}{@{\\extracolsep{5pt}}lccc} \n\\\\[-1.8ex]\\hline \n\\hline \\\\[-1.8ex] \n & \\multicolumn{3}{c}{\\textit{Dependent variable:}} \\\\ \n\\cline{2-4} \n\\\\[-1.8ex] & \\multicolumn{3}{c}{sales} \\\\ \n\\\\[-1.8ex] & (1) & (2) & (3)\\\\ \n\\hline \\\\[-1.8ex] \n TV & 0.048$^{***}$ & 0.046$^{***}$ & 0.019$^{***}$ \\\\ \n  & (0.003) & (0.001) & (0.002) \\\\ \n  & & & \\\\ \n radio &  & 0.189$^{***}$ & 0.029$^{***}$ \\\\ \n  &  & (0.009) & (0.009) \\\\ \n  & & & \\\\ \n newspaper &  & $-$0.001 &  \\\\ \n  &  & (0.006) &  \\\\ \n  & & & \\\\ \n TV:radio &  &  & 0.001$^{***}$ \\\\ \n  &  &  & (0.0001) \\\\ \n  & & & \\\\ \n Constant & 7.033$^{***}$ & 2.939$^{***}$ & 6.750$^{***}$ \\\\ \n  & (0.458) & (0.312) & (0.248) \\\\ \n  & & & \\\\ \n\\hline \\\\[-1.8ex] \nObservations & 200 & 200 & 200 \\\\ \nR$^{2}$ & 0.612 & 0.897 & 0.968 \\\\ \nAdjusted R$^{2}$ & 0.610 & 0.896 & 0.967 \\\\ \nResidual Std. Error & 3.259 (df = 198) & 1.686 (df = 196) & 0.944 (df = 196) \\\\ \nF Statistic & 312.145$^{***}$ (df = 1; 198) & 570.271$^{***}$ (df = 3; 196) & 1,963.057$^{***}$ (df = 3; 196) \\\\ \n\\hline \n\\hline \\\\[-1.8ex] \n\\textit{Note:}  & \\multicolumn{3}{r}{$^{*}$p$<$0.1; $^{**}$p$<$0.05; $^{***}$p$<$0.01} \\\\ \n\\end{tabular} \n\\end{table} \n:::\n\n\n\nEs claro notar que la incorporación de la interacción en nuestro modelo de regresión múltiple mejoró aún más nuestro ajuste de curva, bajo la perspectiva de los mismos indicadores utilizas para comparar los primeros dos modelos. Finalmente, realizamos un análisis de residuos comparando los modelos realizados:\n\n\n::: {.cell fig.fullwidth='true'}\n\n```{.r .cell-code}\nmodelo_5_res <- augment(modelo_5, Advertising) %>%\n  mutate(Model = \"Model de regresión lineal múltiple con interacción\") %>%\n  rbind(modelo_4_res)\n\nggplot(modelo_5_res, aes(.fitted, .resid)) +\n  geom_ref_line(h = 0) +\n  geom_point() +\n  geom_smooth(se = FALSE) +\n  facet_wrap(~ Model) +\n  ggtitle(\"Residuos vs Ajuste\")\n```\n\n::: {.cell-output-display}\n![Distancias de Cook y apalancamientos](IND163C_2022_02_G1_files/figure-html/unnamed-chunk-52-1.png){width=960}\n:::\n:::\n\n\nEl modelo con interacción provee una varianza constante que los otros dos modelos, sin embargo, parecieran haber datos anómalos. Un manera alternativa de analizar visualmente la distribución de los residuos, es utilizando histogramas apropiadamente (en vez de QQ-plot):\n\n\n::: {.cell fig.fullwidth='true'}\n\n```{.r .cell-code}\nggplot(modelo_5_res, aes(.resid)) +\n  geom_histogram(binwidth = .25) +\n  facet_wrap(~ Model, scales = \"free_x\") +\n  ggtitle(\"Histograma de residuos\")\n```\n\n::: {.cell-output-display}\n![Distancias de Cook y apalancamientos](IND163C_2022_02_G1_files/figure-html/unnamed-chunk-54-1.png){width=960}\n:::\n:::\n\n\nEs posible que si analizamos para distintas magnitudes de ventas veamos mayor grado de normalidad en los residuos, digamos que si ventas `sales` mayores a 10, obtenemos:\n\n\n::: {.cell fig.fullwidth='true'}\n\n```{.r .cell-code}\nmodelo_5_res %>%\n  filter(sales > 10) %>%\n  ggplot(aes(.resid)) +\n  geom_histogram(binwidth = .25) +\n  facet_wrap(~ Model, scales = \"free_x\") +\n  ggtitle(\"Histograma de residuos\")\n```\n\n::: {.cell-output-display}\n![Distancias de Cook y apalancamientos](IND163C_2022_02_G1_files/figure-html/unnamed-chunk-56-1.png){width=960}\n:::\n:::\n\n\nEs claro ver la normalidad en el modelo de regresión lineal con interacción es bastante viable. En cuanto a las observaciones anómalas, las diagnosticamos como:\n\n\n::: {.cell fig.fullwidth='true'}\n\n```{.r .cell-code}\npar(mfrow=c(1, 2))\n\nplot(modelo_5, which = 4, id.n = 5)\nplot(modelo_5, which = 5, id.n = 5)\n```\n\n::: {.cell-output-display}\n![Distancias de Cook y apalancamientos](IND163C_2022_02_G1_files/figure-html/unnamed-chunk-58-1.png){width=960}\n:::\n:::\n\n\nEn el gráfico de la distancia de Cook, se ve claramente que las observaciones 6, 9, 109, 131 y 156 parecieran ser outliers. Por lo que vemos estas observaciones.\n\n<label for=\"tufte-mn-\" class=\"margin-toggle\">&#8853;</label><input type=\"checkbox\" id=\"tufte-mn-\" class=\"margin-toggle\"><span class=\"marginnote\">La coma final, ordena a R que nos entregue todas las columnas.</span>\n\n::: {.cell}\n\n```{.r .cell-code}\nAdvertising[c(6,9,109,131,156),]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 5 x 4\n     TV radio newspaper sales\n  <dbl> <dbl>     <dbl> <dbl>\n1   8.7  48.9      75     7.2\n2   8.6   2.1       1     4.8\n3  13.1   0.4      25.6   5.3\n4   0.7  39.6       8.7   1.6\n5   4.1  11.6       5.7   3.2\n```\n:::\n:::\n\n\nNotamos que en todas estas observaciones se tienen pocas ventas, lo que reafirma que nuestro modelo no se desempeña bien para niveles bajos de ventas.",
    "supporting": [
      "IND163C_2022_02_G1_files\\figure-html"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}
{
  "hash": "b2d0829a1e84bef1937ad16a68cec2cc",
  "result": {
    "markdown": "---\ntitle: \"Conceptos Básicos\"\nsubtitle: \"IND 163 - 2022/02\"\nauthor: \"Eloy Alvarado Narváez\"\ninstitute: \"Universidad Técnica Federico Santa María\"\ndate: 26/08/22\nformat: \n  revealjs:\n    theme: slides.scss\n    touch: true\n    slide-level: 2\n    code-copy: true\nincremental: true\nslide-number: true\nlang: es\nhighlight-style: github\nwidth: 1600\nheight: 900\nlogo: images/logo_usm.png\ntransition: fade\nfooter: \"IND 163 - Semana 2\"\nexecute:\n  freeze: auto\n---\n\n\n# Conceptos básicos de probabilidad\n\n## Escuelas de Probabilidad\n\n-   Enfoque clásico\n-   Enfoque frecuentista\n-   Enfoque bayesiano\n\n## Enfoque clásico\n\nEste enfoque también llamado enfoque *apriori* tiene por característica principal la asignación igualitaria de una medida de ocurrencia para un resultado de un experimento aleatorio (experimento equiprobable).\n\n. . .\n\nEsta asignación de *probabilidad* se determina antes de observar los resultados experimentales.\n\n. . .\n\n-   **¿Algún ejemplo?**\n\n## Enfoque frecuentista\n\nEste enfoque también llamado enfoque *empírico*, determina la medida de ocurrencia con base en la proporción de veces que ocurre un resultado *favorable* en un determinado número de observaciones o experimentos. Este enfoque no asigna probabilidades *a priori* a los posibles resultados de un experimento aleatorio.\n\n. . .\n\n-   **¿Algún ejemplo?**\n\n## Enfoque bayesiano\n\nEste enfoque también llamado enfoque *subjetivo*, determina la medida de ocurrencia en base a una *expectativa razonable* basado en el conocimiento del investigador.\n\nEl enfoque bayesiano es particularmente útil cuando se tiene poca información del experimento, y este puede ser realizado para *actualizador* mis probabilidades, esto debido a que cada realización del experimento aleatorio me otorgará información adicional para determinar correctamente mis probabilidades.\n\n## Conceptos fundamentales\n\n-   **Espacio muestral:** Se define como el conjunto de todos los posibles resultados del experimento, lo anotamos por $\\Omega$.\n-   **Suceso o evento:** Es cualquier subconjunto de $\\Omega$, usualmente lo anotamos con letras mayúsculas. $(A,B,C,\\dots)$.\n-   **Espacio de sucesos:** Es el conjunto de todos los subconjuntos de $\\Omega$. Lo anotamos por $2^{\\Omega}$.\n-   $\\sigma$-álgebra: Es una familia de subconjuntos del espacio de sucesos, $\\Sigma \\subset 2^{\\Omega}$, y que cumplen con *ciertas propiedades*.\n\n## Clasificación del espacio muestral\n\n-   **Discreto**\n    -   **Numerable:** Finito o Infinito.\n-   **Continuo**\n    -   **No numerable:** Acotado o No acotado.\n\n## Definición formal de probabilidad\n\nEl par $(\\Omega,\\Sigma)$ se dice *espacio medible*, y la función $\\mathbb{P}:\\Sigma \\rightarrow \\mathbb{R}^{+}$, es una **medida de probabilidad** si satisface:\n\n1.  $0\\leq \\mathbb{P}[A] \\leq 1, \\forall A \\in \\Sigma$\n2.  $\\mathbb{P}[\\Omega]=1$\n3.  Dados $\\displaystyle A_1,A_2,\\dots \\in \\Sigma \\Rightarrow \\mathbb{P}\\left[ \\bigcup_{i=1}^{n} A_n \\right] = \\sum_{i=1}^{n} \\mathbb{P}[A_i], \\hspace{5pt} \\forall i$\n\n## Algunas propiedades\n\n1.  $\\mathbb{P}[A]+\\mathbb{P}[A^c]=\\mathbb{P}[\\Omega]$\n2.  $\\mathbb{P}[\\phi]=1-\\mathbb{P}[\\phi^c]=1-\\mathbb{P}[\\Omega]=0$\n3.  $\\mathbb{P}[A \\cup B]=\\mathbb{P}[A]+\\mathbb{P}[B] - \\mathbb{P}[A\\cap B]$ . Si este último término $(\\mathbb{P}[A\\cap B])$ es cero, se dice que $A$ y $B$ son eventos mutuamente excluyentes.\n4.  $\\mathbb{P}[A-B]=\\mathbb{P}[A\\cap B^c]$\n5.  $\\mathbb{P}[A \\cap B]=\\mathbb{P}[A]\\mathbb{P}[B]$. Si $A$ y $B$ son independientes.\n\n# Variables aleatorias\n\n## Definición Básica\n\nUna **Variable aleatoria**, es una función que permite trabajar cualquier espacio muestral de manera cuantitativa. Se dice que $X$ es una variable aleatoria si es una función que toma los elementos de $\\Omega$ y los transforma en puntos sobre la recta de los reales. Esto es:\n\n\n```{=tex}\n\\begin{align*}\n  X: \\quad &\\Omega \\longrightarrow \\mathbb{R}\\\\\n           &\\omega \\longrightarrow X(\\omega)\n\\end{align*}\n```\n\n. . .\n\nEl conjunto de todas las posibles realizaciones es llamado el **soporte** y lo denotamos por $R_X$.\n\n## Tipos de variables aleatorias\n\nSe dice que $X$ es una Variable Aleatoria si es una función que toma valores en probabilidad, es decir, no se puede predecir con certeza sus resultados.\n\n**Una variable aleatoria es siempre cuantitativa** y se puede clasificar en los siguientes grupos:\n\n\n$$X(\\omega) \\begin{cases}\n\\text{Discreto}\n\\begin{cases}\n\\text{Finito}\\\\\n\\text{Infinito}\n\\end{cases}\\\\\n\\text{Continuo}\n\\begin{cases}\n\\text{Acotados}\\\\\n\\text{No Acotados}\n\\end{cases}\n\\end{cases}$$\n\n## Variables aleatorias discretas\n\nUna variable aleatoria $X$ es llamada **discreta** si:\n\n1.  Su soporte $R_X$ es un conjunto *numerable*.\n2.  Existe una función $p_X:\\mathbb{R}\\rightarrow [0,1]$, llamada la **función de masa de probabilidad** de $X$, tal que, para cualquier $x\\in \\mathbb{R}$:\n\n::: {.fragment}\n\n$$p_X(x)\\begin{cases} \\mathbb{P}(X=x) \\quad &\\text{si } x\\in R_X\\\\ 0 \\quad &\\text{si } x\\notin R_X\\end{cases}$$\n\n:::\n\n. . . \n\nEsta función tiene dos características principales:\n\n1. **no-negatividad**: $p_X(x)\\geq 0$ para cualquier $x\\in \\mathbb{R}$.\n2. **Suma sobre su soporte es 1**: $\\sum_{x\\in R_X}p_X(x)=1$\n\n## Variables aleatorias continuas\n\nUna variable aleatoria $X$ es llamada **continua** si:\n\n1. Su soporte $R_X$ es un conjunto *no-numerable*.\n2. Existe una función $f_X:\\mathbb{R}\\rightarrow [0,1]$, llamada **función de densidad de probabilidad** de $X$, tal que, para cualquier intervalo $[a,b]\\subseteq \\mathbb{R}$:\n\n:::{.fragment}\n\n$$\\mathbb{P}(X\\in [a,b])=\\int_{a}^{b}f_X(x)dx$$\n\n:::\n\n. . . \n\nEsta función tiene dos características principales:\n\n1. **no-negatividad**: $f_X(x)\\geq 0$ para cualquier $x\\in \\mathbb{R}$.\n2. **Integral sobre $\\mathbb{R}$ es 1**: $\\int_{-\\infty}^{\\infty} f_X(x)dx=1$.\n\n\n## Función de distribución\n\nLas variables aleatorias son usualmente caracterizadas en términos de sus funciones de distribución.\n\n. . . \n\nSea $X$ una variable aleatoria. La **función de distribución** de $X$ es una función $F_X:\\mathbb{R}\\rightarrow [0,1]$ tal que:\n\n\n$$F_X(x)=\\mathbb{P}(X\\leq x), \\forall x\\in \\mathbb{R}$$\n\n\n. . .\n\nSi conocemos la función de distribución de una variable aleatoria $X$, entonces podemos fácilmente calcular la probabilidad que $X$ pertenezca a un intervalo $(a,b] \\subseteq \\mathbb{R}$ como:\n\n\n$$\\mathbb{P}(a<X<b)=F_X(b)-F_X(a)$$\n\n\n## Valores esperados\n\nSea $X$ una variable aleatoria, entonces se define el valor esperado de una función real $g(X)$, como:\n\n\n$$\\mathbb{E}[g(X)]= \\begin{cases} \\sum_{x\\in \\mathbb{R}} g(X)P(X=x)\\\\ \\int_{x\\in \\mathbb{R}} g(X)f(x)dx \\end{cases}$$\n\n\n\nSi $g(X)=X$, diremos que el valor esperado o esperanza matemática de $X$ es:\n\n$$\\mathbb{E}(X)=\\begin{cases}\\sum_{x\\in \\mathbb{R}} x P(X=x)\\\\ \\int_{x\\in \\mathbb{R}} x f(x)dx \\end{cases}$$\n\n\nPara variables de tipo discreta y continua, respectivamente.\n\n## Propiedades de los valores esperados\n\nSean $a$ y $b$ constantes, $X$ una variable aleatoria entonces se cumple que:\n\n- $\\mathbb{E}(a)=a$\n- $\\mathbb{E}(X)=\\mu=$ constante\n- $\\mathbb{E}(aX)=a\\mathbb{E}(X)$\n- $\\mathbb{E}(aX+b)=\\mathbb{E}(aX)+\\mathbb{E}(b)=a\\mathbb{E}(X)+b$\n\n## Varianza\n\nSea $X$ una variable aleatoria, se define el la **varianza** de $X$ como:\n\n\n$$\\mathbb{E}[(X-\\mathbb{E}(X))^2]=V(X)=\\begin{cases}\\sum_{x\\in\\mathbb{R}} (X-\\mathbb{E}(X))^2P(X=x)\\\\ \\int_{x\\in\\mathbb{R}}(X-\\mathbb{E}(X))^2f_{X}(x)dx\\end{cases}$$\n\n\nPara variables de tipo discreta y continua, respectivamente.\n\n## Propiedades de la varianza\n\nSea $a$ y $b$ constantes, $X$ una variable aleatoria, entonces se cumple:\n\n\n- $\\mathbb{V}(a)=0$\n- $\\mathbb{V}(X)=\\sigma^2=$ constante\n- $\\mathbb{V}(aX)=a^2 \\mathbb{V}(X)$\n- $\\mathbb{V}(aX+b)=\\mathbb{V}(aX)+\\mathbb{V}(b)=a^2\\mathbb{V}(X)+0=a^2\\mathbb{V}(X)$\n- $\\mathbb{V}(X)=\\mathbb{E}(X^2)-(\\mathbb{E}(X))^2$\n\n# Distribuciones discretas\n\n## Distribución binomial \n\nSea $X$ una variable aleatoria que representa el número de éxitos en $n$ ensayos y $p$ la probabilidad de éxito con cualquiera de éstos. Se dice entonces que $X$ tiene una distribución binomial con función de probabilidad:\n\n\n$$\\mathbb{P}(X=k)= {{n}\\choose{k}}p^k(1-p)^{n-k} \\hspace{20pt} k=1,2,\\cdots,n$$\n\nEn donde ${{n}\\choose{k}}$ es el coeficiente binomial, esto es: \n\n\n$${{n}\\choose{k}}=\\dfrac{n!}{k!(n-k)!}$$\n\n\nSi $n=1$ diremos que $X$ sigue una distribución Bernoulli.\n\n## Propiedades de la distribución binomial\n\nSi $X$ tiene una distribución binomial, entonces se cumple que:\n\n- $\\mathbb{E}[X]=np$\n- $\\mathbb{V}[X]=np(1-p)$\n\n. . . \n\nEs claro ver que si $X$ tiene una distribución bernoulli, entonces:\n\n- $\\mathbb{E}[X]=p$\n- $\\mathbb{V}[X]=p(1-p)$\n\n## Distribución binomial en R \n\n::: {.cell}\n\n:::\n\n\n::: {.panel-tabset}\n\n### Código\n\n::: {.cell}\n\n```{.r .cell-code  code-line-numbers=\"1|2|3|4|5|6|7\"}\nset.seed(163)\ndbinom(x = 2, size = 10, prob = 0.3)\nmean(rbinom(n = 10000, size = 10, prob = 0.3) == 2)\npbinom(q = 5, size = 10, p = 0.3, lower.tail = TRUE)\nmean(rbinom(n = 10000, size = 10, prob = 0.3) <= 5)\npbinom(q = 4, size = 10, p = 0.3, lower.tail  = FALSE)\nmean(rbinom(n = 10000, size = 10, prob = 0.3) >= 5)\n```\n:::\n\n\n### Salidas\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(163)\ndbinom(x = 2, size = 10, prob = 0.3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.2334744\n```\n:::\n\n```{.r .cell-code}\nmean(rbinom(n = 10000, size = 10, prob = 0.3) == 2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.2417\n```\n:::\n\n```{.r .cell-code}\npbinom(q = 5, size = 10, p = 0.3, lower.tail = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.952651\n```\n:::\n\n```{.r .cell-code}\nmean(rbinom(n = 10000, size = 10, prob = 0.3) <= 5)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.9529\n```\n:::\n\n```{.r .cell-code}\npbinom(q = 4, size = 10, p = 0.3, lower.tail  = FALSE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.1502683\n```\n:::\n\n```{.r .cell-code}\nmean(rbinom(n = 10000, size = 10, prob = 0.3) >= 5)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.1497\n```\n:::\n:::\n:::\n\n## Distribución binomial en Python\n\n\n::: {.panel-tabset}\n\n### Código\n\n```{.python code-line-numbers=\"1-3|5|6|7|8|9|10|11\"}\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import binom\n\nnp.random.seed(163)\nbinom.pmf(2, n=10, p=0.3)\nsum(np.random.binomial(10, 0.3, 10000) == 2)/10000\nbinom.cdf(5, n=10, p=0.3)\nsum(np.random.binomial(10, 0.3, 10000) <= 5)/10000\n1-binom.cdf(4, n=10, p=0.3)\nsum(np.random.binomial(10, 0.3, 10000) >= 5)/10000\n```\n\n### Salidas\n\n::: {.cell}\n\n```{.python .cell-code}\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import binom\n\nnp.random.seed(163)\nbinom.pmf(2, n=10, p=0.3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n0.2334744405000001\n```\n:::\n\n```{.python .cell-code}\nsum(np.random.binomial(10, 0.3, 10000) == 2)/10000\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n0.2332\n```\n:::\n\n```{.python .cell-code}\nbinom.cdf(5, n=10, p=0.3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n0.9526510126000001\n```\n:::\n\n```{.python .cell-code}\nsum(np.random.binomial(10, 0.3, 10000) <= 5)/10000\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n0.9517\n```\n:::\n\n```{.python .cell-code}\n1-binom.cdf(4, n=10, p=0.3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n0.15026833259999994\n```\n:::\n\n```{.python .cell-code}\nsum(np.random.binomial(10, 0.3, 10000) >= 5)/10000\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n0.1478\n```\n:::\n:::\n\n:::\n\n## Distribución de Poisson\n\nSea $X$ una variable aleatoria que representa el número de eventos aleatorios independientes que ocurren a una rapidez constante sobre el tiempo o el espacio. Se dice entonces que la variable aleatoria $X$ tiene una distribución de Poisson con función de probabilidad:\n\n\n$$\\mathbb{P}(X=k)=\\dfrac{e^{-\\lambda}\\lambda^k}{k!} \\hspace{20pt} k=0,1,\\cdots,n,\\cdots$$\n\n\nEn donde $\\lambda>0$ representa el número promedio de ocurrencias del evento aleatorio por unidad de tiempo. Además, si $X$ sigue una distribución de Poisson se cumple que:\n\n- $\\mathbb{E}[X]=\\lambda$\n- $\\mathbb{V}[X]=\\lambda$\n\n## Distribución de Poisson en R\n\n::: {.panel-tabset}\n\n### Código\n\n::: {.cell}\n\n```{.r .cell-code  code-line-numbers=\"1|2|3|4|5|6|7\"}\nset.seed(163)\ndpois(x = 7, 5)\nmean(rpois(n = 10000, 5) == 7)\nppois(q = 5, 5, lower.tail = TRUE)\nmean(rpois(n = 10000, 5) <= 5)\nppois(q = 4, 5, lower.tail  = FALSE)\nmean(rpois(n = 10000,5) >= 5)\n```\n:::\n### Salidas\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(163)\ndpois(x = 7, 5)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.1044449\n```\n:::\n\n```{.r .cell-code}\nmean(rpois(n = 10000, 5) == 7)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.1107\n```\n:::\n\n```{.r .cell-code}\nppois(q = 5, 5, lower.tail = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.6159607\n```\n:::\n\n```{.r .cell-code}\nmean(rpois(n = 10000, 5) <= 5)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.6109\n```\n:::\n\n```{.r .cell-code}\nppois(q = 4, 5, lower.tail  = FALSE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.5595067\n```\n:::\n\n```{.r .cell-code}\nmean(rpois(n = 10000,5) >= 5)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.5542\n```\n:::\n:::\n\n:::\n\n## Distribución de Poisson en Python\n\n::: {.panel-tabset}\n\n### Código\n\n```{.python code-line-numbers=\"1-3|5|6|7|8|9|10|11\"}\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import poisson\n\nnp.random.seed(163)\npoisson.pmf(2, n=10, p=0.3)\nsum(np.random.binomial(10, 0.3, 10000) == 2)/10000\nbinom.cdf(5, n=10, p=0.3)\nsum(np.random.binomial(10, 0.3, 10000) <= 5)/10000\n1-binom.cdf(4, n=10, p=0.3)\nsum(np.random.binomial(10, 0.3, 10000) >= 5)/10000\n```\n\n### Salidas\n\n::: {.cell}\n\n```{.python .cell-code}\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import poisson\n\nnp.random.seed(163)\npoisson.pmf(7, 5)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n0.10444486295705395\n```\n:::\n\n```{.python .cell-code}\nsum(np.random.poisson(5, 10000) == 7)/10000\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n0.1024\n```\n:::\n\n```{.python .cell-code}\npoisson.cdf(7, 5)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n0.8666283259299925\n```\n:::\n\n```{.python .cell-code}\nsum(np.random.poisson(5, 10000) <= 7)/10000\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n0.8662\n```\n:::\n\n```{.python .cell-code}\n1-poisson.cdf(6, 5)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n0.2378165370270613\n```\n:::\n\n```{.python .cell-code}\nsum(np.random.poisson(5, 10000) >= 7)/10000\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n0.2369\n```\n:::\n:::\n\n:::\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\r\n<script>\r\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\r\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\r\n  // slide changes (different for each slide format).\r\n  (function () {\r\n    function fireSlideChanged(previousSlide, currentSlide) {\r\n\r\n      // dispatch for htmlwidgets\r\n      const event = window.document.createEvent(\"Event\");\r\n      event.initEvent(\"slideenter\", true, true);\r\n      window.document.dispatchEvent(event);\r\n\r\n      // dispatch for shiny\r\n      if (window.jQuery) {\r\n        if (previousSlide) {\r\n          window.jQuery(previousSlide).trigger(\"hidden\");\r\n        }\r\n        if (currentSlide) {\r\n          window.jQuery(currentSlide).trigger(\"shown\");\r\n        }\r\n      }\r\n    }\r\n\r\n    // hookup for reveal\r\n    if (window.Reveal) {\r\n      window.Reveal.addEventListener(\"slidechanged\", function(event) {\r\n        fireSlideChanged(event.previousSlide, event.currentSlide);\r\n      });\r\n    }\r\n\r\n    // hookup for slidy\r\n    if (window.w3c_slidy) {\r\n      window.w3c_slidy.add_observer(function (slide_num) {\r\n        // slide_num starts at position 1\r\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\r\n      });\r\n    }\r\n\r\n  })();\r\n</script>\r\n\r\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}
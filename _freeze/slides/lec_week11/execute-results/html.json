{
  "hash": "55289b7351a9ebb7adf3652dc82715e4",
  "result": {
    "markdown": "---\ntitle: \"Redes neuronales artificiales\"\nsubtitle: \"IND 163 - 2022/02\"\nauthor: \"Eloy Alvarado Narváez\"\ninstitute: \"Universidad Técnica Federico Santa María\"\ndate: 11/11/22\nformat: \n  revealjs:\n    theme: slides.scss\n    touch: true\n    slide-level: 2\n    code-copy: true\nincremental: true\nslide-number: true\nlang: es\nhighlight-style: github\nwidth: 1600\nheight: 900\nlogo: images/logo_usm.png\ntransition: fade\nfooter: \"IND 163 - Semana 11\"\nexecute:\n  freeze: auto\neditor: \n  markdown: \n    wrap: 72\n---\n\n\n# Redes Neuronales\n\nUna red neuronal artificial, **ANN** por sus siglas en inglés *artificial neural network* modelan la relación entre un conjunto de *señales* de entrada y una *señal de salida* usando un modelo derivado desde nuestro entendimiento de cómo funciona un cerebro biológico ante estímulos externos.\n\nTal como un cerebro usa una red de células interconectadas llamadas **neuronas**, una **red neuronal** usa una red de neuronas artificiales o **nodos** para resolver problemas de aprendizaje.\n\n## Representación de red neuronal\n\n![](images/week11/neural_network.png){fig-align=\"center\"}\n\n## Redes neuronales: continuación \n\nLa forma más común de representar la estructura de una red neuronal es mediante el uso de capas (**layers**), formadas a su vez por neuronas. Cada neurona, realiza una operación sencilla y está conectada a las neuronas de la capa anterior y de la capa siguiente mediante pesos, cuya función es regular la información que se propaga de una neurona a otra.\n\n\n## Red neuronal artificial\n\n![](images/week11/ann.png){fig-align=\"center\"}\n\n## Red neuronal artificial: continuación\n\nPara facilitar la comprensión de la estructura de las redes, es útil representar una red equivalente a un modelo de regresión lineal:\n\n\n$$y=w_1 x_1 +\\dots+w_d x_d + b$$\n\n\nCada neurona de la capa de entrada representa el valor de uno de los predictores. Las flechas representan los coeficientes de regresión, que en términos de redes se llaman pesos, y la neurona de salida representa el valor predicho. Para que esta representación sea equivalente a la ecuación de un modelo lineal, faltan dos cosas:\n\n- El sesgo del modelo\n\n- Las operaciones de multiplicación y suma que combinan el valor de los predictores con los pesos del modelo\n\n. . .\n\nCada neurona de la capa intermedia tiene un valor de sesgo, pero suele omitirse en las representaciones gráficas. En cuanto a las operaciones matemáticas, es el elemento clave que ocurre dentro de las neuronas y conviene verlo con detalle.\n\n# Neurona\n\nLa neurona es la unidad funcional de los modelos de redes. Dentro de cada neurona ocurren simplemente dos operaciones: la suma ponderada de sus entradas y la aplicación de una función de activación.\n\nEn la primera parte, se multiplica cada valor de entrada $x_i$ por su peso asociado $w_i$ y se suman junto con el sesgo. Este es el valor neto de entrada a la neurona. A continuación, este valor se pasa por una función, conocida como **función de activación**, que transforma el valor neto de entrada en un valor de salida.\n\nSi bien el valor que llega a la neurona, siempre es una combinación lineal, gracias a la función de activación, se pueden generar salidas muy diversas. Es en la función de activación donde reside el potencial de los modelos de redes para aprender relaciones no lineales.\n\n## Representación de una neurona\n\n![](images/week11/neurona.png){fig-align=\"center\"}\n\n## Neurona: continuación\n\nLo anterior es la noción intuitiva de las redes neuronales artificiales, en términos matemáticos:\n\nEl valor neto de entrada a una neurona es la suma de los valores que le llegan, ponderados por el peso de las conexiones, más el sesgo:\n\n\n$$Input = \\sum_{i=1}^{n} x_i w_i + b$$\n\n\nEn lugar de utilizar la sumatoria, este operación usualmente se presenta como un producto matricial, donde $X$ representa el vector de los valores de entrada y $W$ el vector de pesos:\n\n\n$$Input = XW + b$$\n\n\n## Neurona: continuación\n\nA este valor se le aplica una función de activación $g$ que lo transforma en lo que se conoce como el valor de activación $a$, que es lo que finalmente sale de la neurona.\n\n\n$$a=g(Input)=g(XW+b)$$\n\n\nPara la capa de entrada, donde únicamente se quiere incorporar el valor de los predictores, la función de activación es la unidad, es decir, sale lo mismo que entra. En la capa de salida, la función de activación utilizada suele ser la identidad para problemas de regresión.\n\n## Función de activación\n\nLas funciones de activación controlan en gran medida qué información se propaga desde una capa a la siguiente (*forward propagation*). Estas funciones convierten el valor neto de entrada a la neurona (combinación de los input, pesos y sesgo) en un nuevo valor. \n\nGracias a combinación de **funciones de activación no lineales con múltiples capas**, los modelos de redes son capaces de aprender relaciones **no lineales**.\n\nLa gran mayoría de funciones de activación convierten el valor de entrada neto de la neurona en un valor dentro del rango $(0, 1)$ o $(-1, 1)$. Cuando el valor de activación de una neurona (salida de su función de activación) es cero, se dice que la neurona está **inactiva**, ya que no pasa ningún tipo de información a las siguientes neuronas.\n\n## Tipos de funciones de activación\n\nExisten muchas funciones de activación utilizadas en la práctica, en lo que sigue mencionamos un par de ellas:\n\n- *Rectified linear unit* (ReLU)\n- Sigmoide\n- Tangente hiperbólica\n\n. . .\n\nTambién hay otras como: función lineal, gaussiana, linear saturada, etc.\n\n\n## Rectified linear unit (ReLU)\n\nLa función de activación **ReLu** aplica una transformación no lineal muy simple, activa la neurona solo si el input está por encima de cero. Mientras el valor de entrada está por debajo de cero, el valor de salida es cero, pero cuando es superior, el valor de salida aumenta de forma lineal con el de entrada.\n\n\n$$ReLU(x)=\\max (x,0)$$\n\n\nDe esta forma, la función de activación retiene únicamente los valores positivos y descarta los negativos dándoles una activación de cero.\n\n## Gráfico ReLU\n\n![](images/week11/relu.png){fig-align=\"center\"}\n\n## Rectified linear unit (ReLU): continuación\n\n\nLa función de activación **ReLU** es con diferencia la función de activación más empleada por sus buenos resultados en aplicaciones diversas. La razón de esto reside en el comportamiento de su derivada (gradiente), que es cero o constante.\n\n\n## Sigmoide\n\nLa función sigmoide transforma valores en la recta real a valores en el rango $[0, 1]$:\n\n\n$$sigmoid(x)=\\dfrac{1}{1+\\exp(-x)}$$\n\n\n## Gráfico Sigmoide\n\n![](images/week11/sigmoid.png){fig-align=\"center\"}\n\n## Sigmoide: continuación\n\nAunque la **función de activación sigmoide** se utilizó mucho en los inicios de los modelos de redes neuronales artificiales, en la actualidad, suele preferirse la **función ReLU**.\n\nUn caso en el que la función de activación sigmoide sigue siendo la función utilizada por defecto es en las neuronas de la capa de salida de los modelos de clasificación binaria, ya que su salida puede interpretarse como probabilidad.\n\n\n## Tangente hiperbólica\n\nLa función de activación tangente hiperbólica, se comporta de forma similar a la función sigmoide, pero su salida está acotada en el rango $(-1, 1)$:\n\n\n$$\\tanh(x)=\\dfrac{1-\\exp(-2x)}{1+\\exp(-2x)}$$\n\n## Gráfico tangente hiperbólica\n\n![](images/week11/tanh.png){fig-align=\"center\"}\n\n# Función de coste (loss function)\n\nLa función de coste ($l$), también llamada función de pérdida, *loss function* o *cost function*, es la encargada de **cuantificar** la distancia entre el valor real y el valor predicho por la red, en otras palabras, **mide cuánto se equivoca la red al realizar predicciones**.\n\nEn la mayoría de casos, la función de coste devuelve valores positivos. Cuanto más próximo a cero es el valor de coste, mejor son las predicciones de la red (menor error), siendo cero cuando las predicciones se corresponden exactamente con el valor real.\n\nLa función de coste puede calcularse para una única observación o para un conjunto de datos (normalmente promediando el valor de todas las observaciones). Es el segundo caso el que se utiliza para dirigir el entrenamiento de los modelos.\n\nDependiendo del tipo de problema, regresión o clasificación, es necesario utilizar una función de coste u otra. En problemas de regresión, las más utilizadas son el error cuadrático medio y el error absoluto medio. En problemas de clasificación suele emplearse la función *log loss*, también llamada *logistic loss* o *cross-entropy loss*.\n\n## Error cuadrático medio\n\nEl error cuadrático medio (*mean squared error*, MSE) es la función de coste más utilizada en problemas de regresión. Para una determinada observación $i$, el error cuadrático se calcula como la diferencia al cuadrado entre el valor predicho $\\hat{y}$ y el valor real $y$.\n\n\n$$l^{(i)}(w,b)=\\left( \\widehat{y}^{(i)}-y^{(i)}\\right)^2$$\n\n\nLas funciones de coste suelen escribirse con la notación $l(w,b)$ para hacer referencia a que su valor depende de los pesos y el sesgo del modelo, ya que son estos los que determinan el valor de las predicciones $\\widehat{y}^{(i)}$.\n\n## Error cuadrático medio: continuación\n\nCon frecuencia, esta función de coste se encuentra multiplicada por $\\dfrac{1}{2}$, esto es simplemente por conveniencia matemática para simplificar el cálculo de su derivada.\n\n\n$$l^{(i)}(w,b)=\\dfrac{1}{2}\\left( \\widehat{y}^{(i)}-y^{(i)}\\right)^2$$\n\n\nPara cuantificar el error que comete el modelo todo un conjunto de datos, por ejemplo los de entrenamiento, se promedia el error de todas las $N$ observaciones.\n\n\n$$L(w,b)=\\dfrac{1}{n}\\sum_{i=1}^{n}l^{(i)}(w,b)=\\dfrac{1}{n}\\sum_{i=1}^{n}\\left( \\widehat{y}^{(i)}-y^{(i)}\\right)^{2}$$\n\n\nCuando un modelo se entrena utilizando el error cuadrático medio como función de coste, está aprendiendo a **predecir la media de la variable respuesta**.\n\n## Error medio absoluto\n\nEl error medio absoluto (*mean absolute error*, MAE) consiste en promediar el error absoluto de las predicciones.\n\n\n$$L(w,b)=\\dfrac{1}{n}\\sum_{i=1}^{n}|\\widehat{y}^{(i)}-y^{(i)}|$$\n\n\nEl error medio absoluto es más robusto frente a *outliers* que el error cuadrático medio. Esto significa que el entrenamiento del modelo se ve menos influenciado por datos anómalos que pueda haber en el conjunto de entrenamiento. Cuando un modelo se entrena utilizando el error absoluto medio como función de coste, está aprendiendo a **predecir la mediana de la variable respuesta**.\n\n# Múltiples capas\n\nEl modelo de red neuronal con una única capa (**single-layer perceptron**), aunque supuso un gran avance en el campo del *machine learning*, solo es capaz de aprender patrones sencillos. Para superar esta limitación, los investigadores descubrieron que, combinando múltiples capas ocultas, la red puede aprender relaciones mucho más complejas entre los predictores y la variable respuesta. A esta estructura se le conoce como **perceptrón multicapa** o **multilayer perceptron** (MLP), y puede considerarse como el primer modelo de **deep learning**.\n\nLa estructura de un perceptrón multicapa consta de varias capas ocultas. Cada neurona está conectada a todas las neuronas de la capa anterior y a las de la capa posterior. Aunque no es estrictamente necesario, todas las neuronas que forman parte de una misma capa suelen emplear la misma función de activación.\n\n## Múltiples capas: continuación\n\n\nCombinando múltiples capas ocultas y **funciones de activación no lineales**, los modelos de redes pueden aprender prácticamente cualquier patrón. De hecho, está demostrado que, con suficientes neuronas, un MLP es un **aproximador universal** para cualquier función.\n\n## Representación MLP\n\n![](images/week11/mlp.png){fig-align=\"center\"}\n\n## Entrenamiento{.small}\n\nEl proceso de entrenamiento de una red neuronal consiste en ajustar el valor de los pesos y sesgo de tal forma que, las predicciones que se generen, tengan el menor error posible. Gracias a esto, el modelo es capaz de identificar qué predictores tienen mayor influencia y de qué forma están relacionados entre ellos y con la variable respuesta.\n\nLa idea intuitiva de cómo entrenar una red neuronal es la siguiente:\n\n1. Iniciar la red con valores aleatorios de los pesos y sesgo.\n\n2. Para cada observación de entrenamiento, calcular el error que comete la red al hacer su predicción. Promediar los errores de todas las observaciones.\n\n3. Identificar la responsabilidad que ha tenido cada peso y sesgo en el error de las predicciones.\n\n4. Modificar ligeramente los pesos y sesgos de la red (de forma proporcional a su responsabilidad en el error) en la dirección correcta para que se reduzca el error.\n\n5. Repetir los pasos 2, 3, 4 y 5 hasta que la red sea suficientemente buena.\n\n. . .\n\nSi bien la idea parece sencilla, alcanzar una forma de implementarla ha requerido la combinación de múltiples métodos matemáticos, en particular, *backward* y *forward propagation*.\n\n## Backpropagation \n\n*Backpropagation* es el algoritmo que permite cuantificar la influencia que tiene cada peso y sesgo en las predicciones de la red. Para conseguirlo, hace uso de la **regla de la cadena** para calcular el gradiente, que no es más que el vector formado por las derivadas parciales de una función.\n\nEn el caso de las redes, la derivada parcial del error respecto a un parámetro (peso o sesgo) mide cuánta \n*responsabilidad* ha tenido ese parámetro en el error cometido. Gracias a esto, se puede identificar qué pesos de la red hay que modificar para mejorarla. El siguiente paso necesario, es determinar cuánto y cómo modificarlos (optimización).\n\n## Prepocesamiento de variables\n\nA la hora de entrenar modelos basados en redes neuronales, es necesario aplicar a los datos, al menos, dos tipos de transformaciones.\n\n- **Binarización (one hot encoding) de las variables categóricas**: La binarización consiste en crear nuevas variables *dummy* con cada uno de los niveles de las variables cualitativas. Este proceso es el mismo realizado en modelos lineales.\n\n- **Estandarización y escalado de variables numéricas**: Cuando los predictores son numéricos, la escala en la que se miden, así como la magnitud de su varianza pueden influir en gran medida en el modelo. Si no se igualan de alguna forma los predictores, aquellos que se midan en una escala mayor o que tengan más varianza dominarán el modelo aunque no sean los que más relación tienen con la variable respuesta. Para ello, en general centramos los datos, y estandarizamos o reescalamos entre 0 y 1.\n\n# Hiperparámetros\n\nLa gran “flexibilidad” que tienen las redes neuronales es un arma de doble filo. Por un lado, son capaces de generar modelos que aprenden relaciones muy complejas, sin embargo, sufren fácilmente el problema de sobreajuste (*overfitting*) lo que las **incapacita al tratar de predecir nuevas observaciones**.\n\nLa forma de minimizar este problema y conseguir modelos útiles pasa por configurar de forma adecuada sus **hiperparámetros**. Son muchos los hiperparámetros de un modelo basado en redes y su nomenclatura varía entre implementaciones, sin embargo, los de mayor impacto siempre están presentes:\n\n- Número y tamaño de capas\n\n- *Learning rate* \n\n- Algoritmo de optimización\n\n- Regularización\n\n## Número y tamaño de capas\n\nLa arquitectura de una red, el número de capas y el número de neuronas que forman parte de cada capa, determinan en gran medida la complejidad del modelo y con ello su potencial capacidad de aprendizaje.\n\nLa capa de entrada y salida son sencillas de establecer. La capa de entrada tiene tantas neuronas como predictores y la capa de salida tiene una neurona en problemas de regresión y tantas como clases en problemas de clasificación. En la mayoría de implementaciones, estos valores se establecen automáticamente en función del conjunto de entrenamiento. El usuario suele especificar únicamente el número de capas intermedias (ocultas) y el tamaño de las mismas.\n\nCuantas más neuronas y capas, mayor la complejidad de las relaciones que puede aprender el modelo. Sin embargo, dado que cada neurona está conectada por pesos al resto de neuronas de las capas adyacentes, el número de parámetros a aprender aumenta y con ello el tiempo de entrenamiento.\n\n## Learning rate\n\nEl *learning rate* o tasa de aprendizaje establece cuan rápido pueden cambiar los parámetros de un modelo a medida que se optimiza (aprende). Este hiperparámetro es uno de los más complicados de establecer, ya que depende mucho de los datos e interactúa con el resto de hiperparámetros. Si el *learning rate* es muy grande, el proceso de optimización puede ir saltando de una región a otra sin que el modelo sea capaz de aprender. Si por el contrario, el learning rate es muy pequeño, el proceso de entrenamiento puede tardar demasiado y no llegar a completarse. Algunas de las recomendaciones **heurísticas** basadas en prueba y error son:\n\n- Utilizar un *learning rate* lo más pequeño posible siempre y cuando el tiempo de entrenamiento no supere las limitaciones temporales disponibles.\n\n- No utilizar un valor constante de *learning rate* durante todo el proceso de entrenamiento. Por lo general, utilizar valores mayores al inicio y pequeños al final.\n\n## Algoritmo de optimización\n\nEl descenso de gradiente y el descenso de gradiente estocástico fueron de los primeros métodos de optimización utilizados para entrenar modelos de redes neuronales. Ambos utilizan **directamente el gradiente** para dirigir la optimización. Pronto se vio que esto genera problemas a medida que las redes aumentan de tamaño (neuronas y capas). \n\nEn muchas regiones del espacio de búsqueda, el gradiente es muy próximo a cero, lo que hace que la optimización quede estancada. Para evitar este problema, se han desarrollado modificaciones del descenso de gradiente capaces de adaptar el *learning rate* en función del gradiente y subgradiente. De esta forma, el proceso de aprendizaje se ralentiza o acelera dependiendo de las características de la región del espacio de búsqueda en el que se encuentren. Aunque existen multitud de adaptaciones, suele recomendarse:\n\n- Para conjuntos de datos pequeños: **l-bfgs** (*limited memory bfgs*)\n\n- Para conjuntos de datos grandes: **adam o rmsprop** (*root mean square propagation*)\n\n. . .\n\nLa elección del algoritmo de optimización puede tener un impacto notable en el aprendizaje de los modelos, sobre todo en *deep learning*.\n\n## Regularización\n\nLos métodos de regularización tienen el objetivo de reducir el sobreajuste (*overfitting*) de los modelos. Un modelo con sobreajuste memoriza los datos de entrenamiento pero es incapaz de predecir correctamente nuevas observaciones.\n\nLos modelos de redes neuronales pueden considerarse como **modelos sobre-parametrizados**, por lo tanto, las estrategias de regularización son fundamentales. \n\nDe entre las muchas que existen, destacan la regularización **L1** y **L2** (*weight decay*) y el *dropout*.\n\n# Ejemplo\n\nUtilizaremos datos del repositorio del *Center for Machine Learning and Intelligent Systems* de la Universidad de California, en particular, el conjunto de datos [**Concrete Compressive Strength Data Sets**](http://archive.ics.uci.edu/ml/datasets/Concrete+Compressive+Strength).\n\n## Ejemplo: continuación\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(readxl)\nconcrete_data<- read_excel(\"db/Concrete_Data.xls\")\nnames(concrete_data)<-c(\"cement\",\"slag\",\"ash\",\"water\",\"superplastic\",\n                        \"coarseagg\",\"fineagg\",\"age\",\"strength\")\nnormalize <- function(x) {\nreturn((x - min(x)) / (max(x) - min(x)))\n}\nhead(concrete_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 9\n  cement  slag   ash water superplastic coarseagg fineagg   age strength\n   <dbl> <dbl> <dbl> <dbl>        <dbl>     <dbl>   <dbl> <dbl>    <dbl>\n1   540     0      0   162          2.5     1040     676     28     80.0\n2   540     0      0   162          2.5     1055     676     28     61.9\n3   332.  142.     0   228          0        932     594    270     40.3\n4   332.  142.     0   228          0        932     594    365     41.1\n5   199.  132.     0   192          0        978.    826.   360     44.3\n6   266   114      0   228          0        932     670     90     47.0\n```\n:::\n:::\n\n\n## Ejemplo: continuación\n\n\n::: {.cell}\n\n```{.r .cell-code}\nconcrete_data_norm <- as.data.frame(lapply(concrete_data, normalize))\nsummary(concrete_data_norm$strength)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.0000  0.2663  0.4000  0.4172  0.5457  1.0000 \n```\n:::\n\n```{.r .cell-code}\nsummary(concrete_data$strength)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  2.332  23.707  34.443  35.818  46.136  82.599 \n```\n:::\n:::\n\n\nDebido a que los datos ya están ordenamos aleatoriamente, simplemente dividimos en dos partes de 75 y 25 porciento, respectivamente.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nconcrete_train <- concrete_data_norm[1:773, ]\nconcrete_test <- concrete_data_norm[774:1030, ]\n```\n:::\n\n\n## Ejemplo: continuación\n\nEl siguiente modelo sería un **simple multilayer feedfoward network**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(neuralnet)\nset.seed(411)\nconcrete_model <- neuralnet(strength ~ cement + slag + \n                            ash + water + superplastic \n                            + coarseagg + fineagg + age,\n                            data = concrete_train)\n```\n:::\n\n\n## Ejemplo: continuación\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nplot(concrete_model, rep=\"best\")\n```\n\n::: {.cell-output-display}\n![](lec_week11_files/figure-revealjs/unnamed-chunk-5-1.png){fig-align='center' width=960}\n:::\n:::\n\n\n## Ejemplo: continuación\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_results <- compute(concrete_model, concrete_test[1:8])\npredicted_strength <- model_results$net.result\ncor(predicted_strength, concrete_test$strength)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n          [,1]\n[1,] 0.7209429\n```\n:::\n:::\n\n\n**Debido a que es un problema de predicción, no podemos realizar una matriz de confusión para determinar el nivel de precisión**\n\n## Ejemplo: continuación\n\nEn el siguiente modelo, ampliaremos la cantidad de neuronas.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nconcrete_model2 <- neuralnet(strength ~ cement + slag +\n                               ash + water + superplastic +\n                               coarseagg + fineagg + age,\n                             data = concrete_train, hidden = 5)\n```\n:::\n\n\n## Ejemplo: continuación\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nplot(concrete_model2, rep=\"best\")\n```\n\n::: {.cell-output-display}\n![](lec_week11_files/figure-revealjs/unnamed-chunk-8-1.png){fig-align='center' width=960}\n:::\n:::\n\n\n## Ejemplo: continuación\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_results2 <- compute(concrete_model2, concrete_test[1:8])\npredicted_strength2 <- model_results2$net.result\ncor(predicted_strength2, concrete_test$strength)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n          [,1]\n[1,] 0.8138362\n```\n:::\n:::\n\n\n## Ejemplo: continuación\n\nEn este problema no podemos utilizar una función de activación **Rectified linear unit (ReLU)** debido a que no tiene derivada en $x=0$. Alternativamente, utilizamos una función de activación llamada **softplus** o **Smooth ReLI**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsoftplus <- function(x) { log(1 + exp(x)) }\nconcrete_model3 <- neuralnet(strength ~ cement + slag +\n                               ash + water + superplastic +\n                               coarseagg + fineagg + age,\n                             data = concrete_train,\n                             hidden = c(5, 5), act.fct = softplus)\n```\n:::\n\n\n## Ejemplo: continuación\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nplot(concrete_model3, rep=\"best\")\n```\n\n::: {.cell-output-display}\n![](lec_week11_files/figure-revealjs/unnamed-chunk-11-1.png){fig-align='center' width=960}\n:::\n:::\n\n\n## Ejemplo: continuación\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_results3 <- compute(concrete_model3, concrete_test[1:8])\npredicted_strength3 <- model_results3$net.result\ncor(predicted_strength3, concrete_test$strength)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n          [,1]\n[1,] 0.6761314\n```\n:::\n\n```{.r .cell-code}\nstrengths <- data.frame(actual = concrete_data$strength[774:1030],pred = predicted_strength3)\nhead(strengths, n = 3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n      actual      pred\n774 37.42476 0.4099593\n775 11.46599 0.2406689\n776 22.43555 0.2818004\n```\n:::\n\n```{.r .cell-code}\ncor(strengths$pred, strengths$actual)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.6761314\n```\n:::\n:::\n\n## Ejemplo: continuación\n\n\n::: {.cell}\n\n```{.r .cell-code}\nunnormalize <- function(x) {\nreturn((x * (max(concrete_data$strength)) -\nmin(concrete_data$strength)) + min(concrete_data$strength))\n}\nstrengths$pred_new <- unnormalize(strengths$pred)\nstrengths$error <- strengths$pred_new - strengths$actual\nhead(strengths, n = 3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n      actual      pred pred_new      error\n774 37.42476 0.4099593 33.86232 -3.5624375\n775 11.46599 0.2406689 19.87906  8.4130769\n776 22.43555 0.2818004 23.27650  0.8409468\n```\n:::\n\n```{.r .cell-code}\ncor(strengths$pred_new, strengths$actual)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.6761314\n```\n:::\n:::\n\n\n# ¿Qué veremos la próxima semana?\n\n- Redes neuronales convolucionales\n\n# ¿Que deben preparar para la próxima semana?\n\n- Avanzar con el trabajo final\n\n",
    "supporting": [
      "lec_week11_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\r\n<script>\r\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\r\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\r\n  // slide changes (different for each slide format).\r\n  (function () {\r\n    function fireSlideChanged(previousSlide, currentSlide) {\r\n\r\n      // dispatch for htmlwidgets\r\n      const event = window.document.createEvent(\"Event\");\r\n      event.initEvent(\"slideenter\", true, true);\r\n      window.document.dispatchEvent(event);\r\n\r\n      // dispatch for shiny\r\n      if (window.jQuery) {\r\n        if (previousSlide) {\r\n          window.jQuery(previousSlide).trigger(\"hidden\");\r\n        }\r\n        if (currentSlide) {\r\n          window.jQuery(currentSlide).trigger(\"shown\");\r\n        }\r\n      }\r\n    }\r\n\r\n    // hookup for reveal\r\n    if (window.Reveal) {\r\n      window.Reveal.addEventListener(\"slidechanged\", function(event) {\r\n        fireSlideChanged(event.previousSlide, event.currentSlide);\r\n      });\r\n    }\r\n\r\n    // hookup for slidy\r\n    if (window.w3c_slidy) {\r\n      window.w3c_slidy.add_observer(function (slide_num) {\r\n        // slide_num starts at position 1\r\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\r\n      });\r\n    }\r\n\r\n  })();\r\n</script>\r\n\r\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}
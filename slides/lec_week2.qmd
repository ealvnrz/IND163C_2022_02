---
title: "Conceptos Básicos"
subtitle: "IND 163 - 2022/02"
author: "Eloy Alvarado Narváez"
institute: "Universidad Técnica Federico Santa María"
date: 26/08/22
format: 
  revealjs:
    theme: slides.scss
    touch: true
    slide-level: 2
    code-copy: true
incremental: true
slide-number: true
lang: es
highlight-style: github
width: 1600
height: 900
logo: images/logo_usm.png
transition: fade
footer: "IND 163 - Semana 2"
execute:
  freeze: auto
---

# Conceptos básicos de probabilidad

## Escuelas de Probabilidad

-   Enfoque clásico
-   Enfoque frecuentista
-   Enfoque bayesiano

## Enfoque clásico

Este enfoque también llamado enfoque *apriori* tiene por característica principal la asignación igualitaria de una medida de ocurrencia para un resultado de un experimento aleatorio (experimento equiprobable).

. . .

Esta asignación de *probabilidad* se determina antes de observar los resultados experimentales.

. . .

-   **¿Algún ejemplo?**

## Enfoque frecuentista

Este enfoque también llamado enfoque *empírico*, determina la medida de ocurrencia con base en la proporción de veces que ocurre un resultado *favorable* en un determinado número de observaciones o experimentos. Este enfoque no asigna probabilidades *a priori* a los posibles resultados de un experimento aleatorio.

. . .

-   **¿Algún ejemplo?**

## Enfoque bayesiano

Este enfoque también llamado enfoque *subjetivo*, determina la medida de ocurrencia en base a una *expectativa razonable* basado en el conocimiento del investigador.

El enfoque bayesiano es particularmente útil cuando se tiene poca información del experimento, y este puede ser realizado para *actualizador* mis probabilidades, esto debido a que cada realización del experimento aleatorio me otorgará información adicional para determinar correctamente mis probabilidades.

## Conceptos fundamentales

-   **Espacio muestral:** Se define como el conjunto de todos los posibles resultados del experimento, lo anotamos por $\Omega$.
-   **Suceso o evento:** Es cualquier subconjunto de $\Omega$, usualmente lo anotamos con letras mayúsculas. $(A,B,C,\dots)$.
-   **Espacio de sucesos:** Es el conjunto de todos los subconjuntos de $\Omega$. Lo anotamos por $2^{\Omega}$.
-   $\sigma$-álgebra: Es una familia de subconjuntos del espacio de sucesos, $\Sigma \subset 2^{\Omega}$, y que cumplen con *ciertas propiedades*.

## Clasificación del espacio muestral

-   **Discreto**
    -   **Numerable:** Finito o Infinito.
-   **Continuo**
    -   **No numerable:** Acotado o No acotado.

## Definición formal de probabilidad

El par $(\Omega,\Sigma)$ se dice *espacio medible*, y la función $\mathbb{P}:\Sigma \rightarrow \mathbb{R}^{+}$, es una **medida de probabilidad** si satisface:

1.  $0\leq \mathbb{P}[A] \leq 1, \forall A \in \Sigma$
2.  $\mathbb{P}[\Omega]=1$
3.  Dados $\displaystyle A_1,A_2,\dots \in \Sigma \Rightarrow \mathbb{P}\left[ \bigcup_{i=1}^{n} A_n \right] = \sum_{i=1}^{n} \mathbb{P}[A_i], \hspace{5pt} \forall i$

## Algunas propiedades

1.  $\mathbb{P}[A]+\mathbb{P}[A^c]=\mathbb{P}[\Omega]$
2.  $\mathbb{P}[\phi]=1-\mathbb{P}[\phi^c]=1-\mathbb{P}[\Omega]=0$
3.  $\mathbb{P}[A \cup B]=\mathbb{P}[A]+\mathbb{P}[B] - \mathbb{P}[A\cap B]$ . Si este último término $(\mathbb{P}[A\cap B])$ es cero, se dice que $A$ y $B$ son eventos mutuamente excluyentes.
4.  $\mathbb{P}[A-B]=\mathbb{P}[A\cap B^c]$
5.  $\mathbb{P}[A \cap B]=\mathbb{P}[A]\mathbb{P}[B]$. Si $A$ y $B$ son independientes.

# Variables aleatorias

## Definición Básica

Una **Variable aleatoria**, es una función que permite trabajar cualquier espacio muestral de manera cuantitativa. Se dice que $X$ es una variable aleatoria si es una función que toma los elementos de $\Omega$ y los transforma en puntos sobre la recta de los reales. Esto es:

```{=tex}
\begin{align*}
  X: \quad &\Omega \longrightarrow \mathbb{R}\\
           &\omega \longrightarrow X(\omega)
\end{align*}
```
. . .

El conjunto de todas las posibles realizaciones es llamado el **soporte** y lo denotamos por $R_X$.

## Tipos de variables aleatorias

Se dice que $X$ es una Variable Aleatoria si es una función que toma valores en probabilidad, es decir, no se puede predecir con certeza sus resultados.

**Una variable aleatoria es siempre cuantitativa** y se puede clasificar en los siguientes grupos:

$$X(\omega) \begin{cases}
\text{Discreto}
\begin{cases}
\text{Finito}\\
\text{Infinito}
\end{cases}\\
\text{Continuo}
\begin{cases}
\text{Acotados}\\
\text{No Acotados}
\end{cases}
\end{cases}$$

## Variables aleatorias discretas

Una variable aleatoria $X$ es llamada **discreta** si:

1.  Su soporte $R_X$ es un conjunto *numerable*.
2.  Existe una función $p_X:\mathbb{R}\rightarrow [0,1]$, llamada la **función de masa de probabilidad** de $X$, tal que, para cualquier $x\in \mathbb{R}$:

::: {.fragment}
$$p_X(x)\begin{cases} \mathbb{P}(X=x) \quad &\text{si } x\in R_X\\ 0 \quad &\text{si } x\notin R_X\end{cases}$$
:::

. . . 

Esta función tiene dos características principales:

1. **no-negatividad**: $p_X(x)\geq 0$ para cualquier $x\in \mathbb{R}$.
2. **Suma sobre su soporte es 1**: $\sum_{x\in R_X}p_X(x)=1$

## Variables aleatorias continuas

Una variable aleatoria $X$ es llamada **continua** si:

1. Su soporte $R_X$ es un conjunto *no-numerable*.
2. Existe una función $f_X:\mathbb{R}\rightarrow [0,1]$, llamada **función de densidad de probabilidad** de $X$, tal que, para cualquier intervalo $[a,b]\subseteq \mathbb{R}$:

:::{.fragment}
$$\mathbb{P}(X\in [a,b])=\int_{a}^{b}f_X(x)dx$$
:::

. . . 

Esta función tiene dos características principales:

1. **no-negatividad**: $f_X(x)\geq 0$ para cualquier $x\in \mathbb{R}$.
2. **Integral sobre $\mathbb{R}$ es 1**: $\int_{-\infty}^{\infty} f_X(x)dx=1$.


## Función de distribución

Las variables aleatorias son usualmente caracterizadas en términos de sus funciones de distribución.

. . . 

Sea $X$ una variable aleatoria. La **función de distribución** de $X$ es una función $F_X:\mathbb{R}\rightarrow [0,1]$ tal que:

$$F_X(x)=\mathbb{P}(X\leq x), \forall x\in \mathbb{R}$$

. . .

Si conocemos la función de distribución de una variable aleatoria $X$, entonces podemos fácilmente calcular la probabilidad que $X$ pertenezca a un intervalo $(a,b] \subseteq \mathbb{R}$ como:

$$\mathbb{P}(a<X<b)=F_X(b)-F_X(a)$$

## Valores esperados

Sea $X$ una variable aleatoria, entonces se define el valor esperado de una función real $g(X)$, como:

$$\mathbb{E}[g(X)]= \begin{cases} \sum_{x\in \mathbb{R}} g(X)P(X=x)\\ \int_{x\in \mathbb{R}} g(X)f(x)dx \end{cases}$$


Si $g(X)=X$, diremos que el valor esperado o esperanza matemática de $X$ es:
$$\mathbb{E}(X)=\begin{cases}\sum_{x\in \mathbb{R}} x P(X=x)\\ \int_{x\in \mathbb{R}} x f(x)dx \end{cases}$$

Para variables de tipo discreta y continua, respectivamente.

## Propiedades de los valores esperados

Sean $a$ y $b$ constantes, $X$ una variable aleatoria entonces se cumple que:

- $\mathbb{E}(a)=a$
- $\mathbb{E}(X)=\mu=$ constante
- $\mathbb{E}(aX)=a\mathbb{E}(X)$
- $\mathbb{E}(aX+b)=\mathbb{E}(aX)+\mathbb{E}(b)=a\mathbb{E}(X)+b$

## Varianza

Sea $X$ una variable aleatoria, se define el la **varianza** de $X$ como:

$$\mathbb{E}[(X-\mathbb{E}(X))^2]=V(X)=\begin{cases}\sum_{x\in\mathbb{R}} (X-\mathbb{E}(X))^2P(X=x)\\ \int_{x\in\mathbb{R}}(X-\mathbb{E}(X))^2f_{X}(x)dx\end{cases}$$

Para variables de tipo discreta y continua, respectivamente.

## Propiedades de la varianza

Sea $a$ y $b$ constantes, $X$ una variable aleatoria, entonces se cumple:


- $\mathbb{V}(a)=0$
- $\mathbb{V}(X)=\sigma^2=$ constante
- $\mathbb{V}(aX)=a^2 \mathbb{V}(X)$
- $\mathbb{V}(aX+b)=\mathbb{V}(aX)+\mathbb{V}(b)=a^2\mathbb{V}(X)+0=a^2\mathbb{V}(X)$
- $\mathbb{V}(X)=\mathbb{E}(X^2)-(\mathbb{E}(X))^2$

# Distribuciones discretas

## Distribución binomial 

Sea $X$ una variable aleatoria que representa el número de éxitos en $n$ ensayos y $p$ la probabilidad de éxito con cualquiera de éstos. Se dice entonces que $X$ tiene una distribución binomial con función de probabilidad:

$$\mathbb{P}(X=k)= {{n}\choose{k}}p^k(1-p)^{n-k} \hspace{20pt} k=1,2,\cdots,n$$
En donde ${{n}\choose{k}}$ es el coeficiente binomial, esto es: 

$${{n}\choose{k}}=\dfrac{n!}{k!(n-k)!}$$

Si $n=1$ diremos que $X$ sigue una distribución Bernoulli.

## Propiedades de la distribución binomial

Si $X$ tiene una distribución binomial, entonces se cumple que:

- $\mathbb{E}[X]=np$
- $\mathbb{V}[X]=np(1-p)$

. . . 

Es claro ver que si $X$ tiene una distribución bernoulli, entonces:

- $\mathbb{E}[X]=p$
- $\mathbb{V}[X]=p(1-p)$

## Distribución binomial en R 

```{r}
#| echo: false
library(reticulate)
#use_python("C:/Users/Eloy/AppData/Local/Programs/Python/Python39")
#py_install("numpy")
#py_install("matplotlib")
#py_install("scipy")
```


::: {.panel-tabset}

### Código

```{r}
#| echo: TRUE
#| eval: FALSE
#| code-line-numbers: "1|2|3|4|5|6|7"
set.seed(163)
dbinom(x = 2, size = 10, prob = 0.3)
mean(rbinom(n = 10000, size = 10, prob = 0.3) == 2)
pbinom(q = 5, size = 10, p = 0.3, lower.tail = TRUE)
mean(rbinom(n = 10000, size = 10, prob = 0.3) <= 5)
pbinom(q = 4, size = 10, p = 0.3, lower.tail  = FALSE)
mean(rbinom(n = 10000, size = 10, prob = 0.3) >= 5)
```


### Salidas

```{r}
#| echo: TRUE
#| eval: TRUE
set.seed(163)
dbinom(x = 2, size = 10, prob = 0.3)
mean(rbinom(n = 10000, size = 10, prob = 0.3) == 2)
pbinom(q = 5, size = 10, p = 0.3, lower.tail = TRUE)
mean(rbinom(n = 10000, size = 10, prob = 0.3) <= 5)
pbinom(q = 4, size = 10, p = 0.3, lower.tail  = FALSE)
mean(rbinom(n = 10000, size = 10, prob = 0.3) >= 5)
```
:::

## Distribución binomial en Python


::: {.panel-tabset}

### Código

```{.python code-line-numbers="1-3|5|6|7|8|9|10|11"}
import numpy as np
import matplotlib.pyplot as plt
from scipy.stats import binom

np.random.seed(163)
binom.pmf(2, n=10, p=0.3)
sum(np.random.binomial(10, 0.3, 10000) == 2)/10000
binom.cdf(5, n=10, p=0.3)
sum(np.random.binomial(10, 0.3, 10000) <= 5)/10000
1-binom.cdf(4, n=10, p=0.3)
sum(np.random.binomial(10, 0.3, 10000) >= 5)/10000
```

### Salidas

```{python}
#| echo: TRUE
#| eval: TRUE
import numpy as np
import matplotlib.pyplot as plt
from scipy.stats import binom

np.random.seed(163)
binom.pmf(2, n=10, p=0.3)
sum(np.random.binomial(10, 0.3, 10000) == 2)/10000
binom.cdf(5, n=10, p=0.3)
sum(np.random.binomial(10, 0.3, 10000) <= 5)/10000
1-binom.cdf(4, n=10, p=0.3)
sum(np.random.binomial(10, 0.3, 10000) >= 5)/10000
```

:::

## Distribución de Poisson

Sea $X$ una variable aleatoria que representa el número de eventos aleatorios independientes que ocurren a una rapidez constante sobre el tiempo o el espacio. Se dice entonces que la variable aleatoria $X$ tiene una distribución de Poisson con función de probabilidad:

$$\mathbb{P}(X=k)=\dfrac{e^{-\lambda}\lambda^k}{k!} \hspace{20pt} k=0,1,\cdots,n,\cdots$$

En donde $\lambda>0$ representa el número promedio de ocurrencias del evento aleatorio por unidad de tiempo. Además, si $X$ sigue una distribución de Poisson se cumple que:

- $\mathbb{E}[X]=\lambda$
- $\mathbb{V}[X]=\lambda$

## Distribución de Poisson en R

::: {.panel-tabset}

### Código

```{r}
#| echo: TRUE
#| eval: FALSE
#| code-line-numbers: "1|2|3|4|5|6|7"
set.seed(163)
dpois(x = 7, 5)
mean(rpois(n = 10000, 5) == 7)
ppois(q = 5, 5, lower.tail = TRUE)
mean(rpois(n = 10000, 5) <= 5)
ppois(q = 4, 5, lower.tail  = FALSE)
mean(rpois(n = 10000,5) >= 5)
```
### Salidas

```{r}
#| echo: TRUE
#| eval: TRUE
set.seed(163)
dpois(x = 7, 5)
mean(rpois(n = 10000, 5) == 7)
ppois(q = 5, 5, lower.tail = TRUE)
mean(rpois(n = 10000, 5) <= 5)
ppois(q = 4, 5, lower.tail  = FALSE)
mean(rpois(n = 10000,5) >= 5)
```

:::

## Distribución de Poisson en Python

::: {.panel-tabset}

### Código

```{.python code-line-numbers="1-3|5|6|7|8|9|10|11"}
import numpy as np
import matplotlib.pyplot as plt
from scipy.stats import poisson

np.random.seed(163)
poisson.pmf(2, n=10, p=0.3)
sum(np.random.binomial(10, 0.3, 10000) == 2)/10000
binom.cdf(5, n=10, p=0.3)
sum(np.random.binomial(10, 0.3, 10000) <= 5)/10000
1-binom.cdf(4, n=10, p=0.3)
sum(np.random.binomial(10, 0.3, 10000) >= 5)/10000
```

### Salidas

```{python}
#| echo: TRUE
#| eval: TRUE
import numpy as np
import matplotlib.pyplot as plt
from scipy.stats import poisson

np.random.seed(163)
poisson.pmf(7, 5)
sum(np.random.poisson(5, 10000) == 7)/10000
poisson.cdf(7, 5)
sum(np.random.poisson(5, 10000) <= 7)/10000
1-poisson.cdf(6, 5)
sum(np.random.poisson(5, 10000) >= 7)/10000
```

:::



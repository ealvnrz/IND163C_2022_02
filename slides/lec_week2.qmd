---
title: "Conceptos Básicos"
subtitle: "IND 163 - 2022/02"
author: "Eloy Alvarado Narváez"
institute: "Universidad Técnica Federico Santa María"
date: 26/08/22
format: 
  revealjs:
    theme: slides.scss
    touch: true
    slide-level: 2
    code-copy: true
incremental: true
slide-number: true
lang: es
highlight-style: github
width: 1600
height: 900
logo: images/logo_usm.png
transition: fade
footer: "IND 163 - Semana 2"
execute:
  freeze: auto
---

# Conceptos básicos de probabilidad

## Escuelas de probabilidad

-   Enfoque clásico
-   Enfoque frecuentista
-   Enfoque bayesiano

## Enfoque clásico

Este enfoque también llamado enfoque *apriori* tiene por característica principal la asignación igualitaria de una medida de ocurrencia para un resultado de un experimento aleatorio (experimento equiprobable).

. . .

Esta asignación de *probabilidad* se determina antes de observar los resultados experimentales.

. . .

-   **¿Algún ejemplo?**

## Enfoque frecuentista

Este enfoque también llamado enfoque *empírico*, determina la medida de ocurrencia con base en la proporción de veces que ocurre un resultado *favorable* en un determinado número de observaciones o experimentos. Este enfoque no asigna probabilidades *a priori* a los posibles resultados de un experimento aleatorio.

. . .

-   **¿Algún ejemplo?**

## Enfoque bayesiano

Este enfoque también llamado enfoque *subjetivo*, determina la medida de ocurrencia en base a una *expectativa razonable* basado en el conocimiento del investigador.

El enfoque bayesiano es particularmente útil cuando se tiene poca información del experimento, y este puede ser realizado para *actualizador* mis probabilidades, esto debido a que cada realización del experimento aleatorio me otorgará información adicional para determinar correctamente mis probabilidades.

## Conceptos fundamentales

-   **Espacio muestral:** Se define como el conjunto de todos los posibles resultados del experimento, lo anotamos por $\Omega$.
-   **Suceso o evento:** Es cualquier subconjunto de $\Omega$, usualmente lo anotamos con letras mayúsculas. $(A,B,C,\dots)$.
-   **Espacio de sucesos:** Es el conjunto de todos los subconjuntos de $\Omega$. Lo anotamos por $2^{\Omega}$.
-   $\sigma$-álgebra: Es una familia de subconjuntos del espacio de sucesos, $\Sigma \subset 2^{\Omega}$, y que cumplen con *ciertas propiedades*.

## Clasificación del espacio muestral

-   **Discreto**
    -   **Numerable:** Finito o Infinito.
-   **Continuo**
    -   **No numerable:** Acotado o No acotado.

## Definición formal de probabilidad

El par $(\Omega,\Sigma)$ se dice *espacio medible*, y la función $\mathbb{P}:\Sigma \rightarrow \mathbb{R}^{+}$, es una **medida de probabilidad** si satisface:

1.  $0\leq \mathbb{P}[A] \leq 1, \forall A \in \Sigma$
2.  $\mathbb{P}[\Omega]=1$
3.  Dados $\displaystyle A_1,A_2,\dots \in \Sigma \Rightarrow \mathbb{P}\left[ \bigcup_{i=1}^{n} A_n \right] = \sum_{i=1}^{n} \mathbb{P}[A_i], \hspace{5pt} \forall i$

## Algunas propiedades

1.  $\mathbb{P}[A]+\mathbb{P}[A^c]=\mathbb{P}[\Omega]$
2.  $\mathbb{P}[\phi]=1-\mathbb{P}[\phi^c]=1-\mathbb{P}[\Omega]=0$
3.  $\mathbb{P}[A \cup B]=\mathbb{P}[A]+\mathbb{P}[B] - \mathbb{P}[A\cap B]$ . Si este último término $(\mathbb{P}[A\cap B])$ es cero, se dice que $A$ y $B$ son eventos mutuamente excluyentes.
4.  $\mathbb{P}[A-B]=\mathbb{P}[A\cap B^c]$
5.  $\mathbb{P}[A \cap B]=\mathbb{P}[A]\mathbb{P}[B]$. Si $A$ y $B$ son independientes.

# Variables aleatorias

## Definición Básica

Una **Variable aleatoria**, es una función que permite trabajar cualquier espacio muestral de manera cuantitativa. Se dice que $X$ es una variable aleatoria si es una función que toma los elementos de $\Omega$ y los transforma en puntos sobre la recta de los reales. Esto es:

```{=tex}
\begin{align*}
  X: \quad &\Omega \longrightarrow \mathbb{R}\\
           &\omega \longrightarrow X(\omega)
\end{align*}
```
. . .

El conjunto de todas las posibles realizaciones es llamado el **soporte** y lo denotamos por $R_X$.

## Tipos de variables aleatorias

Se dice que $X$ es una Variable Aleatoria si es una función que toma valores en probabilidad, es decir, no se puede predecir con certeza sus resultados.

**Una variable aleatoria es siempre cuantitativa** y se puede clasificar en los siguientes grupos:

$$X(\omega) \begin{cases}
\text{Discreto}
\begin{cases}
\text{Finito}\\
\text{Infinito}
\end{cases}\\
\text{Continuo}
\begin{cases}
\text{Acotados}\\
\text{No Acotados}
\end{cases}
\end{cases}$$

## Variables aleatorias discretas

Una variable aleatoria $X$ es llamada **discreta** si:

1.  Su soporte $R_X$ es un conjunto *numerable*.
2.  Existe una función $p_X:\mathbb{R}\rightarrow [0,1]$, llamada la **función de masa de probabilidad** de $X$, tal que, para cualquier $x\in \mathbb{R}$:

::: {.fragment}
$$p_X(x)\begin{cases} \mathbb{P}(X=x) \quad &\text{si } x\in R_X\\ 0 \quad &\text{si } x\notin R_X\end{cases}$$
:::

. . . 

Esta función tiene dos características principales:

1. **no-negatividad**: $p_X(x)\geq 0$ para cualquier $x\in \mathbb{R}$.
2. **Suma sobre su soporte es 1**: $\sum_{x\in R_X}p_X(x)=1$

## Variables aleatorias continuas

Una variable aleatoria $X$ es llamada **continua** si:

1. Su soporte $R_X$ es un conjunto *no-numerable*.
2. Existe una función $f_X:\mathbb{R}\rightarrow [0,1]$, llamada **función de densidad de probabilidad** de $X$, tal que, para cualquier intervalo $[a,b]\subseteq \mathbb{R}$:

:::{.fragment}
$$\mathbb{P}(X\in [a,b])=\int_{a}^{b}f_X(x)dx$$
:::

. . . 

Esta función tiene dos características principales:

1. **no-negatividad**: $f_X(x)\geq 0$ para cualquier $x\in \mathbb{R}$.
2. **Integral sobre $\mathbb{R}$ es 1**: $\int_{-\infty}^{\infty} f_X(x)dx=1$.


## Función de distribución

Las variables aleatorias son usualmente caracterizadas en términos de sus funciones de distribución.

. . . 

Sea $X$ una variable aleatoria. La **función de distribución** de $X$ es una función $F_X:\mathbb{R}\rightarrow [0,1]$ tal que:

$$F_X(x)=\mathbb{P}(X\leq x), \forall x\in \mathbb{R}$$

. . .

Si conocemos la función de distribución de una variable aleatoria $X$, entonces podemos fácilmente calcular la probabilidad que $X$ pertenezca a un intervalo $(a,b] \subseteq \mathbb{R}$ como:

$$\mathbb{P}(a<X<b)=F_X(b)-F_X(a)$$

## Valores esperados

Sea $X$ una variable aleatoria, entonces se define el valor esperado de una función real $g(X)$, como:

$$\mathbb{E}[g(X)]= \begin{cases} \sum_{x\in \mathbb{R}} g(X)P(X=x)\\ \int_{x\in \mathbb{R}} g(X)f(x)dx \end{cases}$$


Si $g(X)=X$, diremos que el valor esperado o esperanza matemática de $X$ es:
$$\mathbb{E}(X)=\begin{cases}\sum_{x\in \mathbb{R}} x P(X=x)\\ \int_{x\in \mathbb{R}} x f(x)dx \end{cases}$$

Para variables de tipo discreta y continua, respectivamente.

## Propiedades de los valores esperados

Sean $a$ y $b$ constantes, $X$ una variable aleatoria entonces se cumple que:

- $\mathbb{E}(a)=a$
- $\mathbb{E}(X)=\mu=$ constante
- $\mathbb{E}(aX)=a\mathbb{E}(X)$
- $\mathbb{E}(aX+b)=\mathbb{E}(aX)+\mathbb{E}(b)=a\mathbb{E}(X)+b$

## Varianza

Sea $X$ una variable aleatoria, se define el la **varianza** de $X$ como:

$$\mathbb{E}[(X-\mathbb{E}(X))^2]=V(X)=\begin{cases}\sum_{x\in\mathbb{R}} (X-\mathbb{E}(X))^2P(X=x)\\ \int_{x\in\mathbb{R}}(X-\mathbb{E}(X))^2f_{X}(x)dx\end{cases}$$

Para variables de tipo discreta y continua, respectivamente.

## Propiedades de la varianza

Sea $a$ y $b$ constantes, $X$ una variable aleatoria, entonces se cumple:


- $\mathbb{V}(a)=0$
- $\mathbb{V}(X)=\sigma^2=$ constante
- $\mathbb{V}(aX)=a^2 \mathbb{V}(X)$
- $\mathbb{V}(aX+b)=\mathbb{V}(aX)+\mathbb{V}(b)=a^2\mathbb{V}(X)+0=a^2\mathbb{V}(X)$
- $\mathbb{V}(X)=\mathbb{E}(X^2)-(\mathbb{E}(X))^2$

# Distribuciones discretas

## Distribución binomial 

Sea $X$ una variable aleatoria que representa el número de éxitos en $n$ ensayos y $p$ la probabilidad de éxito con cualquiera de éstos. Se dice entonces que $X$ tiene una distribución binomial con función de probabilidad:

$$\mathbb{P}(X=k)= {{n}\choose{k}}p^k(1-p)^{n-k} \hspace{20pt} k=1,2,\cdots,n$$
En donde ${{n}\choose{k}}$ es el coeficiente binomial, esto es: 

$${{n}\choose{k}}=\dfrac{n!}{k!(n-k)!}$$

Si $n=1$ diremos que $X$ sigue una distribución Bernoulli.

## Propiedades de la distribución binomial

Si $X$ tiene una distribución binomial, entonces se cumple que:

- $\mathbb{E}[X]=np$
- $\mathbb{V}[X]=np(1-p)$

. . . 

Es claro ver que si $X$ tiene una distribución bernoulli, entonces:

- $\mathbb{E}[X]=p$
- $\mathbb{V}[X]=p(1-p)$

## Distribución binomial en R 

```{r}
#| echo: false
library(reticulate)
#use_python("C:/Users/Eloy/AppData/Local/Programs/Python/Python39")
#py_install("numpy")
#py_install("matplotlib")
#py_install("scipy")
```


::: {.panel-tabset}

### Código

```{r}
#| echo: TRUE
#| eval: FALSE
#| code-line-numbers: "1|2|3|4|5|6|7"
set.seed(163)
dbinom(x = 2, size = 10, prob = 0.3)
mean(rbinom(n = 10000, size = 10, prob = 0.3) == 2)
pbinom(q = 5, size = 10, p = 0.3, lower.tail = TRUE)
mean(rbinom(n = 10000, size = 10, prob = 0.3) <= 5)
pbinom(q = 4, size = 10, p = 0.3, lower.tail  = FALSE)
mean(rbinom(n = 10000, size = 10, prob = 0.3) >= 5)
```


### Salidas

```{r}
#| echo: TRUE
#| eval: TRUE
set.seed(163)
dbinom(x = 2, size = 10, prob = 0.3)
mean(rbinom(n = 10000, size = 10, prob = 0.3) == 2)
pbinom(q = 5, size = 10, p = 0.3, lower.tail = TRUE)
mean(rbinom(n = 10000, size = 10, prob = 0.3) <= 5)
pbinom(q = 4, size = 10, p = 0.3, lower.tail  = FALSE)
mean(rbinom(n = 10000, size = 10, prob = 0.3) >= 5)
```
:::

## Distribución binomial en Python


::: {.panel-tabset}

### Código

```{.python code-line-numbers="1-3|5|6|7|8|9|10|11"}
import numpy as np
import matplotlib.pyplot as plt
from scipy.stats import binom

np.random.seed(163)
binom.pmf(2, n=10, p=0.3)
sum(np.random.binomial(10, 0.3, 10000) == 2)/10000
binom.cdf(5, n=10, p=0.3)
sum(np.random.binomial(10, 0.3, 10000) <= 5)/10000
1-binom.cdf(4, n=10, p=0.3)
sum(np.random.binomial(10, 0.3, 10000) >= 5)/10000
```

### Salidas

```{python}
#| echo: TRUE
#| eval: TRUE
import numpy as np
import matplotlib.pyplot as plt
from scipy.stats import binom

np.random.seed(163)
binom.pmf(2, n=10, p=0.3)
sum(np.random.binomial(10, 0.3, 10000) == 2)/10000
binom.cdf(5, n=10, p=0.3)
sum(np.random.binomial(10, 0.3, 10000) <= 5)/10000
1-binom.cdf(4, n=10, p=0.3)
sum(np.random.binomial(10, 0.3, 10000) >= 5)/10000
```

:::

## Distribución de Poisson

Sea $X$ una variable aleatoria que representa el número de eventos aleatorios independientes que ocurren a una rapidez constante sobre el tiempo o el espacio. Se dice entonces que la variable aleatoria $X$ tiene una distribución de Poisson con función de probabilidad:

$$\mathbb{P}(X=k)=\dfrac{e^{-\lambda}\lambda^k}{k!} \hspace{20pt} k=0,1,\cdots,n,\cdots$$

En donde $\lambda>0$ representa el número promedio de ocurrencias del evento aleatorio por unidad de tiempo. Además, si $X$ sigue una distribución de Poisson se cumple que:

- $\mathbb{E}[X]=\lambda$
- $\mathbb{V}[X]=\lambda$

## Distribución de Poisson en R

::: {.panel-tabset}

### Código

```{r}
#| echo: TRUE
#| eval: FALSE
#| code-line-numbers: "1|2|3|4|5|6|7"
set.seed(163)
dpois(x = 7, 5)
mean(rpois(n = 10000, 5) == 7)
ppois(q = 5, 5, lower.tail = TRUE)
mean(rpois(n = 10000, 5) <= 5)
ppois(q = 4, 5, lower.tail  = FALSE)
mean(rpois(n = 10000,5) >= 5)
```
### Salidas

```{r}
#| echo: TRUE
#| eval: TRUE
set.seed(163)
dpois(x = 7, 5)
mean(rpois(n = 10000, 5) == 7)
ppois(q = 5, 5, lower.tail = TRUE)
mean(rpois(n = 10000, 5) <= 5)
ppois(q = 4, 5, lower.tail  = FALSE)
mean(rpois(n = 10000,5) >= 5)
```

:::

## Distribución de Poisson en Python

::: {.panel-tabset}

### Código

```{.python code-line-numbers="1-2|4|5|6|7|8|9|10"}
import numpy as np
from scipy.stats import poisson

np.random.seed(163)
poisson.pmf(7, 5)
sum(np.random.poisson(5, 10000) == 7)/10000
poisson.cdf(7, 5)
sum(np.random.poisson(5, 10000) <= 7)/10000
1-poisson.cdf(6, 5)
sum(np.random.poisson(5, 10000) >= 7)/10000
```

### Salidas

```{python}
#| echo: TRUE
#| eval: TRUE
import numpy as np
from scipy.stats import poisson

np.random.seed(163)
poisson.pmf(7, 5)
sum(np.random.poisson(5, 10000) == 7)/10000
poisson.cdf(7, 5)
sum(np.random.poisson(5, 10000) <= 7)/10000
1-poisson.cdf(6, 5)
sum(np.random.poisson(5, 10000) >= 7)/10000
```

:::

## Distribución geométrica

Sea $X$ una variable aleatoria que representa el número de fallas que ocurren antes de que se presente el primer éxito.Se dice entonces que la variable aleatoria $X$ tiene una distribución geométrica con función de probabilidad:

$$\mathbb{P}(X=k)=(1-p)^{k-1}p \quad \quad k=1,2,\cdots$$

En donde $p$ es la probabilidad de éxito. Además, Si $X$ sigue una distribución geométrica, entonces se cumple que:

- $\displaystyle E[X]=\dfrac{1}{p}$
- $V[X]=\dfrac{(1-p)}{p^2}$

## Distribución geométrica en R

::: {.panel-tabset}

### Código

```{r}
#| echo: TRUE
#| eval: FALSE
#| code-line-numbers: "1|2-3|4|5|6|7|8|9"
set.seed(163)
p = 0.2
n = 3
dgeom(x = n, prob = p)
mean(rgeom(n = 10000, prob = p) == n)
pgeom(q = n, prob = p, lower.tail = TRUE)
mean(rgeom(n = 10000, prob = p) <= n)
pgeom(q = n, prob = p, lower.tail  = FALSE)
mean(rgeom(n = 10000, prob = p) > n)
```
### Salidas

```{r}
#| echo: TRUE
#| eval: TRUE
set.seed(163)
p = 0.2
n = 3
dgeom(x = n, prob = p)
mean(rgeom(n = 10000, prob = p) == n)
pgeom(q = n, prob = p, lower.tail = TRUE)
mean(rgeom(n = 10000, prob = p) <= n)
pgeom(q = n, prob = p, lower.tail  = FALSE)
mean(rgeom(n = 10000, prob = p) > n)
```

:::

## Distribución geométrica en Python

::: {.panel-tabset}

### Código

```{.python code-line-numbers="1-2|4|5|6|7|8|9|10"}
import numpy as np
from scipy.stats import geom

np.random.seed(163)
geom.pmf(k=3, p=0.2)
sum(np.random.geometric(0.2, 10000) == 3)/10000
geom.cdf(k=3, p=0.2)
sum(np.random.geometric(0.2, 10000) <= 3)/10000
1-geom.cdf(k=3, p=0.2)
sum(np.random.geometric(0.2, 10000) > 3)/10000
```

### Salidas

```{python}
#| echo: TRUE
#| eval: TRUE
import numpy as np
from scipy.stats import geom

np.random.seed(163)
geom.pmf(k=3, p=0.2)
sum(np.random.geometric(0.2, 10000) == 3)/10000
geom.cdf(k=3, p=0.2)
sum(np.random.geometric(0.2, 10000) <= 3)/10000
1-geom.cdf(k=3, p=0.2)
sum(np.random.geometric(0.2, 10000) > 3)/10000
```

:::

## Distribución hipergeométrica

Sea $N$ el número total de objetos de una población finita, de manera tal que $k$ de éstos es de un tipo y $N-k$ de otros. Si se selecciona una muestra aleatoria de la población constituida por $n$ objetos de la probabilidad de que $x$ sea de un tipo exactamente y $n-x$ sea del otro, está dada por la función de probabilidad hipergeométrica:

$$\displaystyle \mathbb{P}(X=x)= \dfrac{{{k}\choose{x}} {{N-k}\choose{n-x}}  }{  {{N}\choose{n}}}\quad \quad x=1,2,\cdots,n \quad; x \leq k\quad ;n-x\leq N-k$$
Si $X$ sigue una distribución hipergeométrica y si $p=k/N$

- $E[X]=np$
- $V[X]=np(1-p)\left( \dfrac{N-n}{N-1}\right)$

# Distribuciones continuas

## Distribución normal

Sea $X$ una variable aleatoria que toma valores reales, diremos que $X$ sigue una distribución normal (o Gaussiana) si su función de densidad está por:

$$f_{X}(x)=\dfrac{1}{\sqrt{2\pi}\sigma}\exp\left[ -\dfrac{1}{2}\left(\dfrac{x-\mu}{\sigma}\right) ^2\right],$$

En donde los parámetros de la distribución son $\mu$ y $\sigma$ satisfacen las condiciones:

$$-\infty<\mu<\infty, \quad \sigma^2>0$$

## Distribución normal en R

::: {.panel-tabset}

### Código

```{r}
#| echo: TRUE
#| eval: FALSE
#| code-line-numbers: "1|2-3|5|6|7|8|9"
set.seed(163)
media=100
ds=16

pnorm(q = 90, mean = media, sd = ds, lower.tail = TRUE)
mean(rnorm(n = 10000, mean = media, sd = ds) <= 90)
pnorm(q = 140, mean = media, sd = ds, lower.tail = FALSE)
mean(rnorm(n = 10000, mean = media, sd = ds) > 140)
```
### Salidas

```{r}
#| echo: TRUE
#| eval: TRUE
set.seed(163)
media=100
ds=16

pnorm(q = 90, mean = media, sd = ds, lower.tail = TRUE)
mean(rnorm(n = 10000, mean = media, sd = ds) <= 90)
pnorm(q = 140, mean = media, sd = ds, lower.tail = FALSE)
mean(rnorm(n = 10000, mean = media, sd = ds) > 140)
```

:::

## Distribución normal en Python

::: {.panel-tabset}

### Código

```{.python code-line-numbers="1-2|4|5|6|7|8|9"}
import numpy as np
from scipy.stats import norm

np.random.seed(163)
mu, sigma = 100, 16
norm.cdf(90, mu , sigma)
sum(np.random.normal(mu, sigma, 10000) <= 90)/10000
1-norm.cdf(140, mu , sigma)
sum(np.random.normal(mu, sigma, 10000) > 140)/10000
```

### Salidas

```{python}
#| echo: TRUE
#| eval: TRUE
import numpy as np
from scipy.stats import norm

np.random.seed(163)
mu, sigma = 100, 16
norm.cdf(90, mu , sigma)
sum(np.random.normal(mu, sigma, 10000) <= 90)/10000
1-norm.cdf(140, mu , sigma)
sum(np.random.normal(mu, sigma, 10000) > 140)/10000
```

:::

## Distribución uniforme

Sea $X$ una variable aleatoria continua, diremos que $X$ sigue una distribución uniforme sobre el intervalo $(a,b)$ si su función de densidad de probabilidad está dada por:

$$f_{X}(x)=\begin{cases}1/(b-a) \quad &a\leq x \leq b\\0 \quad &e.o.c\end{cases}$$

Los parámetros de la distribución cumplen las condiciones:

$$-\infty<a<\infty,\quad -\infty<b<\infty$$

- $E[X]=\dfrac{(a+b)}{2}$    
- $V[X]=\dfrac{(b-a)^2}{12}$ 

## Distribución uniforme en R

::: {.panel-tabset}

### Código

```{r}
#| echo: TRUE
#| eval: FALSE
#| code-line-numbers: "1|3|4|5|6"
set.seed(163)

punif(0.3, 0 , 1 , lower.tail = TRUE)
mean(runif(n = 10000, 0, 1) <= 0.3)
punif(0.3, 0 , 1 , lower.tail = FALSE)
mean(runif(n = 10000, 0, 1) > 0.3)
```
### Salidas

```{r}
#| echo: TRUE
#| eval: TRUE
set.seed(163)

punif(0.3, 0 , 1 , lower.tail = TRUE)
mean(runif(n = 10000, 0, 1) <= 0.3)
punif(0.3, 0 , 1 , lower.tail = FALSE)
mean(runif(n = 10000, 0, 1) > 0.3)
```

:::

## Distribución uniforme en Python

::: {.panel-tabset}

### Código

```{.python code-line-numbers="1-2|4|5|6|7|8"}
import numpy as np
from scipy.stats import uniform

np.random.seed(163)
uniform.cdf(0.3, 0 , 1)
sum(np.random.uniform(0, 1, 10000) <= 0.3)/10000
1-uniform.cdf(0.3, 0 , 1)
sum(np.random.uniform(0, 1, 10000) > 0.3)/10000
```

### Salidas

```{python}
#| echo: TRUE
#| eval: TRUE
import numpy as np
from scipy.stats import uniform

np.random.seed(163)
uniform.cdf(0.3, 0 , 1)
sum(np.random.uniform(0, 1, 10000) <= 0.3)/10000
1-uniform.cdf(0.3, 0 , 1)
sum(np.random.uniform(0, 1, 10000) > 0.3)/10000
```

:::

## Distribución exponencial

Sea $X$ una variable aleatoria continua que toma valores positivos, diremos que $X$ sigue una distribución exponencial con parámetro $\alpha>0$ si su función de densidad está dada por:

$$f_{X}(x)=\begin{cases}\alpha e^{-\alpha x} \quad &x\geq 0 \\0 \quad &e.o.c\end{cases}$$
Además se cumple que:

- $E[X]=\dfrac{1}{\alpha}$     
- $V[X]=\dfrac{1}{\alpha^2}$  

## Distribución exponencial en R

::: {.panel-tabset}

### Código

```{r}
#| echo: TRUE
#| eval: FALSE
#| code-line-numbers: "1|3|4|5|6"
set.seed(163)

pexp(2, 0.4, lower.tail = TRUE)
mean(rexp(0.4, n = 10000) <= 2)
pexp(2, 0.4, lower.tail = FALSE)
mean(rexp(0.4, n = 10000) > 2)
```
### Salidas

```{r}
#| echo: TRUE
#| eval: TRUE
set.seed(163)

pexp(2, 0.4, lower.tail = TRUE)
mean(rexp(0.4, n = 10000) <= 2)
pexp(2, 0.4, lower.tail = FALSE)
mean(rexp(0.4, n = 10000) > 2)
```

:::

## Distribución exponencial en Python 

::: {.panel-tabset}

### Código

```{.python code-line-numbers="1-2|4|5|6|7|8"}
import numpy as np
from scipy.stats import expon

np.random.seed(163)
expon.cdf(2, scale=1/0.4)
sum(np.random.exponential(1/0.4, 10000) <= 2)/10000
1-expon.cdf(2, scale=1/0.4)
sum(np.random.exponential(1/0.4, 10000) > 2)/10000
```

### Salidas

```{python}
#| echo: TRUE
#| eval: TRUE
import numpy as np
from scipy.stats import expon

np.random.seed(163)
expon.cdf(2, scale=1/0.4)
sum(np.random.exponential(1/0.4, 10000) <= 2)/10000
1-expon.cdf(2, scale=1/0.4)
sum(np.random.exponential(1/0.4, 10000) > 2)/10000
```

:::

## Función gamma

La **función gamma** denotada por $\Gamma$ está definida por:

$$\Gamma(p)=\int_{0}^{\infty} x^{p-1} e^{-x}dx \hspace{20pt} p>0$$

Esta función cumple las siguientes propiedades:

- $\Gamma(n)=(n-1)!$       
- $\Gamma(1/2)=\sqrt{\pi}$ 

## Distribución gamma

Sea $X$ una variable aleatoria continua que toma valores positivos. Diremos que $X$ sigue una distribución Gamma si su función de densidad está dada por:

$$f_{X}(x)=\begin{cases}\dfrac{\alpha}{\Gamma(r)}(\alpha x)^{r-1}e^{-\alpha x} \quad &x>0\\0 \quad &e.o.c,\end{cases}$$
En donde los parámetros $r$ y $\alpha$ son positivos.

Es claro ver que un caso particular de la distribución Gamma es la distribución exponencial ($r=1$). Si $X$ se distribuye Gamma entonces se cumple:

- $E[X]=r/\alpha$   
- $V[X]=r/\alpha^2$ 

## Distribución gamma en R

::: {.panel-tabset}

### Código

```{r}
#| echo: TRUE
#| eval: FALSE
#| code-line-numbers: "1|3|4|5|6"
set.seed(163)

pgamma(q = 3, shape = 10, scale = 1/4)
mean(rgamma(shape=10, scale= 1/4, n = 10000) <= 3)
pgamma(q = 3, shape = 10, scale = 1/4, lower.tail = FALSE)
mean(rgamma(shape=10, scale= 1/4, n = 10000) > 3)
```
### Salidas

```{r}
#| echo: TRUE
#| eval: TRUE
set.seed(163)

pgamma(q = 3, shape = 10, scale = 1/4)
mean(rgamma(shape=10, scale= 1/4, n = 10000) <= 3)
pgamma(q = 3, shape = 10, scale = 1/4, lower.tail = FALSE)
mean(rgamma(shape=10, scale= 1/4, n = 10000) > 3)
```

:::

## Distribución gamma en Python

::: {.panel-tabset}

### Código

```{.python code-line-numbers="1-2|4|5|6|7|8"}
import numpy as np
from scipy.stats import gamma

np.random.seed(163)
gamma.cdf(3, a=10, scale=0.25)
sum(np.random.gamma(10,0.25, 10000) <= 3)/10000
1-gamma.cdf(3, a=10, scale=0.25)
sum(np.random.gamma(10,0.25, 10000) > 3)/10000
```

### Salidas

```{python}
#| echo: TRUE
#| eval: TRUE
import numpy as np
from scipy.stats import gamma

np.random.seed(163)
gamma.cdf(3, a=10, scale=0.25)
sum(np.random.gamma(10,0.25, 10000) <= 3)/10000
1-gamma.cdf(3, a=10, scale=0.25)
sum(np.random.gamma(10,0.25, 10000) > 3)/10000
```

:::

## Distribución t-student

Sea $X$ una variable aleatoria continua que toma valores reales, diremos que $X$ sigue una distribución t-student con $\nu$ grados de libertad, si su función de densidad de probabilidad está dada por:

$$f(t) = \dfrac{\Gamma(\dfrac{\nu+1}{2})} {\sqrt{\nu\pi}\,\Gamma(\dfrac{\nu}{2})} \left(1+\dfrac{t^2}{\nu} \right)^{\!-\dfrac{\nu+1}{2}},$$
donde $\Gamma$ es la función gamma. Si $X$ se distribuye t-student entonces:

- $\mathbb{E}[X]=0$ para $\nu>1$. Indefinida para otros valores.                   
- $\mathbb{V}[X]=\dfrac{\nu}{\nu -2}$ para $\nu>2$. Indefinida para otros valores. 

## Distribución t-student en R

::: {.panel-tabset}

### Código

```{r}
#| echo: TRUE
#| eval: FALSE
#| code-line-numbers: "1|3|4|5|6"
set.seed(163)

pt(q=1.9, df=15, lower.tail = T)
mean(rt(15, n = 10000) <= 1.9)
pt(q=1.9, df=15, lower.tail = F)
mean(rt(15, n = 10000) > 1.9)
```
### Salidas

```{r}
#| echo: TRUE
#| eval: TRUE
set.seed(163)

pt(q=1.9, df=15, lower.tail = T)
mean(rt(15, n = 10000) <= 1.9)
pt(q=1.9, df=15, lower.tail = F)
mean(rt(15, n = 10000) > 1.9)
```

:::

## Distribución t-student en Python

::: {.panel-tabset}

### Código

```{.python code-line-numbers="1-2|4|5|6|7|8"}
import numpy as np
from scipy.stats import t

np.random.seed(163)
t.cdf(1.9, 15)
sum(np.random.standard_t(15, 10000) <= 1.9)/10000
1-t.cdf(1.9, 15)
sum(np.random.standard_t(15, 10000) > 1.9)/10000
```

### Salidas

```{python}
#| echo: TRUE
#| eval: TRUE
import numpy as np
from scipy.stats import t

np.random.seed(163)
t.cdf(1.9, 15)
sum(np.random.standard_t(15, 10000) <= 1.9)/10000
1-t.cdf(1.9, 15)
sum(np.random.standard_t(15, 10000) > 1.9)/10000
```

:::

# Teorema del límite central

Sean $X_1,X_2,\dots,X_n$, $n$ variables aleatorias i.i.d. con una distribución de probabilidad no especificada y que tienen una media $\mu$ y varianza $\sigma^2$ finita. El promedio muestral 

$$\overline{X}=(X_1+X_2+\cdots+X_n)/n$$
tiene una distribución con media $\mu$ y varianza $\sigma^2/n$ que tiende hacia una distribución normal conforme $n\rightarrow\infty$. 

En otras palabras, la variable aleatoria $(\overline{X}-\mu)/(\sigma/\sqrt{n})$ tiene como límite una distribución normal estándar.

# ¿Qué veremos la próxima semana?

- Intervalos de confianza
- Test de hipótesis
- Implementación de estos en R y Python

# ¿Que deben preparar para la próxima semana?

- Leer el material adicional sobre R y Python
- Repasar materia MAT042 sobre Intervalos de confianza y test de hipótesis


<!DOCTYPE html>
<html lang="es"><head>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-html/tabby.min.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-html.min.css" rel="stylesheet" data-mode="light">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.0.36">

  <meta name="author" content="Eloy Alvarado Narváez">
  <title>IND163C - Análisis de Negocios (Business Analytics) - Métodos supervisados</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="../site_libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="../site_libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
      }
    pre.numberSource { margin-left: 3em;  padding-left: 4px; }
    div.sourceCode
      { color: #24292e;  }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span { color: #24292e; } /* Normal */
    code span.al { color: #ff5555; font-weight: bold; } /* Alert */
    code span.an { color: #6a737d; } /* Annotation */
    code span.at { color: #d73a49; } /* Attribute */
    code span.bn { color: #005cc5; } /* BaseN */
    code span.bu { color: #d73a49; } /* BuiltIn */
    code span.cf { color: #d73a49; } /* ControlFlow */
    code span.ch { color: #032f62; } /* Char */
    code span.cn { color: #005cc5; } /* Constant */
    code span.co { color: #6a737d; } /* Comment */
    code span.cv { color: #6a737d; } /* CommentVar */
    code span.do { color: #6a737d; } /* Documentation */
    code span.dt { color: #d73a49; } /* DataType */
    code span.dv { color: #005cc5; } /* DecVal */
    code span.er { color: #ff5555; text-decoration: underline; } /* Error */
    code span.ex { color: #d73a49; font-weight: bold; } /* Extension */
    code span.fl { color: #005cc5; } /* Float */
    code span.fu { color: #6f42c1; } /* Function */
    code span.im { color: #032f62; } /* Import */
    code span.in { color: #6a737d; } /* Information */
    code span.kw { color: #d73a49; } /* Keyword */
    code span.op { color: #24292e; } /* Operator */
    code span.ot { color: #6f42c1; } /* Other */
    code span.pp { color: #d73a49; } /* Preprocessor */
    code span.re { color: #6a737d; } /* RegionMarker */
    code span.sc { color: #005cc5; } /* SpecialChar */
    code span.ss { color: #032f62; } /* SpecialString */
    code span.st { color: #032f62; } /* String */
    code span.va { color: #e36209; } /* Variable */
    code span.vs { color: #032f62; } /* VerbatimString */
    code span.wa { color: #ff5555; } /* Warning */
  </style>
  <link rel="stylesheet" href="../site_libs/revealjs/dist/theme/quarto.css" id="theme">
  <link href="../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="../site_libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="../site_libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="../site_libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">

  .callout {
    margin-top: 1em;
    margin-bottom: 1em;  
    border-radius: .25rem;
  }

  .callout.callout-style-simple { 
    padding: 0em 0.5em;
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
    display: flex;
  }

  .callout.callout-style-default {
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
  }

  .callout .callout-body-container {
    flex-grow: 1;
  }

  .callout.callout-style-simple .callout-body {
    font-size: 1rem;
    font-weight: 400;
  }

  .callout.callout-style-default .callout-body {
    font-size: 0.9rem;
    font-weight: 400;
  }

  .callout.callout-captioned.callout-style-simple .callout-body {
    margin-top: 0.2em;
  }

  .callout:not(.callout-captioned) .callout-body {
      display: flex;
  }

  .callout:not(.no-icon).callout-captioned.callout-style-simple .callout-content {
    padding-left: 1.6em;
  }

  .callout.callout-captioned .callout-header {
    padding-top: 0.2em;
    margin-bottom: -0.2em;
  }

  .callout.callout-captioned .callout-caption  p {
    margin-top: 0.5em;
    margin-bottom: 0.5em;
  }
    
  .callout.callout-captioned.callout-style-simple .callout-content  p {
    margin-top: 0;
  }

  .callout.callout-captioned.callout-style-default .callout-content  p {
    margin-top: 0.7em;
  }

  .callout.callout-style-simple div.callout-caption {
    border-bottom: none;
    font-size: .9rem;
    font-weight: 600;
    opacity: 75%;
  }

  .callout.callout-style-default  div.callout-caption {
    border-bottom: none;
    font-weight: 600;
    opacity: 85%;
    font-size: 0.9rem;
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-default div.callout-content {
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-simple .callout-icon::before {
    height: 1rem;
    width: 1rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 1rem 1rem;
  }

  .callout.callout-style-default .callout-icon::before {
    height: 0.9rem;
    width: 0.9rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 0.9rem 0.9rem;
  }

  .callout-caption {
    display: flex
  }
    
  .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  .callout.no-icon::before {
    display: none !important;
  }

  .callout.callout-captioned .callout-body > .callout-content > :last-child {
    margin-bottom: 0.5rem;
  }

  .callout.callout-captioned .callout-icon::before {
    margin-top: .5rem;
    padding-right: .5rem;
  }

  .callout:not(.callout-captioned) .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  /* Callout Types */

  div.callout-note {
    border-left-color: #4582ec !important;
  }

  div.callout-note .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEU0lEQVRYCcVXTWhcVRQ+586kSUMMxkyaElstCto2SIhitS5Ek8xUKV2poatCcVHtUlFQk8mbaaziwpWgglJwVaquitBOfhQXFlqlzSJpFSpIYyXNjBNiTCck7x2/8/LeNDOZxDuEkgOXe++553zfefee+/OYLOXFk3+1LLrRdiO81yNqZ6K9cG0P3MeFaMIQjXssE8Z1JzLO9ls20MBZX7oG8w9GxB0goaPrW5aNMp1yOZIa7Wv6o2ykpLtmAPs/vrG14Z+6d4jpbSKuhdcSyq9wGMPXjonwmESXrriLzFGOdDBLB8Y6MNYBu0dRokSygMA/mrun8MGFN3behm6VVAwg4WR3i6FvYK1T7MHo9BK7ydH+1uurECoouk5MPRyVSBrBHMYwVobG2aOXM07sWrn5qgB60rc6mcwIDJtQrnrEr44kmy+UO9r0u9O5/YbkS9juQckLed3DyW2XV/qWBBB3ptvI8EUY3I9p/67OW+g967TNr3Sotn3IuVlfMLVnsBwH4fsnebJvyGm5GeIUA3jljERmrv49SizPYuq+z7c2H/jlGC+Ghhupn/hcapqmcudB9jwJ/3jvnvu6vu5lVzF1fXyZuZZ7U8nRmVzytvT+H3kilYvH09mLWrQdwFSsFEsxFVs5fK7A0g8gMZjbif4ACpKbjv7gNGaD8bUrlk8x+KRflttr22JEMRUbTUwwDQScyzPgedQHZT0xnx7ujw2jfVfExwYHwOsDTjLdJ2ebmeQIlJ7neo41s/DrsL3kl+W2lWvAga0tR3zueGr6GL78M3ifH0rGXrBC2aAR8uYcIA5gwV8zIE8onoh8u0Fca/ciF7j1uOzEnqcIm59sEXoGc0+z6+H45V1CvAvHcD7THztu669cnp+L0okAeIc6zjbM/24LgGM1gZk7jnRu1aQWoU9sfUOuhrmtaPIO3YY1KLLWZaEO5TKUbMY5zx8W9UJ6elpLwKXbsaZ4EFl7B4bMtDv0iRipKoDQT2sNQI9b1utXFdYisi+wzZ/ri/1m7QfDgEuvgUUEIJPq3DhX/5DWNqIXDOweC2wvIR90Oq3lDpdMIgD2r0dXvGdsEW5H6x6HLRJYU7C69VefO1x8Gde1ZFSJLfWS1jbCnhtOPxmpfv2LXOA2Xk2tvnwKKPFuZ/oRmwBwqRQDcKNeVQkYcOjtWVBuM/JuYw5b6isojIkYxyYAFn5K7ZBF10fea52y8QltAg6jnMqNHFBmGkQ1j+U43HMi2xMar1Nv0zGsf1s8nUsmUtPOOrbFIR8bHFDMB5zL13Gmr/kGlCkUzedTzzmzsaJXhYawnA3UmARpiYj5ooJZiUoxFRtK3X6pgNPv+IZVPcnwbOl6f+aBaO1CNvPW9n9LmCp01nuSaTRF2YxHqZ8DYQT6WsXT+RD6eUztwYLZ8rM+rcPxamv1VQzFUkzFXvkiVrySGQgJNvXHJAxiU3/NwiC03rSf05VBaPtu/Z7/B8Yn/w7eguloAAAAAElFTkSuQmCC');
  }

  div.callout-note.callout-style-default .callout-caption {
    background-color: #dae6fb
  }

  div.callout-important {
    border-left-color: #d9534f !important;
  }

  div.callout-important .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEKklEQVRYCcVXTWhcVRS+575MJym48A+hSRFr00ySRQhURRfd2HYjk2SSTokuBCkU2o0LoSKKraKIBTcuFCoidGFD08nkBzdREbpQ1EDNIv8qSGMFUboImMSZd4/f9zJv8ibJMC8xJQfO3HPPPef7zrvvvnvviIkpC9nsw0UttFunbUhpFzFtarSd6WJkStVMw5xyVqYTvkwfzuf/5FgtkVoB0729j1rjXwThS7Vio+Mo6DNnvLfahoZ+i/o32lULuJ3NNiz7q6+pyAUkJaFF6JwaM2lUJlV0MlnQn5aTRbEu0SEqHUa0A4AdiGuB1kFXRfVyg5d87+Dg4DL6m2TLAub60ilj7A1Ec4odSAc8X95sHh7+ZRPCFo6Fnp7HfU/fBng/hi10CjCnWnJjsxvDNxWw0NfV6Rv5GgP3I3jGWXumdTD/3cbEOP2ZbOZp69yniG3FQ9z1jD7bnBu9Fc2tKGC2q+uAJOQHBDRiZX1x36o7fWBs7J9ownbtO+n0/qWkvW7UPIfc37WgT6ZGR++EOJyeQDSb9UB+DZ1G6DdLDzyS+b/kBCYGsYgJbSQHuThGKRcw5xdeQf8YdNHsc6ePXrlSYMBuSIAFTGAtQo+VuALo4BX83N190NWZWbynBjhOHsmNfFWLeL6v+ynsA58zDvvAC8j5PkbOcXCMg2PZFk3q8MjI7WAG/Dp9AwP7jdGBOOQkAvlFUB+irtm16I1Zw9YBcpGTGXYmk3kQIC/Cds55l+iMI3jqhjAuaoe+am2Jw5GT3Nbz3CkE12NavmzN5+erJW7046n/CH1RO/RVa8lBLozXk9uqykkGAyRXLWlLv5jyp4RFsG5vGVzpDLnIjTWgnRy2Rr+tDKvRc7Y8AyZq10jj8DqXdnIRNtFZb+t/ZRtXcDiVnzpqx8mPcDWxgARUqx0W1QB9MeUZiNrV4qP+Ehc+BpNgATsTX8ozYKL2NtFYAHc84fG7ndxUPr+AR/iQSns7uSUufAymwDOb2+NjK27lEFocm/EE2WpyIy/Hi66MWuMKJn8RvxIcj87IM5Vh9663ziW36kR0HNenXuxmfaD8JC7tfKbrhFr7LiZCrMjrzTeGx+PmkosrkNzW94ObzwocJ7A1HokLolY+AvkTiD/q1H0cN48c5EL8Crkttsa/AXQVDmutfyku0E7jShx49XqV3MFK8IryDhYVbj7Sj2P2eBxwcXoe8T8idsKKPRcnZw1b+slFTubwUwhktrfnAt7J++jwQtLZcm3sr9LQrjRzz6cfMv9aLvgmnAGvpoaGLxM4mAEaLV7iAzQ3oU0IvD5x9ix3yF2RAAuYAOO2f7PEFWCXZ4C9Pb2UsgDeVnFSpbFK7/IWu7TPTvBqzbGdCHOJQSxiEjt6IyZmxQyEJHv6xyQsYk//moVFsN2zP6fRImjfq7/n/wFDguUQFNEwugAAAABJRU5ErkJggg==');
  }

  div.callout-important.callout-style-default .callout-caption {
    background-color: #f7dddc
  }

  div.callout-warning {
    border-left-color: #f0ad4e !important;
  }

  div.callout-warning .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAETklEQVRYCeVWW2gcVRg+58yaTUnizqbipZeX4uWhBEniBaoUX1Ioze52t7sRq6APio9V9MEaoWlVsFasRq0gltaAPuxms8lu0gcviE/FFOstVbSIxgcv6SU7EZqmdc7v9+9mJtNks51NTUH84ed889/PP+cmxP+d5FIbMJmNbpREu4WUkiTtCicKny0l1pIKmBzovF2S+hIJHX8iEu3hZJ5lNZGqyRrGSIQpq15AzF28jgpeY6yk6GVdrfFqdrD6Iw+QlB8g0YS2g7dyQmXM/IDhBhT0UCiRf59lfqmmDvzRt6kByV/m4JjtzuaujMUM2c5Z2d6JdKrRb3K2q6mA+oYVz8JnDdKPmmNthzkAk/lN63sYPgevrguc72aZX/L9C6x09GYyxBgCX4NlvyGUHOKELlm5rXeR1kchuChJt4SSwyddZRXgvwMGvYo4QSlk3/zkHD8UHxwVJA6zjZZqP8v8kK8OWLnIZtLyCAJagYC4rTGW/9Pqj92N/c+LUaAj27movwbi19tk/whRCIE7Q9vyI6yvRpftAKVTdUjOW40X3h5OXsKCdmFcx0xlLJoSuQngnrJe7Kcjm4OMq9FlC7CMmScQANuNvjfP3PjGXDBaUQmbp296S5L4DrpbrHN1T87ZVEZVCzg1FF0Ft+dKrlLukI+/c9ENo+TvlTDbYFvuKPtQ9+l052rXrgKoWkDAFnvh0wTOmYn8R5f4k/jN/fZiCM1tQx9jQQ4ANhqG4hiL0qIFTGViG9DKB7GYzgubnpofgYRwO+DFjh0Zin2m4b/97EDkXkc+f6xYAPX0KK2I/7fUQuwzuwo/L3AkcjugPNixC8cHf0FyPjWlItmLxWw4Ou9YsQCr5fijMGoD/zpdRy95HRysyXA74MWOnscpO4j2y3HAVisw85hX5+AFBRSHt4ShfLFkIMXTqyKFc46xdzQM6XbAi702a7sy04J0+feReMFKp5q9esYLCqAZYw/k14E/xcLLsFElaornTuJB0svMuJINy8xkIYuL+xPAlWRceH6+HX7THJ0djLUom46zREu7tTkxwmf/FdOZ/sh6Q8qvEAiHpm4PJ4a/doJe0gH1t+aHRgCzOvBvJedEK5OFE5jpm4AGP2a8Dxe3gGJ/pAutug9Gp6he92CsSsWBaEcxGx0FHytmIpuqGkOpldqNYQK8cSoXvd+xLxXADw0kf6UkJNFtdo5MOgaLjiQOQHcn+A6h5NuL2s0qsC2LOM75PcF3yr5STuBSAcGG+meA14K/CI21HcS4LBT6tv0QAh8Dr5l93AhZzG5ZJ4VxAqdZUEl9z7WJ4aN+svMvwHHL21UKTd1mqvChH7/Za5xzXBBKrUcB0TQ+Ulgkfbi/H/YT5EptrGzsEK7tR1B7ln9BBwckYfMiuSqklSznIuoIIOM42MQO+QnduCoFCI0bpkzjCjddHPN/F+2Yu+sd9bKNpVwHhbS3LluK/0zgfwD0xYI5dXuzlQAAAABJRU5ErkJggg==');
  }

  div.callout-warning.callout-style-default .callout-caption {
    background-color: #fcefdc
  }

  div.callout-tip {
    border-left-color: #02b875 !important;
  }

  div.callout-tip .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAADr0lEQVRYCe1XTWgTQRj9ZjZV8a9SPIkKgj8I1bMHsUWrqYLVg4Ue6v9BwZOxSYsIerFao7UiUryIqJcqgtpimhbBXoSCVxUFe9CTiogUrUp2Pt+3aUI2u5vdNh4dmMzOzHvvezuz8xNFM0mjnbXaNu1MvFWRXkXEyE6aYOYJpdW4IXuA4r0fo8qqSMDBU0v1HJUgVieAXxzCsdE/YJTdFcVIZQNMyhruOMJKXYFoLfIfIvVIMWdsrd+Rpd86ZmyzzjJmLStqRn0v8lzkb4rVIXvnpScOJuAn2ACC65FkPzEdEy4TPWRLJ2h7z4cArXzzaOdKlbOvKKX25Wl00jSnrwVxAg3o4dRxhO13RBSdNvH0xSARv3adTXbBdTf64IWO2vH0LT+cv4GR1DJt+DUItaQogeBX/chhbTBxEiZ6gftlDNXTrvT7co4ub5A6gp9HIcHvzTa46OS5fBeP87Qm0fQkr4FsYgVQ7Qg+ZayaDg9jhg1GkWj8RG6lkeSacrrHgDaxdoBiZPg+NXV/KifMuB6//JmYH4CntVEHy/keA6x4h4CU5oFy8GzrBS18cLJMXcljAKB6INjWsRcuZBWVaS3GDrqB7rdapVIeA+isQ57Eev9eCqzqOa81CY05VLd6SamW2wA2H3SiTbnbSxmzfp7WtKZkqy4mdyAlGx7ennghYf8voqp9cLSgKdqNfa6RdRsAAkPwRuJZNbpByn+RrJi1RXTwdi8RQF6ymDwGMAtZ6TVE+4uoKh+MYkcLsT0Hk8eAienbiGdjJHZTpmNjlbFJNKDVAp2fJlYju6IreQxQ08UJDNYdoLSl6AadO+fFuCQqVMB1NJwPm69T04Wv5WhfcWyfXQB+wXRs1pt+nCknRa0LVzSA/2B+a9+zQJadb7IyyV24YAxKp2Jqs3emZTuNnKxsah+uabKbMk7CbTgJx/zIgQYErIeTKRQ9yD9wxVof5YolPHqaWo7TD6tJlh7jQnK5z2n3+fGdggIOx2kaa2YI9QWarc5Ce1ipNWMKeSG4DysFF52KBmTNMmn5HqCFkwy34rDg05gDwgH3bBi+sgFhN/e8QvRn8kbamCOhgrZ9GJhFDgfcMHzFb6BAtjKpFhzTjwv1KCVuxHvCbsSiEz4CANnj84cwHdFXAbAOJ4LTSAawGWFn5tDhLMYz6nWeU2wJfIhmIJBefcd/A5FWQWGgrWzyORZ3Q6HuV+Jf0Bj+BTX69fm1zWgK7By1YTXchFDORywnfQ7GpzOo6S+qECrsx2ifVQAAAABJRU5ErkJggg==');
  }

  div.callout-tip.callout-style-default .callout-caption {
    background-color: #ccf1e3
  }

  div.callout-caution {
    border-left-color: #fd7e14 !important;
  }

  div.callout-caution .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAACV0lEQVRYCdVWzWoUQRCuqp2ICBLJXgITZL1EfQDBW/bkzUMUD7klD+ATSHBEfAIfQO+iXsWDxJsHL96EHAwhgzlkg8nBg25XWb0zIb0zs9muYYWkoKeru+vn664fBqElyZNuyh167NXJ8Ut8McjbmEraKHkd7uAnAFku+VWdb3reSmRV8PKSLfZ0Gjn3a6Xlcq9YGb6tADjn+lUfTXtVmaZ1KwBIvFI11rRXlWlatwIAAv2asaa9mlB9wwygiDX26qaw1yYPzFXg2N1GgG0FMF8Oj+VIx7E/03lHx8UhvYyNZLN7BwSPgekXXLribw7w5/c8EF+DBK5idvDVYtEEwMeYefjjLAdEyQ3M9nfOkgnPTEkYU+sxMq0BxNR6jExrAI31H1rzvLEfRIdgcv1XEdj6QTQAS2wtstEALLG1yEZ3QhH6oDX7ExBSFEkFINXH98NTrme5IOaaA7kIfiu2L8A3qhH9zRbukdCqdsA98TdElyeMe5BI8Rs2xHRIsoTSSVFfCFCWGPn9XHb4cdobRIWABNf0add9jakDjQJpJ1bTXOJXnnRXHRf+dNL1ZV1MBRCXhMbaHqGI1JkKIL7+i8uffuP6wVQAzO7+qVEbF6NbS0LJureYcWXUUhH66nLR5rYmva+2tjRFtojkM2aD76HEGAD3tPtKM309FJg5j/K682ywcWJ3PASCcycH/22u+Bh7Aa0ehM2Fu4z0SAE81HF9RkB21c5bEn4Dzw+/qNOyXr3DCTQDMBOdhi4nAgiFDGCinIa2owCEChUwD8qzd03PG+qdW/4fDzjUMcE1ZpIAAAAASUVORK5CYII=');
  }

  div.callout-caution.callout-style-default .callout-caption {
    background-color: #ffe5d0
  }

  </style>
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" class="center">
  <h1 class="title">Métodos supervisados</h1>
  <p class="subtitle">IND 163 - 2022/02</p>
  <p class="author">Eloy Alvarado Narváez</p>
  <p class="institute">Universidad Técnica Federico Santa María</p>
  <p class="date">14/10/22</p>
</section>

<section>
<section id="métodos-supervisados" class="title-slide slide level1 center">
<h1>Métodos supervisados</h1>

</section>
<section id="introducción" class="slide level2">
<h2>Introducción</h2>
<p>Como hemos mencionado a lo largo del curso, una regresión lineal simple asume que la variable respuesta <span class="math inline">\(Y\)</span> es <strong>cuantitativa</strong>, pero en muchas situaciones esta es <strong>cualitativa</strong> (también referida como categórica). En lo que sigue, veremos métodos para predecir respuestas cualitativas, más comúnmente llamado <strong>clasificación</strong>.</p>
<p>Existen mucha técnicas de clasificación o <strong>clasificadores</strong>, que se pueden usar para predecir una variable cualitativa. Entre ellos se encuentras:</p>
<ul>
<li class="fragment"><p>Regresión logística</p></li>
<li class="fragment"><p>Análisis discriminante lineal</p></li>
<li class="fragment"><p><em>k-NN (k- nearest neighbors / k-vecinos cercanos)</em></p></li>
<li class="fragment"><p>Modelos generalizados aditivos</p></li>
<li class="fragment"><p>Árboles y bosques aleatorios</p></li>
<li class="fragment"><p>Boosting</p></li>
<li class="fragment"><p>SVM</p></li>
</ul>
</section>
<section id="ejemplo" class="slide level2">
<h2>Ejemplo</h2>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1"></a><span class="fu">library</span>(ISLR)</span>
<span id="cb1-2"><a href="#cb1-2"></a>data<span class="ot">&lt;-</span>Default</span>
<span id="cb1-3"><a href="#cb1-3"></a><span class="fu">head</span>(data)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>  default student   balance    income
1      No      No  729.5265 44361.625
2      No     Yes  817.1804 12106.135
3      No      No 1073.5492 31767.139
4      No      No  529.2506 35704.494
5      No      No  785.6559 38463.496
6      No     Yes  919.5885  7491.559</code></pre>
</div>
</div>
</section>
<section id="ejemplo-continuación" class="slide level2">
<h2>Ejemplo: continuación</h2>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb3-2"><a href="#cb3-2"></a><span class="fu">ggplot</span>(data) <span class="sc">+</span> <span class="fu">aes</span>(<span class="at">x =</span> balance, <span class="at">y =</span> income, <span class="at">colour =</span> default) <span class="sc">+</span> <span class="fu">geom_point</span>(<span class="at">shape =</span> <span class="st">"bullet"</span>, <span class="at">size =</span> <span class="fl">1.5</span>) <span class="sc">+</span></span>
<span id="cb3-3"><a href="#cb3-3"></a> <span class="fu">scale_color_hue</span>(<span class="at">direction =</span> <span class="sc">-</span><span class="dv">1</span>) <span class="sc">+</span> <span class="fu">theme_gray</span>()</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>

</div>
<img data-src="lec_week7_files/figure-revealjs/unnamed-chunk-4-1.png" width="960" class="r-stretch quarto-figure-center"></section>
<section id="ejemplo-continuación-1" class="slide level2">
<h2>Ejemplo: continuación</h2>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1"></a><span class="fu">ggplot</span>(data) <span class="sc">+</span>  <span class="fu">aes</span>(<span class="at">x =</span> default, <span class="at">y =</span> balance, <span class="at">fill =</span> default) <span class="sc">+</span>  <span class="fu">geom_boxplot</span>(<span class="at">shape =</span> <span class="st">"circle"</span>) <span class="sc">+</span></span>
<span id="cb4-2"><a href="#cb4-2"></a>  <span class="fu">scale_fill_hue</span>(<span class="at">direction =</span> <span class="sc">-</span><span class="dv">1</span>) <span class="sc">+</span>  <span class="fu">theme_gray</span>()</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>

</div>
<img data-src="lec_week7_files/figure-revealjs/unnamed-chunk-6-1.png" width="960" class="r-stretch quarto-figure-center"></section>
<section id="ejemplo-continuación-2" class="slide level2">
<h2>Ejemplo: continuación</h2>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1"></a><span class="fu">ggplot</span>(data) <span class="sc">+</span>  <span class="fu">aes</span>(<span class="at">x =</span> default, <span class="at">y =</span> income, <span class="at">fill =</span> default) <span class="sc">+</span>  <span class="fu">geom_boxplot</span>(<span class="at">shape =</span> <span class="st">"circle"</span>) <span class="sc">+</span></span>
<span id="cb5-2"><a href="#cb5-2"></a>  <span class="fu">scale_fill_hue</span>(<span class="at">direction =</span> <span class="sc">-</span><span class="dv">1</span>) <span class="sc">+</span>  <span class="fu">theme_gray</span>()</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>

</div>
<img data-src="lec_week7_files/figure-revealjs/unnamed-chunk-8-1.png" width="960" class="r-stretch quarto-figure-center"></section>
<section id="por-qué-no-usar-una-regresión-lineal" class="slide level2">
<h2>¿Por qué no usar una regresión lineal?</h2>
<p>Supongamos que se intenta predecir la condición médica de un paciente en la sala de emergencia con base a sus síntomas. Para simplificar, imaginemos que sólo que tienen 3 posibles diagnósticos: accidente cardiovascular, sobredosis y ataque epiléptico. Por lo que podríamos clasificar la variable respuesta como</p>
<p><span class="math display">\[
Y=\begin{cases} 1 \quad \text{si Accidente cardiovascular}\\
2 \quad \text{si Sobredosis} \\
3 \quad \text{si Ataque epiléptico}
\end{cases}
\]</span></p>
<p>Usando esta codificación, se puede usar el método de mínimos cuadrados para ajustar una regresión lineal para predecir <span class="math inline">\(Y\)</span> en base a los predictores <span class="math inline">\(X_1,\dots, X_p\)</span>.</p>
</section>
<section id="por-qué-no-usar-una-regresión-lineal-continuación" class="slide level2">
<h2>¿Por qué no usar una regresión lineal?: continuación</h2>
<p>Desafortunadamente, esta codificación implica un ordenamiento de las salidas, estableciendo sobredosis entre accidente cardiovascular y Ataque epiléptico, e inherentemente afirmando que la <strong>diferencia entre categorías contiguas son la misma</strong>.</p>
<p>Es claro notar que si usamos otra codificación, el ajuste de regresión lineal obtenido será diferente al primero. En general, <strong>no hay una forma natural de convertir una variable respuesta cualitativa con más de dos niveles en una variable cuantitativa que esté lista para hacer una regresión lineal</strong>.</p>
</section>
<section id="por-qué-no-usar-una-regresión-lineal-continuación-1" class="slide level2">
<h2>¿Por qué no usar una regresión lineal?: continuación</h2>
<p>En el caso de variable respuesta binaria, la situación es algo más favorable, debido a que si se cambia la codificación, el ajuste de regresión obtenido será el mismo. Sin embargo, el método de mínimos cuadrados no tiene sentido, provocando que algunas de nuestras estimación estén fuera del intervalo [0,1], haciendo difícil la interpretación de las probabilidades.</p>
<p>Lo anterior debido a que se puede mostrar que el <span class="math inline">\(X\hat{\beta}\)</span> obtenido con la regresión lineal con codificación binaria, es simplemente una estimación de <span class="math inline">\(\mathbb{P}(\text{Sobredosis})\)</span> si la codificación es</p>
<p><span class="math display">\[
Y = \begin{cases} 0 \quad \text{si Accidente cardiovascular}\\
1 \quad \text{si Sobredosis}
\end{cases}
\]</span></p>
</section></section>
<section>
<section id="regresión-logística" class="title-slide slide level1 center">
<h1>Regresión logística</h1>
<p>Usando el mismo conjunto de datos <code>Default</code>, donde la variable respuesta <code>default</code> cae dentro de dos categorías <code>Yes</code> y <code>No</code>. En vez de modelar la respuesta <span class="math inline">\(Y\)</span> directamente, la <strong>regresión logística</strong> modela la probabilidad que <span class="math inline">\(Y\)</span> pertenezca a una categoría particular.</p>
<p>Para el conjunto de datos <code>Default</code>, la regresión logística modela la probabilidad de que haya <em>default</em> (morosidad). Por ejemplo, la probabilidad de <em>default</em> dado cierto <code>balance</code> puede ser escrito como</p>
<p><span class="math display">\[
\mathbb{P}( \text{default}=\text{Yes}|\text{balance})
\]</span></p>
<p>Los valores de esta probabilidad, que la abreviamos como <span class="math inline">\(p(\text{balance})\)</span>, estarán entre 0 y 1. Por lo que para un valor particular de <code>balance</code>, se puede hacer una predicción para <code>default</code>. Por ejemplo, se podría predecir que <code>default=Yes</code> para cualquier individuo cuyo <span class="math inline">\(p(\text{balance})&gt;0.5\)</span>. Alternativamente, si una compañía quisiese ser más conservador en la predicción, podría definir <span class="math inline">\(p(\text{balance})&gt;0.1\)</span>.</p>
</section>
<section id="modelo-logístico" class="slide level2">
<h2>Modelo logístico</h2>
<p>¿Cómo deberíamos modelar la relación entre <span class="math inline">\(p(X)=\mathbb{P}(Y=1|X)\)</span> y <span class="math inline">\(X\)</span>?</p>
<p>Podemos utilizar un enfoque de regresión lineal para representar estar probabilidades, esto es:</p>
<p><span class="math display">\[
p(X)=\beta_0 + \beta_1 X
\]</span></p>
<p>Si usamos este enfoque para predecir <code>default=Yes</code> usando <code>balance</code>, entonces obtendremos el siguiente modelo.</p>
</section>
<section id="modelo-logístico-continuación" class="slide level2">
<h2>Modelo logístico: continuación</h2>

<img data-src="images/week7/lin_reg.png" class="r-stretch quarto-figure-center"></section>
<section id="modelo-logístico-continuación-1" class="slide level2">
<h2>Modelo logístico: continuación</h2>
<p>Para evitar lo anterior, debemos modelar <span class="math inline">\(p(X)\)</span> usando una función que entregue salidas entre 0 y 1 para todos los valores de <span class="math inline">\(X\)</span>. Muchas funciones cumplen estas condiciones. En una <strong>regresión logística</strong>, usamos la <em>función logística</em>.</p>
<p><span class="math display">\[
p(X)=\dfrac{\exp(\beta_0 + \beta_1 X)}{1+\exp(\beta_0 + \beta_1 X)}
\]</span></p>
<p>Para ajustar el modelo anterior, usamos el método de <strong>máxima verosimilitud</strong>.</p>
</section>
<section id="modelo-logístico-continuación-2" class="slide level2">
<h2>Modelo logístico: continuación</h2>

<img data-src="images/week7/log_reg.png" class="r-stretch quarto-figure-center"></section>
<section id="modelo-logístico-continuación-3" class="slide level2">
<h2>Modelo logístico: continuación</h2>
<p>Manipulando un poco la fórmula anterior, se tiene que</p>
<p><span class="math display">\[
\dfrac{p(X)}{1-p(X)}=\exp(\beta_0 + \beta_1 X)
\]</span></p>
<p>La cantidad <span class="math inline">\({p(X) \over 1-p(X)}\)</span> se le llaman <strong>odds</strong>, que pueden toman cualquier valor en <span class="math inline">\(\mathbb{R}^{+}\)</span>. Valores cercanos a cero y tendiendo a infinito, indican muy baja y alta probabilidad de <code>default</code>, respectivamente.</p>
</section>
<section id="modelo-logístico-continuación-4" class="slide level2">
<h2>Modelo logístico: continuación</h2>
<p>Tomando el logaritmo en ambos lados, se tiene</p>
<p><span class="math display">\[
\log \left(\dfrac{p(X)}{1-p(X)}\right)=\beta_0 + \beta_1 X
\]</span></p>
<p>a esta cantidad la llamamos <strong>log-odds</strong> o <strong>logit</strong>. Notamos que el modelo de regresión logística tiene un logit lineal en <span class="math inline">\(X\)</span>.</p>
</section>
<section id="estimación-de-los-coeficientes-de-regresión" class="slide level2">
<h2>Estimación de los coeficientes de regresión</h2>
<p>Los coeficiente <span class="math inline">\(\beta_0\)</span> y <span class="math inline">\(\beta_1\)</span> en la ecuación</p>
<p><span class="math display">\[
p(X)=\dfrac{\exp(\beta_0 + \beta_1 X)}{1+\exp(\beta_0 + \beta_1 X)}
\]</span></p>
<p>son desconocidos, por lo que deben ser estimados basándose en los datos de entrenamiento. Si bien podríamos ocupar una metodología de métodos cuadrados no lineales para ajustar el modelo:</p>
<p><span class="math display">\[
\log \left(\dfrac{p(X)}{1-p(X)}\right)=\beta_0 + \beta_1 X
\]</span></p>
<p>La metodología de máxima verosimilitud es usualmente preferida, debido a que tiene mejores propiedades estadísticas.</p>
</section>
<section id="estimación-de-los-coeficientes-de-regresión-continuación" class="slide level2">
<h2>Estimación de los coeficientes de regresión: continuación</h2>
<p>Formalmente, definimos la <strong>función de verosimilitud</strong> como:</p>
<p><span class="math display">\[
\ell(\beta_0,\beta_1)=\prod_{i:y_i=1}p(x_i)\prod_{i':y_{i'}=0}(1-p(x_{i'}))
\]</span></p>
<p>Las estimaciones <span class="math inline">\(\hat{\beta}_0\)</span> y <span class="math inline">\(\hat{\beta}_1\)</span> son escogidos para maximizar la función de verosimilitud.</p>
</section>
<section id="ejemplo-1" class="slide level2">
<h2>Ejemplo</h2>
<div class="cell">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1"></a>logit <span class="ot">&lt;-</span> <span class="fu">glm</span>(default <span class="sc">~</span> balance, <span class="at">data =</span> data, <span class="at">family =</span> <span class="st">"binomial"</span>)</span>
<span id="cb6-2"><a href="#cb6-2"></a><span class="fu">summary</span>(logit)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
glm(formula = default ~ balance, family = "binomial", data = data)

Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-2.2697  -0.1465  -0.0589  -0.0221   3.7589  

Coefficients:
              Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept) -1.065e+01  3.612e-01  -29.49   &lt;2e-16 ***
balance      5.499e-03  2.204e-04   24.95   &lt;2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 2920.6  on 9999  degrees of freedom
Residual deviance: 1596.5  on 9998  degrees of freedom
AIC: 1600.5

Number of Fisher Scoring iterations: 8</code></pre>
</div>
</div>
</section>
<section id="predicciones" class="slide level2">
<h2>Predicciones</h2>
<p>Una vez que los coeficientes han sido estimados, lo que resta es calcular la probabilidad de <code>default</code> para una <code>balance</code> dado. Por ejemplo, la predicción para una persona con balance <span class="math inline">\(\$1000\)</span> es</p>
<p><span class="math display">\[
\hat{p}(X)=\dfrac{\exp(-10.65+ 0.0055 \times 1000)}{1+\exp(-10.65+ 0.0055 \times 1000)}\approx 0.00576
\]</span></p>
<p>que es bajo <span class="math inline">\(1\%\)</span>. En contraste con alguien que adeuda <span class="math inline">\(\$2000\)</span>, en cuyo caso <span class="math inline">\(\hat{p}(X)=0.586\)</span>.</p>
</section>
<section id="predicciones-continuación" class="slide level2">
<h2>Predicciones: continuación</h2>
<p>Si utilizamos <em>dummy variables</em> para el predictor <code>student</code> codificado como 0 y 1. tendremos el siguiente ajuste</p>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
glm(formula = default ~ student, family = "binomial", data = data)

Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-0.2970  -0.2970  -0.2434  -0.2434   2.6585  

Coefficients:
            Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept) -3.50413    0.07071  -49.55  &lt; 2e-16 ***
studentYes   0.40489    0.11502    3.52 0.000431 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 2920.6  on 9999  degrees of freedom
Residual deviance: 2908.7  on 9998  degrees of freedom
AIC: 2912.7

Number of Fisher Scoring iterations: 6</code></pre>
</div>
</div>
</section>
<section id="predicciones-continuación-1" class="slide level2">
<h2>Predicciones: continuación</h2>
<p>Así, podemos calcular las probabilidades</p>
<p><span class="math display">\[
\mathbb{P}\left( \text{default=Yes }| \text{ student=Yes}\right)=\dfrac{\exp(-3.5041+ 0.4049 \times 1)}{1+\exp(-3.5041+ 0.4049 \times 1)}\approx 0.0431
\]</span></p>
<p>y,</p>
<p><span class="math display">\[
\mathbb{P}\left( \text{default=Yes }| \text{ student=No}\right)=\dfrac{\exp(-3.5041+ 0.4049 \times 0)}{1+\exp(-3.5041+ 0.4049 \times 0)}\approx 0.0292
\]</span></p>
</section>
<section id="regresión-logística-múltiple" class="slide level2">
<h2>Regresión logística múltiple</h2>
<p>Ahora consideramos el problema de predecir una respuesta binaria usando múltiples predictores. La extensión natural del modelo de regresión es</p>
<p><span class="math display">\[
\log \left(\dfrac{p(X)}{1-p(X)}\right)=\beta_0 + \beta_1 X_1 +\dots + \beta_p X_p
\]</span></p>
<p>donde <span class="math inline">\(X=(X_1,\dots,X_p)\)</span> son <span class="math inline">\(p\)</span> predictores. La ecuación anterior la podemos reescribir como</p>
<p><span class="math display">\[
p(X)=\dfrac{\exp(\beta_0 + \beta_1 X_1 +\dots + \beta_p X_p)}{1+ \exp(\beta_0 + \beta_1 X_1 +\dots + \beta_p X_p)}
\]</span></p>
<p>Al igual que antes, usamos el método de máxima verosimilitud para estimar <span class="math inline">\(\mathbf{\beta}\)</span>.</p>
</section>
<section id="ejemplo-2" class="slide level2">
<h2>Ejemplo</h2>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
glm(formula = default ~ balance + student + income, family = "binomial", 
    data = data)

Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-2.4691  -0.1418  -0.0557  -0.0203   3.7383  

Coefficients:
              Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept) -1.087e+01  4.923e-01 -22.080  &lt; 2e-16 ***
balance      5.737e-03  2.319e-04  24.738  &lt; 2e-16 ***
studentYes  -6.468e-01  2.363e-01  -2.738  0.00619 ** 
income       3.033e-06  8.203e-06   0.370  0.71152    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 2920.6  on 9999  degrees of freedom
Residual deviance: 1571.5  on 9996  degrees of freedom
AIC: 1579.5

Number of Fisher Scoring iterations: 8</code></pre>
</div>
</div>
</section>
<section id="ejemplo-continuación-3" class="slide level2">
<h2>Ejemplo: continuación</h2>

<img data-src="images/week7/log_compare.png" class="r-stretch quarto-figure-center"></section>
<section id="regresión-logística-para-2-clases-en-la-respuesta" class="slide level2">
<h2>Regresión logística para <span class="math inline">\(&gt;2\)</span> clases en la respuesta</h2>
<p>En el caso en que tengamos más de dos clases en la variable respuesta, es posible extender la regresión lineal. En el ejemplo de determinación de diagnóstico en una sala de emergencia se tenían las categorías accidente cardiovascular, sobredosis y ataque epiléptico, por lo que se desearía modelar</p>
<p><span class="math display">\[
\mathbb{P}\left( Y= \text{ acc. card. }| X\right)
\]</span></p>
<p>y</p>
<p><span class="math display">\[
\mathbb{P}\left( Y= \text{ sobredosis }| X\right)
\]</span></p>
<p>siendo el remanente,</p>
<p><span class="math display">\[
\mathbb{P}\left( Y= \text{ ataque epiléptico }| X\right)= 1-\mathbb{P}\left( Y= \text{ acc. card }| X\right)-\mathbb{P}\left( Y= \text{ sobredosis }| X\right)
\]</span></p>
<p>Si bien es posible la extensión, en la práctica no es frecuentemente usado, pues se prefiere realizar un <strong>análisis discriminante</strong>.</p>
</section></section>
<section>
<section id="análisis-discriminante-lineal" class="title-slide slide level1 center">
<h1>Análisis discriminante lineal</h1>

</section>
<section id="introducción-1" class="slide level2">
<h2>Introducción</h2>
<p>La regresión logística que vimos antes involucra modelar directamente <span class="math inline">\(\mathbb{P}\left( Y=k|X=x\right)\)</span> usando la función logística dada por</p>
<p><span class="math display">\[
p(X)=\dfrac{\exp(\beta_0 + \beta_1 X_1 +\dots + \beta_p X_p)}{1+ \exp(\beta_0 + \beta_1 X_1 +\dots + \beta_p X_p)}
\]</span></p>
<p>para el caso de dos clases en la variable respuesta. En lo que sigue, consideramos una manera alternativa y menos directa para estimar estas probabilidades. En esta metodología, modelamos la distribución de los predictores <span class="math inline">\(X\)</span> por separado en cada una de las categorías de la variable respuesta <span class="math inline">\((Y)\)</span>, y luego usamos el teorema de Bayes para convertir estos resultados en estimaciones de <span class="math inline">\(\mathbb{P}\left(Y=k|X=x\right)\)</span>.</p>
<p>Cuando estas distribuciones se asumen normales, la forma de este modelo es muy similar a una regresión logística.</p>
</section>
<section id="teorema-de-bayes-para-clasificación" class="slide level2">
<h2>Teorema de Bayes para clasificación</h2>
<p>Supongamos que queremos clasificar una observación entre <span class="math inline">\(K\)</span> clases, donde <span class="math inline">\(K\geq 2\)</span>. Esto es, que la variable respuesta <span class="math inline">\(Y\)</span> puede tomar <span class="math inline">\(K\)</span> posibles valores distintos y no-ordenados.</p>
<p>Sea <span class="math inline">\(\pi_k\)</span> la probabilidad <em>apriori</em> que una observación escogida aleatoriamente provenga de la clase <span class="math inline">\(k-\)</span>ésima. Sea <span class="math inline">\(f_k(X)=\mathbb{P}(X=x|Y=k)\)</span> la <strong>función de densidad</strong> de <span class="math inline">\(X\)</span> para una observación que proviene de la clase <span class="math inline">\(k-\)</span>ésima. Luego, por el teorema de Bayes se tiene</p>
<p><span class="math display">\[
\mathbb{P}(Y=k|X=x)=\dfrac{\pi_k f_k(x)}{\sum_{l=1}^{K} \pi_l f_l(x)}
\]</span></p>
<p>al igual que antes usamos la notación <span class="math inline">\(p_k(X)=\mathbb{P}(Y=k|X)\)</span>.</p>
</section>
<section id="teorema-de-bayes-para-clasificación-continuación" class="slide level2">
<h2>Teorema de Bayes para clasificación: continuación</h2>
<p>La idea general, es no estimar <span class="math inline">\(p_k(X)\)</span> directamente, sino estimar <span class="math inline">\(\pi_k\)</span> y <span class="math inline">\(f_k\)</span> para obtener lo deseado.</p>
<p>Usualmente <span class="math inline">\(\pi_k\)</span> es fácil de obtener si se tiene una muestra aleatoria de <span class="math inline">\(Y\)</span>, pues obtenemos estas estimaciones como las proporciones de cada clase.</p>
<p>En cambio, estimar <span class="math inline">\(f_k(X)\)</span> tiende a ser más difícil, a menos que se asuman formas simples para las densidades.</p>
<p>Llamamos a la cantidad <span class="math inline">\(p_k(x)\)</span> la probabilidad <em>posterior</em> que una observación <span class="math inline">\(X=x\)</span> pertenezca a la clase <span class="math inline">\(k-\)</span>ésima.</p>
</section>
<section id="análisis-discriminante-lineal-con-p1" class="slide level2">
<h2>Análisis discriminante lineal con <span class="math inline">\(p=1\)</span></h2>
<p>Primero asumiremos que <span class="math inline">\(p=1\)</span>, es decir, sólo tenemos un predictor. Deseamos obtener una estimación para <span class="math inline">\(f_k(x)\)</span> para utilizarlo en la ecuación</p>
<p><span class="math display">\[
\mathbb{P}(Y=k|X=x)=\dfrac{\pi_k f_k(x)}{\sum_{l=1}^{K} \pi_l f_l(x)}
\]</span></p>
<p>y así poder estimar <span class="math inline">\(p_k(x)\)</span>. Para poder estimar <span class="math inline">\(f_k\)</span>, primero debemos asumir su forma, por lo que asumiremos que <span class="math inline">\(f_k\)</span> es <em>Gaussiana</em>. Por lo que,</p>
<p><span class="math display">\[
f_k(x)=\dfrac{1}{\sqrt{2\pi}\sigma_k}\exp\left( -\dfrac{1}{2\sigma_{k}^{2}}(x-\mu_k)^2\right)
\]</span></p>
<p>donde <span class="math inline">\(\mu_k\)</span> y <span class="math inline">\(\sigma_{k}^{2}\)</span> son la media y la varianza de la clase <span class="math inline">\(k-\)</span>ésima. Por ahora, asumiremos que <span class="math inline">\(\sigma_{1}^{2}=\dots=\sigma_{K}^{2}=\sigma^2\)</span></p>
</section>
<section id="análisis-discriminante-lineal-con-p1-continuación" class="slide level2">
<h2>Análisis discriminante lineal con <span class="math inline">\(p=1\)</span>: continuación</h2>
<p>Por lo anterior, se tendrá</p>
<p><span class="math display">\[
p_k(x)=\dfrac{\pi_k \dfrac{1}{\sqrt{2\pi}\sigma}\exp\left( -\dfrac{1}{2\sigma^{2}}(x-\mu_k)^2\right)}{\sum_{l=1}^{K}\pi_l\dfrac{1}{\sqrt{2\pi}\sigma}\exp\left( -\dfrac{1}{2\sigma^{2}}(x-\mu_l)^2\right) }
\]</span></p>
<p>El clasificador Bayesiano asigna una observacion <span class="math inline">\(X=x\)</span> a la clase que su <span class="math inline">\(p_k(x)\)</span> es más grande. Si tomamos el logaritmo y arreglamos términos en la expresión anterior, se tiene que el proceso es equivalente a asignar la observación a la clase en la que</p>
<p><span class="math display">\[
\delta_k(x)=x \dfrac{\mu_k}{\sigma^2}-\dfrac{\mu_{k}^{2}}{2\sigma^2}+\log \pi_k
\]</span></p>
<p>es más grande.</p>
</section>
<section id="análisis-discriminante-lineal-con-p1-continuación-1" class="slide level2">
<h2>Análisis discriminante lineal con <span class="math inline">\(p=1\)</span>: continuación</h2>
<p>Por ejemplo, si <span class="math inline">\(K=2\)</span> Y <span class="math inline">\(\pi_1=\pi_2\)</span>, entonces el clasificador Bayesiano asigna una observación a la clase 1 si <span class="math inline">\(2x(\mu_1-\mu_2)&gt;\mu_{1}^{2}-\mu_{2}^{2}\)</span> y a la clase 2 en caso contrario. En este caso, el límite de decisión de Bayes (<em>Bayes decision boundary</em>) corresponde al punto donde</p>
<p><span class="math display">\[
x=\dfrac{\mu_{1}^{2}-\mu_{2}^{2}}{2(\mu_1-\mu_2)}=\dfrac{\mu_1+\mu_2}{2}
\]</span></p>
<p>Llamamos a este, el punto (o área) en donde la clasificación es ambigua.</p>
</section>
<section id="análisis-discriminante-lineal-con-p1-continuación-2" class="slide level2">
<h2>Análisis discriminante lineal con <span class="math inline">\(p=1\)</span>: continuación</h2>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1"></a><span class="fu">ggplot</span>(<span class="fu">data.frame</span>(<span class="at">x =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">4</span>, <span class="dv">4</span>)), <span class="fu">aes</span>(x)) <span class="sc">+</span> <span class="fu">stat_function</span>(<span class="at">fun =</span> dnorm, <span class="at">args =</span> <span class="fu">list</span>(<span class="at">mean =</span> <span class="sc">-</span><span class="fl">1.25</span>, <span class="at">sd =</span> <span class="dv">1</span>), <span class="at">color =</span> <span class="st">"firebrick"</span>) <span class="sc">+</span> <span class="fu">stat_function</span>(<span class="at">fun =</span> dnorm, <span class="at">args =</span> <span class="fu">list</span>(<span class="at">mean =</span> <span class="fl">1.25</span>, <span class="at">sd =</span> <span class="dv">1</span>), <span class="at">color =</span> <span class="st">"green3"</span>) <span class="sc">+</span><span class="fu">geom_vline</span>(<span class="at">xintercept =</span> <span class="dv">0</span>, <span class="at">linetype =</span> <span class="st">"longdash"</span>) <span class="sc">+</span> <span class="fu">theme_bw</span>()</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>

</div>
<img data-src="lec_week7_files/figure-revealjs/unnamed-chunk-16-1.png" width="960" class="r-stretch quarto-figure-center"></section>
<section id="análisis-discriminante-lineal-con-p1-continuación-3" class="slide level2">
<h2>Análisis discriminante lineal con <span class="math inline">\(p=1\)</span>: continuación</h2>
<p>El análisis discriminante lineal (LDA) aproxima el clasificador bayesiano ingresando estimaciones para <span class="math inline">\(pi_k,\mu_k\)</span> y <span class="math inline">\(\sigma^2\)</span> en <span class="math inline">\(\delta_k(x)\)</span>. Particularmente, las siguientes estimaciones son usadas.</p>
<p><span class="math display">\[
\hat{\mu}_k=\dfrac{1}{n_k}\sum_{i:y_i=k}x_i
\]</span></p>
<p>y,</p>
<p><span class="math display">\[
\hat{\sigma}^{2}=\dfrac{1}{n-K}\sum_{k=1}^{K}\sum_{i:y_i=K}(x_i-\hat{\mu}_k)^2
\]</span></p>
<p>donde <span class="math inline">\(n\)</span> es el número total de observaciones en el conjunto de entrenamiento, <span class="math inline">\(n_k\)</span> es el número de observaciones en el conjunto de entrenamiento en la clase <span class="math inline">\(k-\)</span>ésima.</p>
</section>
<section id="análisis-discriminante-lineal-con-p1-continuación-4" class="slide level2">
<h2>Análisis discriminante lineal con <span class="math inline">\(p=1\)</span>: continuación</h2>
<p>En el caso de que no tengamos información de <span class="math inline">\(\pi_1,\dots,\pi_K\)</span>, el análisis discriminante lineal estima <span class="math inline">\(\pi_k\)</span> usando la proporción de las observaciones en el conjunto de entrenamiento que pertenece a la clase <span class="math inline">\(k-\)</span>ésima. Esto es,</p>
<p><span class="math display">\[
\hat{\pi}_k=\dfrac{n_k}{n}
\]</span></p>
<p>El clasificador <strong>LDA</strong> reemplaza las estimaciones anteriores en <span class="math inline">\(\delta_k(x)\)</span> y asigna una observación <span class="math inline">\(X=x\)</span> a la clase en la cual</p>
<p><span class="math display">\[
\hat{\delta}_k=x\dfrac{\hat{\mu}_k}{\hat{\sigma}^2}-\dfrac{\hat{\mu}_{k}^{2}}{\hat{2\sigma}^2}+\log \hat{\pi}_k
\]</span></p>
<p>es más grande. El nombre de <strong>lineal</strong> viene de la linealidad de la <em>función discriminante</em> <span class="math inline">\(\hat{\delta}_k\)</span> para <span class="math inline">\(x\)</span>.</p>
</section>
<section id="análisis-discriminante-lineal-con-p1-continuación-5" class="slide level2">
<h2>Análisis discriminante lineal con <span class="math inline">\(p=1\)</span>: continuación</h2>

<img data-src="lec_week7_files/figure-revealjs/unnamed-chunk-18-1.png" width="960" class="r-stretch quarto-figure-center"></section>
<section id="análisis-discriminante-lineal-con-p1-1" class="slide level2">
<h2>Análisis discriminante lineal con <span class="math inline">\(p&gt;1\)</span></h2>
<p>En lo que sigue, vamos a extender las nociones de análisis discriminante cuando se tienen múltiples predictores, para ello asumiremos que <span class="math inline">\(X=(X_1,X_2,\dots,X_p)\)</span> es obtenido desde una distribución normal multivariada, con medias por clase e igual matriz de varianza-covarianza.</p>
<p>Recordar que si <span class="math inline">\(X\sim N(\mu,\Sigma)\)</span> con <span class="math inline">\(\mathbb{E}(X)=\mu\)</span> (vector de medias) y <span class="math inline">\(Cov(X)=\Sigma\)</span> la matriz <span class="math inline">\(p\times p\)</span> de covarianza de <span class="math inline">\(X\)</span>. Formalmente, la densidad de <span class="math inline">\(X\)</span> se define como:</p>
<p><span class="math display">\[
f(x)=\dfrac{1}{(2\pi)^{p/2}|\Sigma|^{1/2}}\exp\left( -\dfrac{1}{2}(x-\mu)^{T} \Sigma^{-1}(x-\mu)\right)
\]</span></p>
<p>En el caso de <span class="math inline">\(p&gt;1\)</span> predictores, el análisis discriminante lineal asume que las observaciones en la clase <span class="math inline">\(k-\)</span>ésima son obtenidos desde una distribución normal multivariada.</p>
</section>
<section id="análisis-discriminante-lineal-con-p1-continuación-6" class="slide level2">
<h2>Análisis discriminante lineal con <span class="math inline">\(p&gt;1\)</span>: continuación</h2>
<p>Si reemplazamos la función de densidad para la clase <span class="math inline">\(k-\)</span>ésima, <span class="math inline">\(f_k(X=x)\)</span> en la ecuación</p>
<p><span class="math display">\[
\mathbb{P}(Y=k|X=x)=\dfrac{\pi_k f_k(x)}{\sum_{l=1}^{K} \pi_l f_l(x)}
\]</span></p>
<p>y usando un poco de álgebra, se puede reescribir <span class="math inline">\(\delta_k(x)\)</span> como</p>
<p><span class="math display">\[
\delta_k(x)=x^T\Sigma^{-1} \mu_k-\dfrac{1}{2}\mu_{k}^{T} \Sigma^{-1} \mu_k +\log \pi_k
\]</span></p>
<p>y el clasificador bayesiano asigna la observación <span class="math inline">\(X=x\)</span> a la clase que tienen mayor <span class="math inline">\(\delta_{k}(x)\)</span>.</p>
</section>
<section id="análisis-discriminante-lineal-con-p1-continuación-7" class="slide level2">
<h2>Análisis discriminante lineal con <span class="math inline">\(p&gt;1\)</span>: continuación</h2>

<img data-src="images/week7/lda_1.png" class="r-stretch quarto-figure-center"></section>
<section id="análisis-discriminante-lineal-con-p1-continuación-8" class="slide level2">
<h2>Análisis discriminante lineal con <span class="math inline">\(p&gt;1\)</span>: continuación</h2>
<p>En la figura anterior, las elipses representan las regiones que contienen <span class="math inline">\(95\%\)</span> de la probabilidad de cada una de las clases. Al igual que antes, la línea punteada es el <strong>Límite de decisión Bayes</strong>. Es decir, representan el conjunto de valores <span class="math inline">\(x\)</span> para los cuales <span class="math inline">\(\delta_k(x)=\delta_\ell(x)\)</span>, esto es:</p>
<p><span class="math display">\[
x^T\Sigma^{-1} \mu_k-\dfrac{1}{2}\mu_{k}^{T} \Sigma^{-1} \mu_k=x^T\Sigma^{-1} \mu_l-\dfrac{1}{2}\mu_{l}^{T} \Sigma^{-1} \mu_l
\]</span></p>
<p>para <span class="math inline">\(k\neq l\)</span>.</p>
</section>
<section id="ejemplo-3" class="slide level2">
<h2>Ejemplo</h2>
<div class="cell">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1"></a><span class="fu">library</span>(MASS)</span>
<span id="cb11-2"><a href="#cb11-2"></a>mod_lda <span class="ot">&lt;-</span> <span class="fu">lda</span>(Species <span class="sc">~</span> Sepal.Width <span class="sc">+</span> Sepal.Length <span class="sc">+</span> Petal.Length <span class="sc">+</span> Petal.Width, <span class="at">data =</span> iris)</span>
<span id="cb11-3"><a href="#cb11-3"></a>mod_lda</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Call:
lda(Species ~ Sepal.Width + Sepal.Length + Petal.Length + Petal.Width, 
    data = iris)

Prior probabilities of groups:
    setosa versicolor  virginica 
 0.3333333  0.3333333  0.3333333 

Group means:
           Sepal.Width Sepal.Length Petal.Length Petal.Width
setosa           3.428        5.006        1.462       0.246
versicolor       2.770        5.936        4.260       1.326
virginica        2.974        6.588        5.552       2.026

Coefficients of linear discriminants:
                    LD1         LD2
Sepal.Width   1.5344731  2.16452123
Sepal.Length  0.8293776  0.02410215
Petal.Length -2.2012117 -0.93192121
Petal.Width  -2.8104603  2.83918785

Proportion of trace:
   LD1    LD2 
0.9912 0.0088 </code></pre>
</div>
</div>
</section>
<section id="ejemplo-continuación-4" class="slide level2">
<h2>Ejemplo: continuación</h2>
<div class="cell">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1"></a>predicciones <span class="ot">&lt;-</span> <span class="fu">predict</span>(<span class="at">object =</span> mod_lda, <span class="at">newdata =</span> iris[, <span class="sc">-</span><span class="dv">5</span>])</span>
<span id="cb13-2"><a href="#cb13-2"></a><span class="fu">table</span>(iris<span class="sc">$</span>Species, predicciones<span class="sc">$</span>class, <span class="at">dnn =</span> <span class="fu">c</span>(<span class="st">"Clase real"</span>, <span class="st">"Clase predicha"</span>))</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>            Clase predicha
Clase real   setosa versicolor virginica
  setosa         50          0         0
  versicolor      0         48         2
  virginica       0          1        49</code></pre>
</div>
</div>
</section>
<section id="ejemplo-continuación-5" class="slide level2">
<h2>Ejemplo: continuación</h2>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1"></a><span class="fu">library</span>(klaR)</span>
<span id="cb15-2"><a href="#cb15-2"></a><span class="fu">partimat</span>(Species <span class="sc">~</span> Sepal.Width <span class="sc">+</span> Sepal.Length <span class="sc">+</span> Petal.Length <span class="sc">+</span> Petal.Width, <span class="at">data =</span> iris, <span class="at">method =</span> <span class="st">"lda"</span>, <span class="at">prec =</span> <span class="dv">200</span>,  <span class="at">image.colors =</span> <span class="fu">c</span>(<span class="st">"darkgoldenrod1"</span>, <span class="st">"snow2"</span>, <span class="st">"skyblue2"</span>), <span class="at">col.mean =</span> <span class="st">"firebrick"</span>)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>

</div>
<img data-src="lec_week7_files/figure-revealjs/unnamed-chunk-24-1.png" width="960" class="r-stretch quarto-figure-center"></section>
<section id="métricas-para-clasificación" class="slide level2">
<h2>Métricas para clasificación</h2>
<p>En problemas de clasificación, existen un gran número de métricas para evaluar el desempeño de un modelo. Por ejemplo, para el ejemplo de morosidad:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1"></a><span class="fu">library</span>(caret)</span>
<span id="cb16-2"><a href="#cb16-2"></a><span class="fu">confusionMatrix</span>(<span class="fu">table</span>(<span class="fu">predict</span>(logit2, <span class="at">type=</span><span class="st">"response"</span>) <span class="sc">&gt;=</span> <span class="fl">0.5</span>, data<span class="sc">$</span>default <span class="sc">==</span> <span class="st">"Yes"</span>))</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Confusion Matrix and Statistics

       
        FALSE TRUE
  FALSE  9627  228
  TRUE     40  105
                                          
               Accuracy : 0.9732          
                 95% CI : (0.9698, 0.9763)
    No Information Rate : 0.9667          
    P-Value [Acc &gt; NIR] : 0.0001044       
                                          
                  Kappa : 0.4278          
                                          
 Mcnemar's Test P-Value : &lt; 2.2e-16       
                                          
            Sensitivity : 0.9959          
            Specificity : 0.3153          
         Pos Pred Value : 0.9769          
         Neg Pred Value : 0.7241          
             Prevalence : 0.9667          
         Detection Rate : 0.9627          
   Detection Prevalence : 0.9855          
      Balanced Accuracy : 0.6556          
                                          
       'Positive' Class : FALSE           
                                          </code></pre>
</div>
</div>
</section>
<section id="métricas-para-clasificación-continuación" class="slide level2">
<h2>Métricas para clasificación: continuación</h2>
<p>La función <code>confusionMatrix()</code> nos entrega la <strong>matriz de confusión</strong> junto con varias métricas asociadas. Esta matriz en su forma más esencial es:</p>

<img data-src="images/week7/confusion.png" class="r-stretch quarto-figure-center"></section>
<section id="análisis-discriminante-cuadrático" class="slide level2">
<h2>Análisis discriminante cuadrático</h2>
<p>El <strong>análisis discriminante cuadrático</strong> es una alternativa a <em>LDA</em>, en la que se asumía distribución normal e igual varianza en cada una de las clases. Si bien, en el análisis discriminante cuadrático (<strong>QDA</strong>) también se asume que los datos provienen desde una distribución normal y estima los parámetros para predecir. Sin embargo, el <strong>QDA</strong> asume que cada clase tienen su propia matriz de covarianza.</p>
<p>Esto es, se asume que una observación proveniente de la clase <span class="math inline">\(k-\)</span>ésima es de la forma <span class="math inline">\(X\sim N(\mu_k,\Sigma_k)\)</span>, donde <span class="math inline">\(\Sigma_k\)</span> es la matriz de covarianza para la clase <span class="math inline">\(k-\)</span>ésima.</p>
</section>
<section id="análisis-discriminante-cuadrático-continuación" class="slide level2">
<h2>Análisis discriminante cuadrático: continuación</h2>
<p>Bajo estos supuestos, el clasificador bayesiano asigna una observación <span class="math inline">\(X=x\)</span> a la clase en la que</p>
<span class="math display">\[\begin{align*}
\delta_k(x)&amp;=-\dfrac{1}{2}(x-\mu_k)^{T}\Sigma_{k}^{-1}(x-\mu_k)+\log \pi_k \\
&amp;=-\dfrac{1}{2}x^{T} \Sigma_{k}^{-1}x+x^{T}\Sigma_{k}^{-1}\mu_k-\dfrac{1}{2}\mu_{k}^{T}\mu_k+\log \pi_k
\end{align*}\]</span>
<p>es mayor. Así, se requerirá estimar <span class="math inline">\(\Sigma_k,\mu_k\)</span> y <span class="math inline">\(\pi_k\)</span>. El nombre de cuadrático viene debido a que <span class="math inline">\(x\)</span> aparece como una función cuadrática en la ecuación anterior.</p>
</section>
<section id="lda-o-qda" class="slide level2">
<h2>¿LDA o QDA?</h2>
<p>Si tenemos <span class="math inline">\(p\)</span> predictores, estimar la matriz de covarianza requiere estimar <span class="math inline">\(p(p+1)/2\)</span> parámetros. En el caso de <strong>QDA</strong> se estima una matriz de covarianza para cada clase, por lo que se deben estimar <span class="math inline">\(Kp(p+1)/2\)</span> parámetros. Si asumimos que las <span class="math inline">\(K\)</span> clases comparten la misma matriz de covarianza, el modelo de <strong>LDA</strong> es lineal en <span class="math inline">\(x\)</span>, lo que significa que se debe estimar <span class="math inline">\(Kp\)</span> parámetros.</p>
<p>En general, el discriminante lineal es menos flexible que su contraparte cuadrática, y tiene una varianza sustancialmente menor. Sin embargo, si el supuesto de igualdad de matrices de covarianza entre las clases es erróneo, provocará que el discriminante lineal tenga un enorme sesgo.</p>
</section>
<section id="lda-o-qda-continuación" class="slide level2">
<h2>¿LDA o QDA?: continuación</h2>
<p>Usualmente, <strong>LDA</strong> tiende a ser mejor que <strong>QDA</strong> si se tienen pocas observaciones en el conjunto de entrenamiento, por lo que reducir la varianza es particularmente importante.</p>
<p>En contraste, <strong>QDA</strong> es recomendado si el conjunto de entrenamiento es grande, de manera que la varianza del clasificador no sea tan relevante, o si el supuesto de igual matriz de covarianza en las distintas clases es claramente insostenible.</p>
</section>
<section id="lda-o-qda-continuación-1" class="slide level2">
<h2>¿LDA o QDA?: continuación</h2>

<img data-src="images/week7/lda_qda.png" class="r-stretch quarto-figure-center"></section></section>
<section id="qué-veremos-la-próxima-semana" class="title-slide slide level1 center">
<h1>¿Qué veremos la próxima semana?</h1>
<ul>
<li class="fragment">Métodos supervisados: continuación</li>
</ul>
</section>

<section id="que-deben-preparar-para-la-próxima-semana" class="title-slide slide level1 center">
<h1>¿Que deben preparar para la próxima semana?</h1>
<ul>
<li class="fragment">Capítulo 3 , Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems. Géron, Aurélien.</li>
<li class="fragment">Capítulo 4, An Introduction to Statistical Learning with Applications in R.</li>
</ul>


<img src="images/logo_usm.png" class="slide-logo r-stretch"><div class="footer footer-default">
<p>IND 163 - Semana 7</p>
</div>
</section>
    </div>
  </div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="../site_libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="../site_libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="../site_libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="../site_libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="../site_libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="../site_libs/revealjs/plugin/notes/notes.js"></script>
  <script src="../site_libs/revealjs/plugin/search/search.js"></script>
  <script src="../site_libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="../site_libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': false,
'smaller': false,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'fade',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1600,

        height: 900,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    
    <script>
      // htmlwidgets need to know to resize themselves when slides are shown/hidden.
      // Fire the "slideenter" event (handled by htmlwidgets.js) when the current
      // slide changes (different for each slide format).
      (function () {
        function fireSlideChanged(previousSlide, currentSlide) {

          // dispatch for htmlwidgets
          const event = window.document.createEvent("Event");
          event.initEvent("slideenter", true, true);
          window.document.dispatchEvent(event);

          // dispatch for shiny
          if (window.jQuery) {
            if (previousSlide) {
              window.jQuery(previousSlide).trigger("hidden");
            }
            if (currentSlide) {
              window.jQuery(currentSlide).trigger("shown");
            }
          }
        }

        // hookup for reveal
        if (window.Reveal) {
          window.Reveal.addEventListener("slidechanged", function(event) {
            fireSlideChanged(event.previousSlide, event.currentSlide);
          });
        }

        // hookup for slidy
        if (window.w3c_slidy) {
          window.w3c_slidy.add_observer(function (slide_num) {
            // slide_num starts at position 1
            fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);
          });
        }

      })();
    </script>

    <script id="quarto-html-after-body" type="application/javascript">
    window.document.addEventListener("DOMContentLoaded", function (event) {
      const toggleBodyColorMode = (bsSheetEl) => {
        const mode = bsSheetEl.getAttribute("data-mode");
        const bodyEl = window.document.querySelector("body");
        if (mode === "dark") {
          bodyEl.classList.add("quarto-dark");
          bodyEl.classList.remove("quarto-light");
        } else {
          bodyEl.classList.add("quarto-light");
          bodyEl.classList.remove("quarto-dark");
        }
      }
      const toggleBodyColorPrimary = () => {
        const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
        if (bsSheetEl) {
          toggleBodyColorMode(bsSheetEl);
        }
      }
      toggleBodyColorPrimary();  
      const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
      tabsets.forEach(function(tabset) {
        const tabby = new Tabby('#' + tabset.id);
      });
      const clipboard = new window.ClipboardJS('.code-copy-button', {
        target: function(trigger) {
          return trigger.previousElementSibling;
        }
      });
      clipboard.on('success', function(e) {
        // button target
        const button = e.trigger;
        // don't keep focus
        button.blur();
        // flash "checked"
        button.classList.add('code-copy-button-checked');
        var currentTitle = button.getAttribute("title");
        button.setAttribute("title", "Copiada");
        setTimeout(function() {
          button.setAttribute("title", currentTitle);
          button.classList.remove('code-copy-button-checked');
        }, 1000);
        // clear code selection
        e.clearSelection();
      });
      function tippyHover(el, contentFn) {
        const config = {
          allowHTML: true,
          content: contentFn,
          maxWidth: 500,
          delay: 100,
          arrow: false,
          appendTo: function(el) {
              return el.closest('section.slide') || el.parentElement;
          },
          interactive: true,
          interactiveBorder: 10,
          theme: 'quarto-reveal',
          placement: 'bottom-start'
        };
          config['offset'] = [0,0];
          config['maxWidth'] = 700;
        window.tippy(el, config); 
      }
      const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
      for (var i=0; i<noterefs.length; i++) {
        const ref = noterefs[i];
        tippyHover(ref, function() {
          let href = ref.getAttribute('href');
          try { href = new URL(href).hash; } catch {}
          const id = href.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          return note.innerHTML;
        });
      }
      var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
      for (var i=0; i<bibliorefs.length; i++) {
        const ref = bibliorefs[i];
        const cites = ref.parentNode.getAttribute('data-cites').split(' ');
        tippyHover(ref, function() {
          var popup = window.document.createElement('div');
          cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    });
    </script>
    

</body></html>
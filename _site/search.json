[
  {
    "objectID": "slides/lec_week2.html#escuelas-de-probabilidad",
    "href": "slides/lec_week2.html#escuelas-de-probabilidad",
    "title": "Conceptos Básicos",
    "section": "Escuelas de probabilidad",
    "text": "Escuelas de probabilidad\n\nEnfoque clásico\nEnfoque frecuentista\nEnfoque bayesiano"
  },
  {
    "objectID": "slides/lec_week2.html#enfoque-clásico",
    "href": "slides/lec_week2.html#enfoque-clásico",
    "title": "Conceptos Básicos",
    "section": "Enfoque clásico",
    "text": "Enfoque clásico\nEste enfoque también llamado enfoque apriori tiene por característica principal la asignación igualitaria de una medida de ocurrencia para un resultado de un experimento aleatorio (experimento equiprobable).\n\nEsta asignación de probabilidad se determina antes de observar los resultados experimentales.\n\n\n\n¿Algún ejemplo?"
  },
  {
    "objectID": "slides/lec_week2.html#enfoque-frecuentista",
    "href": "slides/lec_week2.html#enfoque-frecuentista",
    "title": "Conceptos Básicos",
    "section": "Enfoque frecuentista",
    "text": "Enfoque frecuentista\nEste enfoque también llamado enfoque empírico, determina la medida de ocurrencia con base en la proporción de veces que ocurre un resultado favorable en un determinado número de observaciones o experimentos. Este enfoque no asigna probabilidades a priori a los posibles resultados de un experimento aleatorio.\n\n\n¿Algún ejemplo?"
  },
  {
    "objectID": "slides/lec_week2.html#enfoque-bayesiano",
    "href": "slides/lec_week2.html#enfoque-bayesiano",
    "title": "Conceptos Básicos",
    "section": "Enfoque bayesiano",
    "text": "Enfoque bayesiano\nEste enfoque también llamado enfoque subjetivo, determina la medida de ocurrencia en base a una expectativa razonable basado en el conocimiento del investigador.\nEl enfoque bayesiano es particularmente útil cuando se tiene poca información del experimento, y este puede ser realizado para actualizador mis probabilidades, esto debido a que cada realización del experimento aleatorio me otorgará información adicional para determinar correctamente mis probabilidades."
  },
  {
    "objectID": "slides/lec_week2.html#conceptos-fundamentales",
    "href": "slides/lec_week2.html#conceptos-fundamentales",
    "title": "Conceptos Básicos",
    "section": "Conceptos fundamentales",
    "text": "Conceptos fundamentales\n\nEspacio muestral: Se define como el conjunto de todos los posibles resultados del experimento, lo anotamos por \\(\\Omega\\).\nSuceso o evento: Es cualquier subconjunto de \\(\\Omega\\), usualmente lo anotamos con letras mayúsculas. \\((A,B,C,\\dots)\\).\nEspacio de sucesos: Es el conjunto de todos los subconjuntos de \\(\\Omega\\). Lo anotamos por \\(2^{\\Omega}\\).\n\\(\\sigma\\)-álgebra: Es una familia de subconjuntos del espacio de sucesos, \\(\\Sigma \\subset 2^{\\Omega}\\), y que cumplen con ciertas propiedades."
  },
  {
    "objectID": "slides/lec_week2.html#clasificación-del-espacio-muestral",
    "href": "slides/lec_week2.html#clasificación-del-espacio-muestral",
    "title": "Conceptos Básicos",
    "section": "Clasificación del espacio muestral",
    "text": "Clasificación del espacio muestral\n\nDiscreto\n\nNumerable: Finito o Infinito.\n\nContinuo\n\nNo numerable: Acotado o No acotado."
  },
  {
    "objectID": "slides/lec_week2.html#definición-formal-de-probabilidad",
    "href": "slides/lec_week2.html#definición-formal-de-probabilidad",
    "title": "Conceptos Básicos",
    "section": "Definición formal de probabilidad",
    "text": "Definición formal de probabilidad\nEl par \\((\\Omega,\\Sigma)\\) se dice espacio medible, y la función \\(\\mathbb{P}:\\Sigma \\rightarrow \\mathbb{R}^{+}\\), es una medida de probabilidad si satisface:\n\n\\(0\\leq \\mathbb{P}[A] \\leq 1, \\forall A \\in \\Sigma\\)\n\\(\\mathbb{P}[\\Omega]=1\\)\nDados \\(\\displaystyle A_1,A_2,\\dots \\in \\Sigma \\Rightarrow \\mathbb{P}\\left[ \\bigcup_{i=1}^{n} A_n \\right] = \\sum_{i=1}^{n} \\mathbb{P}[A_i], \\hspace{5pt} \\forall i\\)"
  },
  {
    "objectID": "slides/lec_week2.html#algunas-propiedades",
    "href": "slides/lec_week2.html#algunas-propiedades",
    "title": "Conceptos Básicos",
    "section": "Algunas propiedades",
    "text": "Algunas propiedades\n\n\\(\\mathbb{P}[A]+\\mathbb{P}[A^c]=\\mathbb{P}[\\Omega]\\)\n\\(\\mathbb{P}[\\phi]=1-\\mathbb{P}[\\phi^c]=1-\\mathbb{P}[\\Omega]=0\\)\n\\(\\mathbb{P}[A \\cup B]=\\mathbb{P}[A]+\\mathbb{P}[B] - \\mathbb{P}[A\\cap B]\\) . Si este último término \\((\\mathbb{P}[A\\cap B])\\) es cero, se dice que \\(A\\) y \\(B\\) son eventos mutuamente excluyentes.\n\\(\\mathbb{P}[A-B]=\\mathbb{P}[A\\cap B^c]\\)\n\\(\\mathbb{P}[A \\cap B]=\\mathbb{P}[A]\\mathbb{P}[B]\\). Si \\(A\\) y \\(B\\) son independientes."
  },
  {
    "objectID": "slides/lec_week2.html#definición-básica",
    "href": "slides/lec_week2.html#definición-básica",
    "title": "Conceptos Básicos",
    "section": "Definición Básica",
    "text": "Definición Básica\nUna Variable aleatoria, es una función que permite trabajar cualquier espacio muestral de manera cuantitativa. Se dice que \\(X\\) es una variable aleatoria si es una función que toma los elementos de \\(\\Omega\\) y los transforma en puntos sobre la recta de los reales. Esto es:\n\\[\\begin{align*}\n  X: \\quad &\\Omega \\longrightarrow \\mathbb{R}\\\\\n           &\\omega \\longrightarrow X(\\omega)\n\\end{align*}\\]\n\nEl conjunto de todas las posibles realizaciones es llamado el soporte y lo denotamos por \\(R_X\\)."
  },
  {
    "objectID": "slides/lec_week2.html#tipos-de-variables-aleatorias",
    "href": "slides/lec_week2.html#tipos-de-variables-aleatorias",
    "title": "Conceptos Básicos",
    "section": "Tipos de variables aleatorias",
    "text": "Tipos de variables aleatorias\nSe dice que \\(X\\) es una Variable Aleatoria si es una función que toma valores en probabilidad, es decir, no se puede predecir con certeza sus resultados.\nUna variable aleatoria es siempre cuantitativa y se puede clasificar en los siguientes grupos:\n\\[X(\\omega) \\begin{cases}\n\\text{Discreto}\n\\begin{cases}\n\\text{Finito}\\\\\n\\text{Infinito}\n\\end{cases}\\\\\n\\text{Continuo}\n\\begin{cases}\n\\text{Acotados}\\\\\n\\text{No Acotados}\n\\end{cases}\n\\end{cases}\\]"
  },
  {
    "objectID": "slides/lec_week2.html#variables-aleatorias-discretas",
    "href": "slides/lec_week2.html#variables-aleatorias-discretas",
    "title": "Conceptos Básicos",
    "section": "Variables aleatorias discretas",
    "text": "Variables aleatorias discretas\nUna variable aleatoria \\(X\\) es llamada discreta si:\n\nSu soporte \\(R_X\\) es un conjunto numerable.\nExiste una función \\(p_X:\\mathbb{R}\\rightarrow [0,1]\\), llamada la función de masa de probabilidad de \\(X\\), tal que, para cualquier \\(x\\in \\mathbb{R}\\):\n\n\n\\[p_X(x)\\begin{cases} \\mathbb{P}(X=x) \\quad &\\text{si } x\\in R_X\\\\ 0 \\quad &\\text{si } x\\notin R_X\\end{cases}\\]\n\n\nEsta función tiene dos características principales:\n\nno-negatividad: \\(p_X(x)\\geq 0\\) para cualquier \\(x\\in \\mathbb{R}\\).\nSuma sobre su soporte es 1: \\(\\sum_{x\\in R_X}p_X(x)=1\\)"
  },
  {
    "objectID": "slides/lec_week2.html#variables-aleatorias-continuas",
    "href": "slides/lec_week2.html#variables-aleatorias-continuas",
    "title": "Conceptos Básicos",
    "section": "Variables aleatorias continuas",
    "text": "Variables aleatorias continuas\nUna variable aleatoria \\(X\\) es llamada continua si:\n\nSu soporte \\(R_X\\) es un conjunto no-numerable.\nExiste una función \\(f_X:\\mathbb{R}\\rightarrow [0,1]\\), llamada función de densidad de probabilidad de \\(X\\), tal que, para cualquier intervalo \\([a,b]\\subseteq \\mathbb{R}\\):\n\n\n\\[\\mathbb{P}(X\\in [a,b])=\\int_{a}^{b}f_X(x)dx\\]\n\n\nEsta función tiene dos características principales:\n\nno-negatividad: \\(f_X(x)\\geq 0\\) para cualquier \\(x\\in \\mathbb{R}\\).\nIntegral sobre \\(\\mathbb{R}\\) es 1: \\(\\int_{-\\infty}^{\\infty} f_X(x)dx=1\\)."
  },
  {
    "objectID": "slides/lec_week2.html#función-de-distribución",
    "href": "slides/lec_week2.html#función-de-distribución",
    "title": "Conceptos Básicos",
    "section": "Función de distribución",
    "text": "Función de distribución\nLas variables aleatorias son usualmente caracterizadas en términos de sus funciones de distribución.\n\nSea \\(X\\) una variable aleatoria. La función de distribución de \\(X\\) es una función \\(F_X:\\mathbb{R}\\rightarrow [0,1]\\) tal que:\n\\[F_X(x)=\\mathbb{P}(X\\leq x), \\forall x\\in \\mathbb{R}\\]\n\n\nSi conocemos la función de distribución de una variable aleatoria \\(X\\), entonces podemos fácilmente calcular la probabilidad que \\(X\\) pertenezca a un intervalo \\((a,b] \\subseteq \\mathbb{R}\\) como:\n\\[\\mathbb{P}(a<X<b)=F_X(b)-F_X(a)\\]"
  },
  {
    "objectID": "slides/lec_week2.html#valores-esperados",
    "href": "slides/lec_week2.html#valores-esperados",
    "title": "Conceptos Básicos",
    "section": "Valores esperados",
    "text": "Valores esperados\nSea \\(X\\) una variable aleatoria, entonces se define el valor esperado de una función real \\(g(X)\\), como:\n\\[\\mathbb{E}[g(X)]= \\begin{cases} \\sum_{x\\in \\mathbb{R}} g(X)P(X=x)\\\\ \\int_{x\\in \\mathbb{R}} g(X)f(x)dx \\end{cases}\\]\nSi \\(g(X)=X\\), diremos que el valor esperado o esperanza matemática de \\(X\\) es:\n\\[\\mathbb{E}(X)=\\begin{cases}\\sum_{x\\in \\mathbb{R}} x P(X=x)\\\\ \\int_{x\\in \\mathbb{R}} x f(x)dx \\end{cases}\\]\nPara variables de tipo discreta y continua, respectivamente."
  },
  {
    "objectID": "slides/lec_week2.html#propiedades-de-los-valores-esperados",
    "href": "slides/lec_week2.html#propiedades-de-los-valores-esperados",
    "title": "Conceptos Básicos",
    "section": "Propiedades de los valores esperados",
    "text": "Propiedades de los valores esperados\nSean \\(a\\) y \\(b\\) constantes, \\(X\\) una variable aleatoria entonces se cumple que:\n\n\\(\\mathbb{E}(a)=a\\)\n\\(\\mathbb{E}(X)=\\mu=\\) constante\n\\(\\mathbb{E}(aX)=a\\mathbb{E}(X)\\)\n\\(\\mathbb{E}(aX+b)=\\mathbb{E}(aX)+\\mathbb{E}(b)=a\\mathbb{E}(X)+b\\)"
  },
  {
    "objectID": "slides/lec_week2.html#varianza",
    "href": "slides/lec_week2.html#varianza",
    "title": "Conceptos Básicos",
    "section": "Varianza",
    "text": "Varianza\nSea \\(X\\) una variable aleatoria, se define el la varianza de \\(X\\) como:\n\\[\\mathbb{E}[(X-\\mathbb{E}(X))^2]=V(X)=\\begin{cases}\\sum_{x\\in\\mathbb{R}} (X-\\mathbb{E}(X))^2P(X=x)\\\\ \\int_{x\\in\\mathbb{R}}(X-\\mathbb{E}(X))^2f_{X}(x)dx\\end{cases}\\]\nPara variables de tipo discreta y continua, respectivamente."
  },
  {
    "objectID": "slides/lec_week2.html#propiedades-de-la-varianza",
    "href": "slides/lec_week2.html#propiedades-de-la-varianza",
    "title": "Conceptos Básicos",
    "section": "Propiedades de la varianza",
    "text": "Propiedades de la varianza\nSea \\(a\\) y \\(b\\) constantes, \\(X\\) una variable aleatoria, entonces se cumple:\n\n\\(\\mathbb{V}(a)=0\\)\n\\(\\mathbb{V}(X)=\\sigma^2=\\) constante\n\\(\\mathbb{V}(aX)=a^2 \\mathbb{V}(X)\\)\n\\(\\mathbb{V}(aX+b)=\\mathbb{V}(aX)+\\mathbb{V}(b)=a^2\\mathbb{V}(X)+0=a^2\\mathbb{V}(X)\\)\n\\(\\mathbb{V}(X)=\\mathbb{E}(X^2)-(\\mathbb{E}(X))^2\\)"
  },
  {
    "objectID": "slides/lec_week2.html#distribución-binomial",
    "href": "slides/lec_week2.html#distribución-binomial",
    "title": "Conceptos Básicos",
    "section": "Distribución binomial",
    "text": "Distribución binomial\nSea \\(X\\) una variable aleatoria que representa el número de éxitos en \\(n\\) ensayos y \\(p\\) la probabilidad de éxito con cualquiera de éstos. Se dice entonces que \\(X\\) tiene una distribución binomial con función de probabilidad:\n\\[\\mathbb{P}(X=k)= {{n}\\choose{k}}p^k(1-p)^{n-k} \\hspace{20pt} k=1,2,\\cdots,n\\]\nEn donde \\({{n}\\choose{k}}\\) es el coeficiente binomial, esto es:\n\\[{{n}\\choose{k}}=\\dfrac{n!}{k!(n-k)!}\\]\nSi \\(n=1\\) diremos que \\(X\\) sigue una distribución Bernoulli."
  },
  {
    "objectID": "slides/lec_week2.html#propiedades-de-la-distribución-binomial",
    "href": "slides/lec_week2.html#propiedades-de-la-distribución-binomial",
    "title": "Conceptos Básicos",
    "section": "Propiedades de la distribución binomial",
    "text": "Propiedades de la distribución binomial\nSi \\(X\\) tiene una distribución binomial, entonces se cumple que:\n\n\\(\\mathbb{E}[X]=np\\)\n\\(\\mathbb{V}[X]=np(1-p)\\)\n\n\nEs claro ver que si \\(X\\) tiene una distribución bernoulli, entonces:\n\n\\(\\mathbb{E}[X]=p\\)\n\\(\\mathbb{V}[X]=p(1-p)\\)"
  },
  {
    "objectID": "slides/lec_week2.html#distribución-binomial-en-r",
    "href": "slides/lec_week2.html#distribución-binomial-en-r",
    "title": "Conceptos Básicos",
    "section": "Distribución binomial en R",
    "text": "Distribución binomial en R\n\n\n\n\nCódigoSalidas\n\n\n\nset.seed(163)\ndbinom(x = 2, size = 10, prob = 0.3)\nmean(rbinom(n = 10000, size = 10, prob = 0.3) == 2)\npbinom(q = 5, size = 10, p = 0.3, lower.tail = TRUE)\nmean(rbinom(n = 10000, size = 10, prob = 0.3) <= 5)\npbinom(q = 4, size = 10, p = 0.3, lower.tail  = FALSE)\nmean(rbinom(n = 10000, size = 10, prob = 0.3) >= 5)\n\n\n\n\nset.seed(163)\ndbinom(x = 2, size = 10, prob = 0.3)\n\n[1] 0.2334744\n\nmean(rbinom(n = 10000, size = 10, prob = 0.3) == 2)\n\n[1] 0.2417\n\npbinom(q = 5, size = 10, p = 0.3, lower.tail = TRUE)\n\n[1] 0.952651\n\nmean(rbinom(n = 10000, size = 10, prob = 0.3) <= 5)\n\n[1] 0.9529\n\npbinom(q = 4, size = 10, p = 0.3, lower.tail  = FALSE)\n\n[1] 0.1502683\n\nmean(rbinom(n = 10000, size = 10, prob = 0.3) >= 5)\n\n[1] 0.1497"
  },
  {
    "objectID": "slides/lec_week2.html#distribución-binomial-en-python",
    "href": "slides/lec_week2.html#distribución-binomial-en-python",
    "title": "Conceptos Básicos",
    "section": "Distribución binomial en Python",
    "text": "Distribución binomial en Python\n\nCódigoSalidas\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import binom\n\nnp.random.seed(163)\nbinom.pmf(2, n=10, p=0.3)\nsum(np.random.binomial(10, 0.3, 10000) == 2)/10000\nbinom.cdf(5, n=10, p=0.3)\nsum(np.random.binomial(10, 0.3, 10000) <= 5)/10000\n1-binom.cdf(4, n=10, p=0.3)\nsum(np.random.binomial(10, 0.3, 10000) >= 5)/10000\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import binom\n\nnp.random.seed(163)\nbinom.pmf(2, n=10, p=0.3)\n\n0.2334744405000001\n\nsum(np.random.binomial(10, 0.3, 10000) == 2)/10000\n\n0.2332\n\nbinom.cdf(5, n=10, p=0.3)\n\n0.9526510126000001\n\nsum(np.random.binomial(10, 0.3, 10000) <= 5)/10000\n\n0.9517\n\n1-binom.cdf(4, n=10, p=0.3)\n\n0.15026833259999994\n\nsum(np.random.binomial(10, 0.3, 10000) >= 5)/10000\n\n0.1478"
  },
  {
    "objectID": "slides/lec_week2.html#distribución-de-poisson",
    "href": "slides/lec_week2.html#distribución-de-poisson",
    "title": "Conceptos Básicos",
    "section": "Distribución de Poisson",
    "text": "Distribución de Poisson\nSea \\(X\\) una variable aleatoria que representa el número de eventos aleatorios independientes que ocurren a una rapidez constante sobre el tiempo o el espacio. Se dice entonces que la variable aleatoria \\(X\\) tiene una distribución de Poisson con función de probabilidad:\n\\[\\mathbb{P}(X=k)=\\dfrac{e^{-\\lambda}\\lambda^k}{k!} \\hspace{20pt} k=0,1,\\cdots,n,\\cdots\\]\nEn donde \\(\\lambda>0\\) representa el número promedio de ocurrencias del evento aleatorio por unidad de tiempo. Además, si \\(X\\) sigue una distribución de Poisson se cumple que:\n\n\\(\\mathbb{E}[X]=\\lambda\\)\n\\(\\mathbb{V}[X]=\\lambda\\)"
  },
  {
    "objectID": "slides/lec_week2.html#distribución-de-poisson-en-r",
    "href": "slides/lec_week2.html#distribución-de-poisson-en-r",
    "title": "Conceptos Básicos",
    "section": "Distribución de Poisson en R",
    "text": "Distribución de Poisson en R\n\nCódigoSalidas\n\n\n\nset.seed(163)\ndpois(x = 7, 5)\nmean(rpois(n = 10000, 5) == 7)\nppois(q = 5, 5, lower.tail = TRUE)\nmean(rpois(n = 10000, 5) <= 5)\nppois(q = 4, 5, lower.tail  = FALSE)\nmean(rpois(n = 10000,5) >= 5)\n\n\n\n\nset.seed(163)\ndpois(x = 7, 5)\n\n[1] 0.1044449\n\nmean(rpois(n = 10000, 5) == 7)\n\n[1] 0.1107\n\nppois(q = 5, 5, lower.tail = TRUE)\n\n[1] 0.6159607\n\nmean(rpois(n = 10000, 5) <= 5)\n\n[1] 0.6109\n\nppois(q = 4, 5, lower.tail  = FALSE)\n\n[1] 0.5595067\n\nmean(rpois(n = 10000,5) >= 5)\n\n[1] 0.5542"
  },
  {
    "objectID": "slides/lec_week2.html#distribución-de-poisson-en-python",
    "href": "slides/lec_week2.html#distribución-de-poisson-en-python",
    "title": "Conceptos Básicos",
    "section": "Distribución de Poisson en Python",
    "text": "Distribución de Poisson en Python\n\nCódigoSalidas\n\n\nimport numpy as np\nfrom scipy.stats import poisson\n\nnp.random.seed(163)\npoisson.pmf(7, 5)\nsum(np.random.poisson(5, 10000) == 7)/10000\npoisson.cdf(7, 5)\nsum(np.random.poisson(5, 10000) <= 7)/10000\n1-poisson.cdf(6, 5)\nsum(np.random.poisson(5, 10000) >= 7)/10000\n\n\n\nimport numpy as np\nfrom scipy.stats import poisson\n\nnp.random.seed(163)\npoisson.pmf(7, 5)\n\n0.10444486295705395\n\nsum(np.random.poisson(5, 10000) == 7)/10000\n\n0.1024\n\npoisson.cdf(7, 5)\n\n0.8666283259299925\n\nsum(np.random.poisson(5, 10000) <= 7)/10000\n\n0.8662\n\n1-poisson.cdf(6, 5)\n\n0.2378165370270613\n\nsum(np.random.poisson(5, 10000) >= 7)/10000\n\n0.2369"
  },
  {
    "objectID": "slides/lec_week2.html#distribución-geométrica",
    "href": "slides/lec_week2.html#distribución-geométrica",
    "title": "Conceptos Básicos",
    "section": "Distribución geométrica",
    "text": "Distribución geométrica\nSea \\(X\\) una variable aleatoria que representa el número de fallas que ocurren antes de que se presente el primer éxito.Se dice entonces que la variable aleatoria \\(X\\) tiene una distribución geométrica con función de probabilidad:\n\\[\\mathbb{P}(X=k)=(1-p)^{k-1}p \\quad \\quad k=1,2,\\cdots\\]\nEn donde \\(p\\) es la probabilidad de éxito. Además, Si \\(X\\) sigue una distribución geométrica, entonces se cumple que:\n\n\\(\\displaystyle E[X]=\\dfrac{1}{p}\\)\n\\(V[X]=\\dfrac{(1-p)}{p^2}\\)"
  },
  {
    "objectID": "slides/lec_week2.html#distribución-geométrica-en-r",
    "href": "slides/lec_week2.html#distribución-geométrica-en-r",
    "title": "Conceptos Básicos",
    "section": "Distribución geométrica en R",
    "text": "Distribución geométrica en R\n\nCódigoSalidas\n\n\n\nset.seed(163)\np = 0.2\nn = 3\ndgeom(x = n, prob = p)\nmean(rgeom(n = 10000, prob = p) == n)\npgeom(q = n, prob = p, lower.tail = TRUE)\nmean(rgeom(n = 10000, prob = p) <= n)\npgeom(q = n, prob = p, lower.tail  = FALSE)\nmean(rgeom(n = 10000, prob = p) > n)\n\n\n\n\nset.seed(163)\np = 0.2\nn = 3\ndgeom(x = n, prob = p)\n\n[1] 0.1024\n\nmean(rgeom(n = 10000, prob = p) == n)\n\n[1] 0.1028\n\npgeom(q = n, prob = p, lower.tail = TRUE)\n\n[1] 0.5904\n\nmean(rgeom(n = 10000, prob = p) <= n)\n\n[1] 0.5905\n\npgeom(q = n, prob = p, lower.tail  = FALSE)\n\n[1] 0.4096\n\nmean(rgeom(n = 10000, prob = p) > n)\n\n[1] 0.4011"
  },
  {
    "objectID": "slides/lec_week2.html#distribución-geométrica-en-python",
    "href": "slides/lec_week2.html#distribución-geométrica-en-python",
    "title": "Conceptos Básicos",
    "section": "Distribución geométrica en Python",
    "text": "Distribución geométrica en Python\n\nCódigoSalidas\n\n\nimport numpy as np\nfrom scipy.stats import geom\n\nnp.random.seed(163)\ngeom.pmf(k=3, p=0.2)\nsum(np.random.geometric(0.2, 10000) == 3)/10000\ngeom.cdf(k=3, p=0.2)\nsum(np.random.geometric(0.2, 10000) <= 3)/10000\n1-geom.cdf(k=3, p=0.2)\nsum(np.random.geometric(0.2, 10000) > 3)/10000\n\n\n\nimport numpy as np\nfrom scipy.stats import geom\n\nnp.random.seed(163)\ngeom.pmf(k=3, p=0.2)\n\n0.12800000000000003\n\nsum(np.random.geometric(0.2, 10000) == 3)/10000\n\n0.1291\n\ngeom.cdf(k=3, p=0.2)\n\n0.488\n\nsum(np.random.geometric(0.2, 10000) <= 3)/10000\n\n0.4938\n\n1-geom.cdf(k=3, p=0.2)\n\n0.512\n\nsum(np.random.geometric(0.2, 10000) > 3)/10000\n\n0.5113"
  },
  {
    "objectID": "slides/lec_week2.html#distribución-hipergeométrica",
    "href": "slides/lec_week2.html#distribución-hipergeométrica",
    "title": "Conceptos Básicos",
    "section": "Distribución hipergeométrica",
    "text": "Distribución hipergeométrica\nSea \\(N\\) el número total de objetos de una población finita, de manera tal que \\(k\\) de éstos es de un tipo y \\(N-k\\) de otros. Si se selecciona una muestra aleatoria de la población constituida por \\(n\\) objetos de la probabilidad de que \\(x\\) sea de un tipo exactamente y \\(n-x\\) sea del otro, está dada por la función de probabilidad hipergeométrica:\n\\[\\displaystyle \\mathbb{P}(X=x)= \\dfrac{{{k}\\choose{x}} {{N-k}\\choose{n-x}}  }{  {{N}\\choose{n}}}\\quad \\quad x=1,2,\\cdots,n \\quad; x \\leq k\\quad ;n-x\\leq N-k\\]\nSi \\(X\\) sigue una distribución hipergeométrica y si \\(p=k/N\\)\n\n\\(E[X]=np\\)\n\\(V[X]=np(1-p)\\left( \\dfrac{N-n}{N-1}\\right)\\)"
  },
  {
    "objectID": "slides/lec_week2.html#distribución-normal",
    "href": "slides/lec_week2.html#distribución-normal",
    "title": "Conceptos Básicos",
    "section": "Distribución normal",
    "text": "Distribución normal\nSea \\(X\\) una variable aleatoria que toma valores reales, diremos que \\(X\\) sigue una distribución normal (o Gaussiana) si su función de densidad está por:\n\\[f_{X}(x)=\\dfrac{1}{\\sqrt{2\\pi}\\sigma}\\exp\\left[ -\\dfrac{1}{2}\\left(\\dfrac{x-\\mu}{\\sigma}\\right) ^2\\right],\\]\nEn donde los parámetros de la distribución son \\(\\mu\\) y \\(\\sigma\\) satisfacen las condiciones:\n\\[-\\infty<\\mu<\\infty, \\quad \\sigma^2>0\\]"
  },
  {
    "objectID": "slides/lec_week2.html#distribución-normal-en-r",
    "href": "slides/lec_week2.html#distribución-normal-en-r",
    "title": "Conceptos Básicos",
    "section": "Distribución normal en R",
    "text": "Distribución normal en R\n\nCódigoSalidas\n\n\n\nset.seed(163)\nmedia=100\nds=16\n\npnorm(q = 90, mean = media, sd = ds, lower.tail = TRUE)\nmean(rnorm(n = 10000, mean = media, sd = ds) <= 90)\npnorm(q = 140, mean = media, sd = ds, lower.tail = FALSE)\nmean(rnorm(n = 10000, mean = media, sd = ds) > 140)\n\n\n\n\nset.seed(163)\nmedia=100\nds=16\n\npnorm(q = 90, mean = media, sd = ds, lower.tail = TRUE)\n\n[1] 0.2659855\n\nmean(rnorm(n = 10000, mean = media, sd = ds) <= 90)\n\n[1] 0.2592\n\npnorm(q = 140, mean = media, sd = ds, lower.tail = FALSE)\n\n[1] 0.006209665\n\nmean(rnorm(n = 10000, mean = media, sd = ds) > 140)\n\n[1] 0.005"
  },
  {
    "objectID": "slides/lec_week2.html#distribución-normal-en-python",
    "href": "slides/lec_week2.html#distribución-normal-en-python",
    "title": "Conceptos Básicos",
    "section": "Distribución normal en Python",
    "text": "Distribución normal en Python\n\nCódigoSalidas\n\n\nimport numpy as np\nfrom scipy.stats import norm\n\nnp.random.seed(163)\nmu, sigma = 100, 16\nnorm.cdf(90, mu , sigma)\nsum(np.random.normal(mu, sigma, 10000) <= 90)/10000\n1-norm.cdf(140, mu , sigma)\nsum(np.random.normal(mu, sigma, 10000) > 140)/10000\n\n\n\nimport numpy as np\nfrom scipy.stats import norm\n\nnp.random.seed(163)\nmu, sigma = 100, 16\nnorm.cdf(90, mu , sigma)\n\n0.26598552904870054\n\nsum(np.random.normal(mu, sigma, 10000) <= 90)/10000\n\n0.2656\n\n1-norm.cdf(140, mu , sigma)\n\n0.006209665325776159\n\nsum(np.random.normal(mu, sigma, 10000) > 140)/10000\n\n0.0068"
  },
  {
    "objectID": "slides/lec_week2.html#distribución-uniforme",
    "href": "slides/lec_week2.html#distribución-uniforme",
    "title": "Conceptos Básicos",
    "section": "Distribución uniforme",
    "text": "Distribución uniforme\nSea \\(X\\) una variable aleatoria continua, diremos que \\(X\\) sigue una distribución uniforme sobre el intervalo \\((a,b)\\) si su función de densidad de probabilidad está dada por:\n\\[f_{X}(x)=\\begin{cases}1/(b-a) \\quad &a\\leq x \\leq b\\\\0 \\quad &e.o.c\\end{cases}\\]\nLos parámetros de la distribución cumplen las condiciones:\n\\[-\\infty<a<\\infty,\\quad -\\infty<b<\\infty\\]\n\n\\(E[X]=\\dfrac{(a+b)}{2}\\)\n\n\\(V[X]=\\dfrac{(b-a)^2}{12}\\)"
  },
  {
    "objectID": "slides/lec_week2.html#distribución-uniforme-en-r",
    "href": "slides/lec_week2.html#distribución-uniforme-en-r",
    "title": "Conceptos Básicos",
    "section": "Distribución uniforme en R",
    "text": "Distribución uniforme en R\n\nCódigoSalidas\n\n\n\nset.seed(163)\n\npunif(0.3, 0 , 1 , lower.tail = TRUE)\nmean(runif(n = 10000, 0, 1) <= 0.3)\npunif(0.3, 0 , 1 , lower.tail = FALSE)\nmean(runif(n = 10000, 0, 1) > 0.3)\n\n\n\n\nset.seed(163)\n\npunif(0.3, 0 , 1 , lower.tail = TRUE)\n\n[1] 0.3\n\nmean(runif(n = 10000, 0, 1) <= 0.3)\n\n[1] 0.298\n\npunif(0.3, 0 , 1 , lower.tail = FALSE)\n\n[1] 0.7\n\nmean(runif(n = 10000, 0, 1) > 0.3)\n\n[1] 0.7082"
  },
  {
    "objectID": "slides/lec_week2.html#distribución-uniforme-en-python",
    "href": "slides/lec_week2.html#distribución-uniforme-en-python",
    "title": "Conceptos Básicos",
    "section": "Distribución uniforme en Python",
    "text": "Distribución uniforme en Python\n\nCódigoSalidas\n\n\nimport numpy as np\nfrom scipy.stats import uniform\n\nnp.random.seed(163)\nuniform.cdf(0.3, 0 , 1)\nsum(np.random.uniform(0, 1, 10000) <= 0.3)/10000\n1-uniform.cdf(0.3, 0 , 1)\nsum(np.random.uniform(0, 1, 10000) > 0.3)/10000\n\n\n\nimport numpy as np\nfrom scipy.stats import uniform\n\nnp.random.seed(163)\nuniform.cdf(0.3, 0 , 1)\n\n0.3\n\nsum(np.random.uniform(0, 1, 10000) <= 0.3)/10000\n\n0.3048\n\n1-uniform.cdf(0.3, 0 , 1)\n\n0.7\n\nsum(np.random.uniform(0, 1, 10000) > 0.3)/10000\n\n0.699"
  },
  {
    "objectID": "slides/lec_week2.html#distribución-exponencial",
    "href": "slides/lec_week2.html#distribución-exponencial",
    "title": "Conceptos Básicos",
    "section": "Distribución exponencial",
    "text": "Distribución exponencial\nSea \\(X\\) una variable aleatoria continua que toma valores positivos, diremos que \\(X\\) sigue una distribución exponencial con parámetro \\(\\alpha>0\\) si su función de densidad está dada por:\n\\[f_{X}(x)=\\begin{cases}\\alpha e^{-\\alpha x} \\quad &x\\geq 0 \\\\0 \\quad &e.o.c\\end{cases}\\]\nAdemás se cumple que:\n\n\\(E[X]=\\dfrac{1}{\\alpha}\\)\n\n\\(V[X]=\\dfrac{1}{\\alpha^2}\\)"
  },
  {
    "objectID": "slides/lec_week2.html#distribución-exponencial-en-r",
    "href": "slides/lec_week2.html#distribución-exponencial-en-r",
    "title": "Conceptos Básicos",
    "section": "Distribución exponencial en R",
    "text": "Distribución exponencial en R\n\nCódigoSalidas\n\n\n\nset.seed(163)\n\npexp(2, 0.4, lower.tail = TRUE)\nmean(rexp(0.4, n = 10000) <= 2)\npexp(2, 0.4, lower.tail = FALSE)\nmean(rexp(0.4, n = 10000) > 2)\n\n\n\n\nset.seed(163)\n\npexp(2, 0.4, lower.tail = TRUE)\n\n[1] 0.550671\n\nmean(rexp(0.4, n = 10000) <= 2)\n\n[1] 0.5458\n\npexp(2, 0.4, lower.tail = FALSE)\n\n[1] 0.449329\n\nmean(rexp(0.4, n = 10000) > 2)\n\n[1] 0.446"
  },
  {
    "objectID": "slides/lec_week2.html#distribución-exponencial-en-python",
    "href": "slides/lec_week2.html#distribución-exponencial-en-python",
    "title": "Conceptos Básicos",
    "section": "Distribución exponencial en Python",
    "text": "Distribución exponencial en Python\n\nCódigoSalidas\n\n\nimport numpy as np\nfrom scipy.stats import expon\n\nnp.random.seed(163)\nexpon.cdf(2, scale=1/0.4)\nsum(np.random.exponential(1/0.4, 10000) <= 2)/10000\n1-expon.cdf(2, scale=1/0.4)\nsum(np.random.exponential(1/0.4, 10000) > 2)/10000\n\n\n\nimport numpy as np\nfrom scipy.stats import expon\n\nnp.random.seed(163)\nexpon.cdf(2, scale=1/0.4)\n\n0.5506710358827784\n\nsum(np.random.exponential(1/0.4, 10000) <= 2)/10000\n\n0.5572\n\n1-expon.cdf(2, scale=1/0.4)\n\n0.44932896411722156\n\nsum(np.random.exponential(1/0.4, 10000) > 2)/10000\n\n0.4416"
  },
  {
    "objectID": "slides/lec_week2.html#función-gamma",
    "href": "slides/lec_week2.html#función-gamma",
    "title": "Conceptos Básicos",
    "section": "Función gamma",
    "text": "Función gamma\nLa función gamma denotada por \\(\\Gamma\\) está definida por:\n\\[\\Gamma(p)=\\int_{0}^{\\infty} x^{p-1} e^{-x}dx \\hspace{20pt} p>0\\]\nEsta función cumple las siguientes propiedades:\n\n\\(\\Gamma(n)=(n-1)!\\)\n\n\\(\\Gamma(1/2)=\\sqrt{\\pi}\\)"
  },
  {
    "objectID": "slides/lec_week2.html#distribución-gamma",
    "href": "slides/lec_week2.html#distribución-gamma",
    "title": "Conceptos Básicos",
    "section": "Distribución gamma",
    "text": "Distribución gamma\nSea \\(X\\) una variable aleatoria continua que toma valores positivos. Diremos que \\(X\\) sigue una distribución Gamma si su función de densidad está dada por:\n\\[f_{X}(x)=\\begin{cases}\\dfrac{\\alpha}{\\Gamma(r)}(\\alpha x)^{r-1}e^{-\\alpha x} \\quad &x>0\\\\0 \\quad &e.o.c,\\end{cases}\\]\nEn donde los parámetros \\(r\\) y \\(\\alpha\\) son positivos.\nEs claro ver que un caso particular de la distribución Gamma es la distribución exponencial (\\(r=1\\)). Si \\(X\\) se distribuye Gamma entonces se cumple:\n\n\\(E[X]=r/\\alpha\\)\n\n\\(V[X]=r/\\alpha^2\\)"
  },
  {
    "objectID": "slides/lec_week2.html#distribución-gamma-en-r",
    "href": "slides/lec_week2.html#distribución-gamma-en-r",
    "title": "Conceptos Básicos",
    "section": "Distribución gamma en R",
    "text": "Distribución gamma en R\n\nCódigoSalidas\n\n\n\nset.seed(163)\n\npgamma(q = 3, shape = 10, scale = 1/4)\nmean(rgamma(shape=10, scale= 1/4, n = 10000) <= 3)\npgamma(q = 3, shape = 10, scale = 1/4, lower.tail = FALSE)\nmean(rgamma(shape=10, scale= 1/4, n = 10000) > 3)\n\n\n\n\nset.seed(163)\n\npgamma(q = 3, shape = 10, scale = 1/4)\n\n[1] 0.7576078\n\nmean(rgamma(shape=10, scale= 1/4, n = 10000) <= 3)\n\n[1] 0.7542\n\npgamma(q = 3, shape = 10, scale = 1/4, lower.tail = FALSE)\n\n[1] 0.2423922\n\nmean(rgamma(shape=10, scale= 1/4, n = 10000) > 3)\n\n[1] 0.2427"
  },
  {
    "objectID": "slides/lec_week2.html#distribución-gamma-en-python",
    "href": "slides/lec_week2.html#distribución-gamma-en-python",
    "title": "Conceptos Básicos",
    "section": "Distribución gamma en Python",
    "text": "Distribución gamma en Python\n\nCódigoSalidas\n\n\nimport numpy as np\nfrom scipy.stats import gamma\n\nnp.random.seed(163)\ngamma.cdf(3, a=10, scale=0.25)\nsum(np.random.gamma(10,0.25, 10000) <= 3)/10000\n1-gamma.cdf(3, a=10, scale=0.25)\nsum(np.random.gamma(10,0.25, 10000) > 3)/10000\n\n\n\nimport numpy as np\nfrom scipy.stats import gamma\n\nnp.random.seed(163)\ngamma.cdf(3, a=10, scale=0.25)\n\n0.7576078383294875\n\nsum(np.random.gamma(10,0.25, 10000) <= 3)/10000\n\n0.7595\n\n1-gamma.cdf(3, a=10, scale=0.25)\n\n0.24239216167051247\n\nsum(np.random.gamma(10,0.25, 10000) > 3)/10000\n\n0.2443"
  },
  {
    "objectID": "slides/lec_week2.html#distribución-t-student",
    "href": "slides/lec_week2.html#distribución-t-student",
    "title": "Conceptos Básicos",
    "section": "Distribución t-student",
    "text": "Distribución t-student\nSea \\(X\\) una variable aleatoria continua que toma valores reales, diremos que \\(X\\) sigue una distribución t-student con \\(\\nu\\) grados de libertad, si su función de densidad de probabilidad está dada por:\n\\[f(t) = \\dfrac{\\Gamma(\\dfrac{\\nu+1}{2})} {\\sqrt{\\nu\\pi}\\,\\Gamma(\\dfrac{\\nu}{2})} \\left(1+\\dfrac{t^2}{\\nu} \\right)^{\\!-\\dfrac{\\nu+1}{2}},\\]\ndonde \\(\\Gamma\\) es la función gamma. Si \\(X\\) se distribuye t-student entonces:\n\n\\(\\mathbb{E}[X]=0\\) para \\(\\nu>1\\). Indefinida para otros valores.\n\n\\(\\mathbb{V}[X]=\\dfrac{\\nu}{\\nu -2}\\) para \\(\\nu>2\\). Indefinida para otros valores."
  },
  {
    "objectID": "slides/lec_week2.html#distribución-t-student-en-r",
    "href": "slides/lec_week2.html#distribución-t-student-en-r",
    "title": "Conceptos Básicos",
    "section": "Distribución t-student en R",
    "text": "Distribución t-student en R\n\nCódigoSalidas\n\n\n\nset.seed(163)\n\npt(q=1.9, df=15, lower.tail = T)\nmean(rt(15, n = 10000) <= 1.9)\npt(q=1.9, df=15, lower.tail = F)\nmean(rt(15, n = 10000) > 1.9)\n\n\n\n\nset.seed(163)\n\npt(q=1.9, df=15, lower.tail = T)\n\n[1] 0.9615845\n\nmean(rt(15, n = 10000) <= 1.9)\n\n[1] 0.9637\n\npt(q=1.9, df=15, lower.tail = F)\n\n[1] 0.03841551\n\nmean(rt(15, n = 10000) > 1.9)\n\n[1] 0.0386"
  },
  {
    "objectID": "slides/lec_week2.html#distribución-t-student-en-python",
    "href": "slides/lec_week2.html#distribución-t-student-en-python",
    "title": "Conceptos Básicos",
    "section": "Distribución t-student en Python",
    "text": "Distribución t-student en Python\n\nCódigoSalidas\n\n\nimport numpy as np\nfrom scipy.stats import t\n\nnp.random.seed(163)\nt.cdf(1.9, 15)\nsum(np.random.standard_t(15, 10000) <= 1.9)/10000\n1-t.cdf(1.9, 15)\nsum(np.random.standard_t(15, 10000) > 1.9)/10000\n\n\n\nimport numpy as np\nfrom scipy.stats import t\n\nnp.random.seed(163)\nt.cdf(1.9, 15)\n\n0.9615844871419956\n\nsum(np.random.standard_t(15, 10000) <= 1.9)/10000\n\n0.9611\n\n1-t.cdf(1.9, 15)\n\n0.038415512858004375\n\nsum(np.random.standard_t(15, 10000) > 1.9)/10000\n\n0.0392"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "IND163C - Análisis de Negocios (Business Analytics)",
    "section": "",
    "text": "En este curso se estudian los fundamentos del análisis de información a través del desarrollo de aplicaciones Cloud (nube) mediante lenguajes de programación, vinculando áreas técnicas especializadas en Analytics con otras áreas de la organización, agregando valor al proceso de diagnóstico y toma de decisiones en tiempo real.\nA lo largo del curso se evalúan el uso de Analytics midiendo el impacto de esta herramienta a nivel individual y social, decidiendo de forma ética y socialmente responsable respecto del uso de la información."
  },
  {
    "objectID": "index.html#softwares",
    "href": "index.html#softwares",
    "title": "IND163C - Análisis de Negocios (Business Analytics)",
    "section": "Softwares",
    "text": "Softwares\nPara la mayoría de las aplicaciones utilizaremos R y Python, por lo que se sugiere utilizar un IDE como RStudio o Spyder.\nPara la entrega de informes y talleres que requieran uso de programación, se recomienda el uso de Rmarkdown, Jupyter Notebook o \\(\\LaTeX\\) para la confección de documentos a entregar."
  },
  {
    "objectID": "index.html#bibliografía-principal",
    "href": "index.html#bibliografía-principal",
    "title": "IND163C - Análisis de Negocios (Business Analytics)",
    "section": "Bibliografía principal",
    "text": "Bibliografía principal\nLa bibliografía principal del curso es:\n\n\n\n\n\n\nData Science For Business: What You Need to Know About Data Mining & Data-Analytic Thinking. Provost F., Fawcett, T.\n\n\n\n\n\n\n\nThink like a Data Scientist: Tackle the data science process step-by-step. Godsey B.\n\n\n\n\n\n\n\nNumsense! Data Science for the Layman: No Math Added. Ng, A, Soo K."
  },
  {
    "objectID": "index.html#bibliografía-secundaria-y-de-profundización",
    "href": "index.html#bibliografía-secundaria-y-de-profundización",
    "title": "IND163C - Análisis de Negocios (Business Analytics)",
    "section": "Bibliografía secundaria y de profundización",
    "text": "Bibliografía secundaria y de profundización\nLa bibliografía secundaria y de profundización de las distintas temáticas a estudiar del curso es:\n\n\n\n\n\n\nMachine Learning with R Expert techniques for predictive modeling. Lantz, Brett.\n\n\n\n\n\n\n\nAn Introduction to Statistical Learning with Applications in R. James, Gareth, Witten, Daniela, Hastie, Trevor, Tibshirani Robert.\n\n\n\n\n\n\n\nHands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems. Géron, Aurélien."
  },
  {
    "objectID": "pages/week1.html",
    "href": "pages/week1.html",
    "title": "Semana 1",
    "section": "",
    "text": "Leer el programa del curso"
  },
  {
    "objectID": "pages/week1.html#presentación",
    "href": "pages/week1.html#presentación",
    "title": "Semana 1",
    "section": "Presentación",
    "text": "Presentación\nVer presentación en pantalla completa"
  },
  {
    "objectID": "pages/week1.html#material-adicional",
    "href": "pages/week1.html#material-adicional",
    "title": "Semana 1",
    "section": "Material adicional",
    "text": "Material adicional\n\nLeer Capítulo 1, Data Science For Business: What You Need to Know About Data Mining & Data-Analytic Thinking.\nLeer Capítulo 1 y 2, Think like a Data Scientist: Tackle the data science process step-by-step."
  },
  {
    "objectID": "slides/lec_week1.html#de-qué-trata-el-curso",
    "href": "slides/lec_week1.html#de-qué-trata-el-curso",
    "title": "Análisis de Negocios",
    "section": "¿De qué trata el curso?",
    "text": "¿De qué trata el curso?\nA lo largo del curso analizaremos los fundamentos del análisis de datos mediante el uso de lenguajes de programación con el fin de agregar al valor al proceso de diagnóstico y toma de decisiones en tiempo real.\nCon el fin de tener mayor claridad de lo que han estudiado\n\n\n¿Qué herramientas computacionales han visto en cursos anteriores?\n¿Hasta qué vieron en el curso MAT042: Probabilidad y Estadística?\n¿Han tenido alguna experiencia trabajando con R o Python en el análisis de datos?"
  },
  {
    "objectID": "slides/lec_week1.html#horario-de-clases",
    "href": "slides/lec_week1.html#horario-de-clases",
    "title": "Análisis de Negocios",
    "section": "Horario de clases",
    "text": "Horario de clases\n\n\n\n\nDía\nHorario\nLugar\n\n\n\n\nCátedra #1\nViernes\n09:35 am - 10:45 am\nM401-H\n\n\nCátedra #2\nViernes\n10:55 am - 12:05 pm\nM401-H\n\n\n\nPágina del curso\nUtilizaremos el Aula USM y el sitio https://ind163c-2022-02.netlify.app/. Ambas páginas tendrán la misma información, sin embargo, para efectos de entrega de informes el medio oficial será el aula USM."
  },
  {
    "objectID": "slides/lec_week1.html#qué-necesitaremos-a-lo-largo-del-curso",
    "href": "slides/lec_week1.html#qué-necesitaremos-a-lo-largo-del-curso",
    "title": "Análisis de Negocios",
    "section": "¿Qué necesitaremos a lo largo del curso?",
    "text": "¿Qué necesitaremos a lo largo del curso?\n\n\n\n\n\n\n\n\n\n\n\nAdicionalmente, se recomienda utilizar un IDE como RStudio o Spyder."
  },
  {
    "objectID": "slides/lec_week1.html#bibliografía-principal",
    "href": "slides/lec_week1.html#bibliografía-principal",
    "title": "Análisis de Negocios",
    "section": "Bibliografía principal",
    "text": "Bibliografía principal\n\n\n\n\n\n\nData Science For Business: What You Need to Know About Data Mining & Data-Analytic Thinking. Provost F., Fawcett, T.\n\n\n\n\n \n\n\n\n\n\nThink like a Data Scientist: Tackle the data science process step-by-step. Godsey B.\n\n\n\n\n \n\n\n\n\n\nNumsense! Data Science for the Layman: No Math Added. Ng, A, Soo K."
  },
  {
    "objectID": "slides/lec_week1.html#bibliografía-secundaria-y-de-profundización",
    "href": "slides/lec_week1.html#bibliografía-secundaria-y-de-profundización",
    "title": "Análisis de Negocios",
    "section": "Bibliografía secundaria y de profundización",
    "text": "Bibliografía secundaria y de profundización\n\n\n\n\n\n\nMachine Learning with R Expert techniques for predictive modeling. Lantz, Brett.\n\n\n\n\n \n\n\n\n\n\nAn Introduction to Statistical Learning with Applications in R. James, Gareth, Witten, Daniela, Hastie, Trevor, Tibshirani Robert.\n\n\n\n\n \n\n\n\n\n\nHands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems. Géron, Aurélien."
  },
  {
    "objectID": "slides/lec_week1.html#introducción-a-analytics",
    "href": "slides/lec_week1.html#introducción-a-analytics",
    "title": "Análisis de Negocios",
    "section": "Introducción a Analytics",
    "text": "Introducción a Analytics\n\nDel sistema de información de marketing al analytics ¿Qué es Analytics? ¿Para qué sirve? ¿En qué contexto es necesario?\nAnalytics en el mundo y en Chile.\nImpacto social de Analytics en Chile y el mundo.\nComposición de perfiles de un área genérica de analytics en una empresa nacional."
  },
  {
    "objectID": "slides/lec_week1.html#conceptos-básicos",
    "href": "slides/lec_week1.html#conceptos-básicos",
    "title": "Análisis de Negocios",
    "section": "Conceptos Básicos",
    "text": "Conceptos Básicos\n\nEscuelas de probabilidad\nDistribuciones probabilistas\nTest de hipótesis e intervalos de confianza\nRegresión lineal\nEstimadores blandos y robustos\nTécnicas básicas de segmentación\nReglas de asociación\nÁrboles de decisión\nDeep learning, machine learning e inteligencia artificial."
  },
  {
    "objectID": "slides/lec_week1.html#lenguajes-de-programación-y-aplicaciones-en-la-nube",
    "href": "slides/lec_week1.html#lenguajes-de-programación-y-aplicaciones-en-la-nube",
    "title": "Análisis de Negocios",
    "section": "Lenguajes de programación y aplicaciones en la nube",
    "text": "Lenguajes de programación y aplicaciones en la nube\n\nIntroducción a bases de datos\nIntroducción a Python y R\nIntroducción a Google Cloud y AWS."
  },
  {
    "objectID": "slides/lec_week1.html#planificación-de-proyectos-de-analytics-y-aplicaciones-de-negocios",
    "href": "slides/lec_week1.html#planificación-de-proyectos-de-analytics-y-aplicaciones-de-negocios",
    "title": "Análisis de Negocios",
    "section": "Planificación de proyectos de analytics y aplicaciones de negocios",
    "text": "Planificación de proyectos de analytics y aplicaciones de negocios\n\nAplicaciones transversales a la empresa."
  },
  {
    "objectID": "slides/lec_week1.html#ponderaciones",
    "href": "slides/lec_week1.html#ponderaciones",
    "title": "Análisis de Negocios",
    "section": "Ponderaciones",
    "text": "Ponderaciones\nLa metodología de evaluación es la siguiente:\n\n\n\n\n\n\n\nTipo de evaluación\nPorcentaje que corresponde\n\n\n\n\nCertamen 1 (\\(C_1\\))\n20%\n\n\nCertamen 2 (\\(C_2\\))\n20%\n\n\nInforme escrito de avance de proyecto (\\(P_1\\))\n20%\n\n\nInforme escrito y oral final de proyecto (\\(P_2\\))\n40%\n\n\n\nLa nota final (\\(NF\\)) de la asignatura se calculará según:\n\\[\nNF= 0.2*C_1+0.2*C_2+0.2*P_1+0.4*P_2\n\\]"
  },
  {
    "objectID": "slides/lec_week1.html#requerimientos-mínimos-de-aprobación",
    "href": "slides/lec_week1.html#requerimientos-mínimos-de-aprobación",
    "title": "Análisis de Negocios",
    "section": "Requerimientos mínimos de aprobación",
    "text": "Requerimientos mínimos de aprobación\n\nPromedio Certámenes (\\(C_1\\) y \\(C_2\\)): \\(\\overline{C}_{1,2}\\geq 55\\)\nPromedio Proyecto (\\(P_1\\) y \\(P_2\\)): \\(\\overline{P}_{1,2}\\geq 55\\)"
  },
  {
    "objectID": "slides/lec_week1.html#metodología-del-curso",
    "href": "slides/lec_week1.html#metodología-del-curso",
    "title": "Análisis de Negocios",
    "section": "Metodología del curso",
    "text": "Metodología del curso\n\nAntes de cada sesión, se mandará una lectura de preparación para la sesión\nEl enfoque principal será aplicado, pero sin dejar de lado los fundamentos matemáticos\nSe pondrá a disposición material adicional para estudiar:\n\nEjemplos y ejercicios teóricos\nCódigos\n\nEl curso será autocontenido, pero requiere al menos conocimiento básico de probabilidad y estadística."
  },
  {
    "objectID": "slides/lec_week1.html#ayudantía",
    "href": "slides/lec_week1.html#ayudantía",
    "title": "Análisis de Negocios",
    "section": "Ayudantía",
    "text": "Ayudantía\n\nAyudante: Nicolás Cárdenas\nHorario a definir"
  },
  {
    "objectID": "slides/lec_week1.html#analytics",
    "href": "slides/lec_week1.html#analytics",
    "title": "Análisis de Negocios",
    "section": "Analytics",
    "text": "Analytics\n\n¿Qué noción tienen sobre analytics?\n¿Dé que sirve en la empresa? ¿Algún ejemplo?\n¿En qué contexto es necesario?\n¿Cómo afecta el uso de analytics en Chile y en el mundo?\n¿Cuál es su impacto social?"
  },
  {
    "objectID": "slides/lec_week1.html#data-analytics",
    "href": "slides/lec_week1.html#data-analytics",
    "title": "Análisis de Negocios",
    "section": "Data Analytics",
    "text": "Data Analytics\n\nEl avance tecnológico ha permitido la recolección de datos dentro y fuera de la empresa\nEsta disponibilidad de datos ha fomentado la creación de metodologías para extraer información de los datos\nLa gran mayoría de las empresas tienen equipos especializados en extraer la mayor cantidad de información útil para la empresa\nAntiguamente, la industria exploraba los conjuntos de datos disponibles de manera más o menos manual, pero debido al incremento del volumen de datos, esto ya no es posible.\nEn la actualidad, el proceso de descubrir información relevante en los conjuntos de datos disponibles, se le llama data mining"
  },
  {
    "objectID": "slides/lec_week1.html#data-mining",
    "href": "slides/lec_week1.html#data-mining",
    "title": "Análisis de Negocios",
    "section": "Data mining",
    "text": "Data mining\n\nLa aplicación más frecuente de las técnicas de data mining están en marketing. Por ejemplo:\n\nMarketing dirigido\nPublicidad online\nRecomendaciones de compra\n\nEn el sector financiero, es frecuente encontrar estas técnicas en la creación de puntajes crediticios e identificación de fraude\nMuchas empresas han generado una ventaja comparativa utilizando Data Science estratégicamente"
  },
  {
    "objectID": "slides/lec_week1.html#ejemplo",
    "href": "slides/lec_week1.html#ejemplo",
    "title": "Análisis de Negocios",
    "section": "Ejemplo",
    "text": "Ejemplo\n\nEn una empresa de telecomunicaciones se tiene un problema de retención de clientes\nMuchos de estos clientes se van a la competencia\nA este fenómeno se le conoce como CHURN o tasa de cancelación de clientes.\nTenemos dos formas de abordar la problemática:\n\nAtraer nuevos clientes\nMantener a los clientes actuales\n\nEn general, atraer nuevos clientes es más caro que mantener a los actuales\n¿Cómo podemos identificar clientes que son más propenso a cambiar de compañía?"
  },
  {
    "objectID": "slides/lec_week1.html#automatización-de-decisiones",
    "href": "slides/lec_week1.html#automatización-de-decisiones",
    "title": "Análisis de Negocios",
    "section": "Automatización de decisiones",
    "text": "Automatización de decisiones\nLa automatización de decisiones en una empresa o DDD (Data-driven decision-making), hace referencia a la práctica de basar las decisiones en el análisis de datos en vez de la intuición. Brynjolfsson, Hitt, & Kim, 2011 realizaron un estudio que analizó el rendimiento de distintas empresas, evaluando cada una de estas mediante un índice DDD que cuantificaba cuan predominante eran las decisiones basadas en el análisis de datos.\n\nLos autores mostraron estadísticamente que mientras más decisiones basadas en el análisis de datos, más productiva era la empresa. Más aún, las diferencias entre las empresas con un alto y bajo nivel de índice DDD eran notablemente grandes."
  },
  {
    "objectID": "slides/lec_week1.html#procesamiento-de-datos-y-big-data",
    "href": "slides/lec_week1.html#procesamiento-de-datos-y-big-data",
    "title": "Análisis de Negocios",
    "section": "Procesamiento de datos y “Big Data”",
    "text": "Procesamiento de datos y “Big Data”\nActualmente, dentro de las empresas existen varias áreas que trabajan con datos. No obstante, no todas ellas recaen dentro de lo que conocemos como Data Science. En general, llamamos ciencia de datos a los análisis posteriores al acceso de datos, por lo que el almacenamiento y procesamiento de datos (en el sentido ingenieril) no sería llamado Data Science. Sin embargo, el trabajo hecho por los Ingenieros de Datos es fundamental para el correcto ejercicio del análisis de negocios.\n\nEl concepto Big Data hace referencia al volumen gigante de datos disponibles, y particularmente, a las tecnologías asociadas que permiten su almacenamiento y correcto acceso, como por ejemplo Hadoop o MongoDB. Estas tecnologías son cruciales para tener acceso a los datos que se analizarán. Este tipo de tecnología (y sus alternativas) ya son estándar en la industria."
  },
  {
    "objectID": "slides/lec_week1.html#área-de-analytics",
    "href": "slides/lec_week1.html#área-de-analytics",
    "title": "Análisis de Negocios",
    "section": "Área de analytics",
    "text": "Área de analytics\nExisten distintas formas de segmentar un área de analytics en una empresa, pero por lo general, se adecuan al proceso general de minería de datos CRISP-DM (Cross Industry Standard Process for Data Mining)"
  },
  {
    "objectID": "slides/lec_week1.html#roles-frecuentes",
    "href": "slides/lec_week1.html#roles-frecuentes",
    "title": "Análisis de Negocios",
    "section": "Roles frecuentes",
    "text": "Roles frecuentes\nEntre los roles más frecuentes en el área de analytics de una empresa están:\n\nBI Analyst\nData Engineer\nSoftware Engineer\nData Scientist\nMachine Learning Researcher/Engineer\nProduct Owner"
  },
  {
    "objectID": "slides/lec_week1.html#habilidades-de-algunos-de-estos-roles",
    "href": "slides/lec_week1.html#habilidades-de-algunos-de-estos-roles",
    "title": "Análisis de Negocios",
    "section": "Habilidades de algunos de estos roles",
    "text": "Habilidades de algunos de estos roles"
  },
  {
    "objectID": "slides/lec_week1.html#manejando-un-equipo-de-data-science",
    "href": "slides/lec_week1.html#manejando-un-equipo-de-data-science",
    "title": "Análisis de Negocios",
    "section": "Manejando un equipo de Data Science",
    "text": "Manejando un equipo de Data Science\nEs posible ver un proceso de minería de datos como un proceso de desarollo de software, aplicando las metodologías usuales en aquellas áreas (Agile/Scrum). Pero dependiendo del rubro de la empresa, será una mezcla entre las metodologías ágiles de desarrollo de software y el proceso CRISP-DM."
  },
  {
    "objectID": "slides/lec_week1.html#herramientas-del-análisis-de-negocios",
    "href": "slides/lec_week1.html#herramientas-del-análisis-de-negocios",
    "title": "Análisis de Negocios",
    "section": "Herramientas del análisis de negocios",
    "text": "Herramientas del análisis de negocios\n\nEstadística\nDatabase Querying\nData Warehousing\nMachine Learning"
  },
  {
    "objectID": "slides/lec_week1.html#planteamiento-de-la-problemática",
    "href": "slides/lec_week1.html#planteamiento-de-la-problemática",
    "title": "Análisis de Negocios",
    "section": "Planteamiento de la problemática",
    "text": "Planteamiento de la problemática\n\nSi no sabemos que debemos resolver, no podremos proveer una respuesta al problema\nAntes de intentar solucionar el problema, debemos identificar en su totalidad el contexto del problema\nPreguntas como:\n\n¿El problema es recurrente?¿Requerirá una automatización posterior a encontrar una solución?\n¿Qué magnitud tiene el problema?\n¿Qué herramientas tengo disponibles? ¿Hay personas capacitadas para resolver concretamente el problema?\n¿Qué tipo de datos se tiene a disposición? ¿Es esta suficiente?\n¿Qué tanto tiempo se tiene ha disposición?"
  },
  {
    "objectID": "slides/lec_week1.html#evaluando-la-solución",
    "href": "slides/lec_week1.html#evaluando-la-solución",
    "title": "Análisis de Negocios",
    "section": "Evaluando la solución",
    "text": "Evaluando la solución\n\nUna vez identificado a cabalidad la problemática, resta preguntarnos:\n\n¿Alguien ha resuelto este tipo de problemas? ¿Cómo?\n¿Es posible replicar aquella solución?\n\nFinalmente, debemos plantear y estructurar la forma en que procederemos. Sin embargo, debemos preguntarnos:\n\n¿Es posible hacerlo dentro del contexto de la empresa?\n¿Resuelve concretamente el problema?\n¿Es eficiente la solución que podremos entregar?\n\n\n\nAl planificar los pasos a seguir, debemos ser lo más flexible posible, debido a que usualmente en proyectos de data science, los percanses suelen ocurrir."
  },
  {
    "objectID": "pages/week2.html",
    "href": "pages/week2.html",
    "title": "Semana 2",
    "section": "",
    "text": "Instalar R y Python.\nSe recomienda también instalar Rstudio y Spyder\nRepasar materia MAT042"
  },
  {
    "objectID": "pages/week2.html#presentación",
    "href": "pages/week2.html#presentación",
    "title": "Semana 2",
    "section": "Presentación",
    "text": "Presentación\nVer presentación en pantalla completa"
  },
  {
    "objectID": "pages/week2.html#material-adicional",
    "href": "pages/week2.html#material-adicional",
    "title": "Semana 2",
    "section": "Material adicional",
    "text": "Material adicional\nCapítulo 1 a 8 de Introducción a R en español\nCapítulo 1 y 2 de Python for probability, statistics, and machine learning"
  },
  {
    "objectID": "slides/lec_week2.html#distribución-binomial-en-r-y-python",
    "href": "slides/lec_week2.html#distribución-binomial-en-r-y-python",
    "title": "Conceptos Básicos",
    "section": "Distribución binomial en R y Python",
    "text": "Distribución binomial en R y Python\n\n\n\nIND 163 - Semana 2"
  },
  {
    "objectID": "pages/calendario.html",
    "href": "pages/calendario.html",
    "title": "Calendario",
    "section": "",
    "text": "Semana\nFecha\nPreparación\nPresentación\nMaterial adicional\nCertamen\nTrabajo Final\n\n\n\n\n1\n19/08\n📖\n🖥️\n📋\n\n\n\n\n2\n26/08\n📖\n🖥️\n📋\n\n\n\n\n3\n02/09\n📖\n🖥️\n📋\n\n\n\n\n4\n09/09\n📖\n🖥️\n📋\n\n\n\n\n5\n30/09\n📖\n🖥️\n📋\n📝\n\n\n\n6\n07/10\n📖\n🖥️\n📋\n\n\n\n\n7\n14/10\n📖\n🖥️\n📋\n\n\n\n\n8\n21/10\n📖\n🖥️\n📋\n\n\n\n\n9\n28/10\n📖\n🖥️\n📋\n\n\n\n\n10\n04/11\n📖\n🖥️\n📋\n📝\n📔\n\n\n11\n11/11\n📖\n🖥️\n📋\n\n\n\n\n12\n18/11\n📖\n🖥️\n📋\n\n\n\n\n13\n25/11\n📖\n🖥️\n📋\n\n📔\n\n\n14\n02/12\n📖\n🖥️\n📋\n\n\n\n\n15\n09/12\n📖\n🖥️\n📋\n\n\n\n\n16\n16/12\n📖\n🖥️\n📋\n\n📔"
  },
  {
    "objectID": "pages/evaluaciones.html",
    "href": "pages/evaluaciones.html",
    "title": "Evaluaciones",
    "section": "",
    "text": "Requerimientos mínimos de aprobación\n\nPromedio Certámenes (\\(C_1\\) y \\(C_2\\)): \\(\\overline{C}_{1,2}\\geq 55\\)\nPromedio Proyecto (\\(P_1\\) y \\(P_2\\)): \\(\\overline{P}_{1,2}\\geq 55\\)"
  },
  {
    "objectID": "pages/programa.html",
    "href": "pages/programa.html",
    "title": "Programa del curso",
    "section": "",
    "text": "Introducción a Analytics\n\nDel sistema de información de marketing al analytics ¿Qué es Analytics? ¿Para qué sirve? ¿En qué contexto es necesario?\nAnalytics en el mundo y en Chile.\nImpacto social de Analytics en Chile y el mundo.\nComposición de perfiles de un área genérica de analytics en una empresa nacional.\n\n\n\nConceptos Básicos\n\nEscuelas de probabilidad\nDistribuciones probabilistas\nTest de hipótesis e intervalos de confianza\nRegresión lineal\nEstimadores blandos y robustos\nTécnicas básicas de segmentación\nReglas de asociación\nÁrboles de decisión\nDeep learning, machine learning e inteligencia artificial.\n\n\n\nLenguajes de programación y aplicaciones en la nube\n\nIntroducción a bases de datos\nIntroducción a Python y R\nIntroducción a Google Cloud y AWS.\n\n\n\nPlanificación de proyectos de analytics aplicaciones de negocios\n\nAplicaciones transversales a la empresa."
  },
  {
    "objectID": "pages/week10.html#presentación",
    "href": "pages/week10.html#presentación",
    "title": "Semana 10",
    "section": "Presentación",
    "text": "Presentación\nVer presentación en pantalla completa"
  },
  {
    "objectID": "pages/week10.html#material-adicional",
    "href": "pages/week10.html#material-adicional",
    "title": "Semana 10",
    "section": "Material adicional",
    "text": "Material adicional"
  },
  {
    "objectID": "pages/week11.html#presentación",
    "href": "pages/week11.html#presentación",
    "title": "Semana 11",
    "section": "Presentación",
    "text": "Presentación\nVer presentación en pantalla completa"
  },
  {
    "objectID": "pages/week11.html#material-adicional",
    "href": "pages/week11.html#material-adicional",
    "title": "Semana 11",
    "section": "Material adicional",
    "text": "Material adicional"
  },
  {
    "objectID": "pages/week12.html#presentación",
    "href": "pages/week12.html#presentación",
    "title": "Semana 12",
    "section": "Presentación",
    "text": "Presentación\nVer presentación en pantalla completa"
  },
  {
    "objectID": "pages/week12.html#material-adicional",
    "href": "pages/week12.html#material-adicional",
    "title": "Semana 12",
    "section": "Material adicional",
    "text": "Material adicional"
  },
  {
    "objectID": "pages/week13.html#presentación",
    "href": "pages/week13.html#presentación",
    "title": "Semana 13",
    "section": "Presentación",
    "text": "Presentación\nVer presentación en pantalla completa"
  },
  {
    "objectID": "pages/week13.html#material-adicional",
    "href": "pages/week13.html#material-adicional",
    "title": "Semana 13",
    "section": "Material adicional",
    "text": "Material adicional"
  },
  {
    "objectID": "pages/week14.html#presentación",
    "href": "pages/week14.html#presentación",
    "title": "Semana 14",
    "section": "Presentación",
    "text": "Presentación\nVer presentación en pantalla completa"
  },
  {
    "objectID": "pages/week14.html#material-adicional",
    "href": "pages/week14.html#material-adicional",
    "title": "Semana 14",
    "section": "Material adicional",
    "text": "Material adicional"
  },
  {
    "objectID": "pages/week15.html#presentación",
    "href": "pages/week15.html#presentación",
    "title": "Semana 15",
    "section": "Presentación",
    "text": "Presentación\nVer presentación en pantalla completa"
  },
  {
    "objectID": "pages/week15.html#material-adicional",
    "href": "pages/week15.html#material-adicional",
    "title": "Semana 15",
    "section": "Material adicional",
    "text": "Material adicional"
  },
  {
    "objectID": "pages/week16.html#presentación",
    "href": "pages/week16.html#presentación",
    "title": "Semana 16",
    "section": "Presentación",
    "text": "Presentación\nVer presentación en pantalla completa"
  },
  {
    "objectID": "pages/week16.html#material-adicional",
    "href": "pages/week16.html#material-adicional",
    "title": "Semana 16",
    "section": "Material adicional",
    "text": "Material adicional"
  },
  {
    "objectID": "pages/week3.html",
    "href": "pages/week3.html",
    "title": "Semana 3",
    "section": "",
    "text": "Repasar materia MAT042: Test de hipótesis e intervalos de confianza"
  },
  {
    "objectID": "pages/week3.html#presentación",
    "href": "pages/week3.html#presentación",
    "title": "Semana 3",
    "section": "Presentación",
    "text": "Presentación\nVer presentación en pantalla completa"
  },
  {
    "objectID": "pages/week3.html#material-adicional",
    "href": "pages/week3.html#material-adicional",
    "title": "Semana 3",
    "section": "Material adicional",
    "text": "Material adicional\n\nPara contextualización en la industria, capítulo 2 de Data Science For Business: What You Need to Know About Data Mining & Data-Analytic Thinking.\nCapítulo 6, Numsense! Data Science for the Layman: No Math Added. Ng, A, Soo K."
  },
  {
    "objectID": "pages/week4.html#presentación",
    "href": "pages/week4.html#presentación",
    "title": "Semana 4",
    "section": "Presentación",
    "text": "Presentación\nVer presentación en pantalla completa"
  },
  {
    "objectID": "pages/week4.html#material-adicional",
    "href": "pages/week4.html#material-adicional",
    "title": "Semana 4",
    "section": "Material adicional",
    "text": "Material adicional"
  },
  {
    "objectID": "pages/week5.html#presentación",
    "href": "pages/week5.html#presentación",
    "title": "Semana 5",
    "section": "Presentación",
    "text": "Presentación\nVer presentación en pantalla completa"
  },
  {
    "objectID": "pages/week5.html#material-adicional",
    "href": "pages/week5.html#material-adicional",
    "title": "Semana 5",
    "section": "Material adicional",
    "text": "Material adicional"
  },
  {
    "objectID": "pages/week6.html#presentación",
    "href": "pages/week6.html#presentación",
    "title": "Semana 6",
    "section": "Presentación",
    "text": "Presentación\nVer presentación en pantalla completa"
  },
  {
    "objectID": "pages/week6.html#material-adicional",
    "href": "pages/week6.html#material-adicional",
    "title": "Semana 6",
    "section": "Material adicional",
    "text": "Material adicional"
  },
  {
    "objectID": "pages/week7.html#presentación",
    "href": "pages/week7.html#presentación",
    "title": "Semana 7",
    "section": "Presentación",
    "text": "Presentación\nVer presentación en pantalla completa"
  },
  {
    "objectID": "pages/week7.html#material-adicional",
    "href": "pages/week7.html#material-adicional",
    "title": "Semana 7",
    "section": "Material adicional",
    "text": "Material adicional\n\nCapítulo 6 y 7, Data Science For Business: What You Need to Know About Data Mining & Data-Analytic Thinking. Provost F., Fawcett, T."
  },
  {
    "objectID": "pages/week8.html#presentación",
    "href": "pages/week8.html#presentación",
    "title": "Semana 8",
    "section": "Presentación",
    "text": "Presentación\nVer presentación en pantalla completa"
  },
  {
    "objectID": "pages/week8.html#material-adicional",
    "href": "pages/week8.html#material-adicional",
    "title": "Semana 8",
    "section": "Material adicional",
    "text": "Material adicional\n\nCapítulos 7 y 9, Numsense! Data Science for the Layman: No Math Added. Ng, A, Soo K."
  },
  {
    "objectID": "pages/week9.html#presentación",
    "href": "pages/week9.html#presentación",
    "title": "Semana 9",
    "section": "Presentación",
    "text": "Presentación\nVer presentación en pantalla completa"
  },
  {
    "objectID": "pages/week9.html#material-adicional",
    "href": "pages/week9.html#material-adicional",
    "title": "Semana 9",
    "section": "Material adicional",
    "text": "Material adicional"
  },
  {
    "objectID": "slides/lec_week3.html#parámetro-y-espacio-paramétrico",
    "href": "slides/lec_week3.html#parámetro-y-espacio-paramétrico",
    "title": "Introducción a inferencia estadística",
    "section": "Parámetro y espacio paramétrico",
    "text": "Parámetro y espacio paramétrico\n\nParámetro: Es una característica numérica de la distribución de la población, que describe, parcial o completamente, la función de masa de probabilidad de la característica de interés, habitualmente se simboliza por la letra griega \\(\\theta\\).\nEspacio paramétrico: Es el conjunto de posibles valores que puede(n) ser considerado(s) para el(los) parámetro(s). Se simboliza por la letra griega mayúscula \\(\\Theta\\)."
  },
  {
    "objectID": "slides/lec_week3.html#método-de-máxima-verosimilitud",
    "href": "slides/lec_week3.html#método-de-máxima-verosimilitud",
    "title": "Introducción a inferencia estadística",
    "section": "Método de máxima verosimilitud",
    "text": "Método de máxima verosimilitud\nEl método de máxima verosimilitud consiste en encontrar el valor(es) del parámetro(s) que maximiza la función de masa (densidad) de probabilidad conjunta de la muestra, llamada verosimilitud.\n\n\nFunción de verosimilitud: Sean \\(X_1,\\cdots,X_n\\) una muestra aleatoria con función de masa(densidad) de probabilidad \\(f(X;\\theta)\\) y sea \\(L(\\theta,;X_1,\\cdots,X_n)\\) la verosimilitud de la muestra como función de \\(\\theta\\), la cual se representa por:\n\n\n\n\\[L(\\theta;x)=L(\\theta,;X_1,\\cdots,X_n)=f(x_1;\\theta)\\times f(x_2;\\theta)\\times \\cdots f(x_n;\\theta)\\]\n\n\nEl método de máxima verosimilitud busca \\(\\widehat{\\theta}(x_1,\\cdots,x_n)\\) función que depende sólo de la muestra que maximiza \\(L(\\theta;x)\\). Para obtener estimadores máximo verosímiles se utilizan las herramientas de cálculo matemático, además para simplificar los cálculos se utiliza el logaritmo de la verosimilitud, llamada función de logverosimilitud, representado por:\n\\[l(\\theta;x)=\\ln (L(\\theta;x))\\]"
  },
  {
    "objectID": "slides/lec_week3.html#método-de-mínimos-cuadrados",
    "href": "slides/lec_week3.html#método-de-mínimos-cuadrados",
    "title": "Introducción a inferencia estadística",
    "section": "Método de mínimos cuadrados",
    "text": "Método de mínimos cuadrados\nSupongamos que tenemos \\(\\mathbb{E}(Y)=\\alpha X + \\beta\\), donde \\(\\alpha,\\beta\\) y \\(X\\) son tal como en una regresión lineal simple. Sea \\((x_1,Y_1),\\dots,(x_n,Y_n)\\) una muestra aleatoria de \\(Y\\). Los estimadores mínimos cuadrados de los parámetros \\(\\alpha,\\beta\\) son los valores de \\(\\alpha\\) y \\(\\beta\\) que minimizan:\n\\[\\sum_{i=1}^{N} [Y_i - (\\alpha x_i +\\beta)]^2\\]\nPara poder obtener las estimaciones para \\(\\alpha\\) y \\(\\beta\\), procedemos de la siguiente manera:\nSea \\(S(\\alpha,\\beta)=\\sum_{i=1}^{N} [Y_i - (\\alpha x_i +\\beta)]^2\\). Para minimizar \\(S(\\alpha,\\beta)\\), debemos resolver las ecuaciones:\n\\[\\dfrac{\\partial S}{\\partial \\alpha}=0 \\hspace{20pt}\\text{y}\\hspace{20pt}\\dfrac{\\partial S}{\\partial \\beta}=0\\]"
  },
  {
    "objectID": "slides/lec_week3.html#section",
    "href": "slides/lec_week3.html#section",
    "title": "Introducción a inferencia estadística",
    "section": "",
    "text": "Derivando, obtenemos:\n\\[\\dfrac{\\partial S}{\\partial \\alpha}=\\sum_{i=1}^{n}2[Y_i - (\\alpha x_i + \\beta)](-x_i)=-2\\sum_{i=1}^{n}[x_i Y_i - \\alpha x_{i}^{2} - \\beta x_i]\\]\ny,\n\\[\\dfrac{\\partial S}{\\partial \\alpha}=\\sum_{i=1}^{n}2[Y_i - (\\alpha x_i + \\beta)](-1)=-2\\sum_{i=1}^{n}[Y_i - \\alpha x_{i} - \\beta]\\]"
  },
  {
    "objectID": "slides/lec_week3.html#hidemissingtitlestrue",
    "href": "slides/lec_week3.html#hidemissingtitlestrue",
    "title": "Introducción a inferencia estadística",
    "section": "{.hideMissingTitles=true}",
    "text": "{.hideMissingTitles=true}\nDerivando, obtenemos:\n\\[\\dfrac{\\partial S}{\\partial \\alpha}=\\sum_{i=1}^{n}2[Y_i - (\\alpha x_i + \\beta)](-x_i)=-2\\sum_{i=1}^{n}[x_i Y_i - \\alpha x_{i}^{2} - \\beta x_i]\\]\ny,\n\\[\\dfrac{\\partial S}{\\partial \\alpha}=\\sum_{i=1}^{n}2[Y_i - (\\alpha x_i + \\beta)](-1)=-2\\sum_{i=1}^{n}[Y_i - \\alpha x_{i} - \\beta]\\]"
  },
  {
    "objectID": "slides/lec_week3.html#método-de-mínimos-cuadrados-desarrollo",
    "href": "slides/lec_week3.html#método-de-mínimos-cuadrados-desarrollo",
    "title": "Introducción a inferencia estadística",
    "section": "Método de mínimos cuadrados: desarrollo",
    "text": "Método de mínimos cuadrados: desarrollo\nDerivando, obtenemos:\n\\[\\dfrac{\\partial S}{\\partial \\alpha}=\\sum_{i=1}^{n}2[Y_i - (\\alpha x_i + \\beta)](-x_i)=-2\\sum_{i=1}^{n}[x_i Y_i - \\alpha x_{i}^{2} - \\beta x_i]\\]\ny,\n\\[\\dfrac{\\partial S}{\\partial \\beta}=\\sum_{i=1}^{n}2[Y_i - (\\alpha x_i + \\beta)](-1)=-2\\sum_{i=1}^{n}[Y_i - \\alpha x_{i} - \\beta]\\]\nLuego, igualando a cero, se tiene que:\n\\[\\alpha\\sum_{i=1}^{n} x_{i}^{2} + \\beta \\sum_{i=1}^{n} x_i = \\sum_{i=1}^{n} x_i Y_i \\qquad \\text{y,} \\qquad \\alpha \\sum_{i=1}^{n} x_i + n\\beta=\\sum_{i=1}^{n} Y_i\\]"
  },
  {
    "objectID": "slides/lec_week3.html#método-de-mínimos-cuadrados-desarrollo-1",
    "href": "slides/lec_week3.html#método-de-mínimos-cuadrados-desarrollo-1",
    "title": "Introducción a inferencia estadística",
    "section": "Método de mínimos cuadrados: desarrollo",
    "text": "Método de mínimos cuadrados: desarrollo\nTenemos dos ecuaciones lineales y dos incógnitas, por lo que podemos obtener soluciones para \\(\\alpha\\) y \\(\\beta\\), así:\n\\[\\hat{\\alpha}=\\dfrac{\\sum_{i=1}^{n} Y_i (x_i - \\overline{x})}{\\sum_{i=1}^{n} (x_i-\\overline{x})^2}\\hspace{20pt}\\text{donde}\\hspace{20pt}\\overline{x}=\\dfrac{1}{n}\\sum_{i=1}^{n}x_i\\]\n\\[\\hat{\\beta}=\\overline{Y}-\\hat{\\alpha}\\overline{x}\\hspace{20pt}\\text{donde}\\hspace{20pt}\\overline{Y}=\\dfrac{1}{n}\\sum_{i=1}^{n}Y_i\\]\nEstas soluciones siempre se pueden obtener y son únicas si \\(\\sum_{i=1}^{n}(x_i-\\overline{x})^2\\neq 0\\).\nSin embargo, esta condición se satisface cuando no todos los \\(x_i\\) son iguales. En cuanto a la estimación de \\(\\sigma^2\\), esta no puede obtenida mediante este método."
  },
  {
    "objectID": "slides/lec_week3.html#propiedades-de-los-estimadores",
    "href": "slides/lec_week3.html#propiedades-de-los-estimadores",
    "title": "Inferencia estadística",
    "section": "Propiedades de los estimadores:",
    "text": "Propiedades de los estimadores:\nConsideramos una muestra aleatoria, \\(X_1,X_2,\\cdots,X_n\\) y \\(T=T(X_1,X_2,\\cdots,X_n)\\) una función de la muestra, entonces \\(T\\) es llamada un estadística. Cuando una estadística \\(T\\), se utiliza con fines de estimación recibe el nombre de estimador. En general, se desea que los estimadores tengan algunas propiedades especiales.\n\nEstimadores Insesgados: Sea \\(T\\) un estimador (estadística) de un parámetro \\(\\theta\\), se dice que \\(T\\) es un estimador insesgado (o libre de sesgo), si \\(E[T]=\\theta\\), para todos los posibles valores de \\(\\theta\\).\n\n\nEn otras palabras, lo que se desea es que el estimador \\(T\\), en promedio (promediando sobre todas las posibles muestras), sea igual a \\(\\theta\\), “lo que se desea estimar”, bajo la hipótesis que la distribución de probabilidad de la población propuesta es correcta."
  },
  {
    "objectID": "slides/lec_week3.html#propiedades-de-los-estimadores-1",
    "href": "slides/lec_week3.html#propiedades-de-los-estimadores-1",
    "title": "Inferencia estadística",
    "section": "Propiedades de los estimadores:",
    "text": "Propiedades de los estimadores:\nError Cuadrático Medio:\nSea \\(T\\) un estimador de un parámetro \\(\\theta\\), se define el error cuadrático medio de \\(T\\), como el valor esperado del cuadrado de la diferencia entre \\(T\\) y \\(\\theta\\), y se anota \\(ECM(t)\\), esto es:\n\\[ECM(T)=E[(T-\\theta)^2]\\]\nSi de desarrolla la expresión, podemos reescribir lo anterior de la forma:\n\\[ECM(T)=V[T]+(E[T]-\\theta)^2\\]\nEl error cuadrático medio de un estimador \\(T\\), es la suma de dos cantidades no negativas: una es la varianza del estimador, mientras que la otra es el sesgo al cuadrado.\nUn criterio para seleccionar un estimador, es que posea el ECM más pequeño entre los posibles estimadores de \\(\\theta\\)."
  },
  {
    "objectID": "slides/lec_week3.html#propiedades-de-los-estimadores-2",
    "href": "slides/lec_week3.html#propiedades-de-los-estimadores-2",
    "title": "Inferencia estadística",
    "section": "Propiedades de los estimadores: 2",
    "text": "Propiedades de los estimadores: 2\nError Cuadrático Medio:\nSea \\(T\\) un estimador de un parámetro \\(\\theta\\), se define el error cuadrático medio de \\(T\\), como el valor esperado del cuadrado de la diferencia entre \\(T\\) y \\(\\theta\\), y se anota \\(ECM(t)\\), esto es:\n\\[ECM(T)=E[(T-\\theta)^2]\\]\nSi de desarrolla la expresión, podemos reescribir lo anterior de la forma:\n\\[ECM(T)=V[T]+(E[T]-\\theta)^2\\]\nEl error cuadrático medio de un estimador \\(T\\), es la suma de dos cantidades no negativas: una es la varianza del estimador, mientras que la otra es el sesgo al cuadrado.\nUn criterio para seleccionar un estimador, es que posea el ECM más pequeño entre los posibles estimadores de \\(\\theta\\)."
  },
  {
    "objectID": "slides/lec_week3.html#estimadores-insesgados",
    "href": "slides/lec_week3.html#estimadores-insesgados",
    "title": "Introducción a inferencia estadística",
    "section": "Estimadores insesgados",
    "text": "Estimadores insesgados\nConsideramos una muestra aleatoria, \\(X_1,X_2,\\cdots,X_n\\) y \\(T=T(X_1,X_2,\\cdots,X_n)\\) una función de la muestra, entonces \\(T\\) es llamada un estadística. Cuando una estadística \\(T\\), se utiliza con fines de estimación recibe el nombre de estimador. En general, se desea que los estimadores tengan algunas propiedades especiales.\n\nEstimadores Insesgados: Sea \\(T\\) un estimador (estadística) de un parámetro \\(\\theta\\), se dice que \\(T\\) es un estimador insesgado (o libre de sesgo), si \\(E[T]=\\theta\\), para todos los posibles valores de \\(\\theta\\).\n\n\nEn otras palabras, lo que se desea es que el estimador \\(T\\), en promedio (promediando sobre todas las posibles muestras), sea igual a \\(\\theta\\), “lo que se desea estimar”, bajo la hipótesis que la distribución de probabilidad de la población propuesta es correcta."
  },
  {
    "objectID": "slides/lec_week3.html#error-cuadrático-medio",
    "href": "slides/lec_week3.html#error-cuadrático-medio",
    "title": "Introducción a inferencia estadística",
    "section": "Error cuadrático medio",
    "text": "Error cuadrático medio\nSea \\(T\\) un estimador de un parámetro \\(\\theta\\), se define el error cuadrático medio de \\(T\\), como el valor esperado del cuadrado de la diferencia entre \\(T\\) y \\(\\theta\\), y se anota \\(ECM(T)\\), esto es:\n\\[ECM(T)=E[(T-\\theta)^2]\\]\nSi de desarrolla la expresión, podemos reescribir lo anterior de la forma:\n\\[ECM(T)=V[T]+(E[T]-\\theta)^2\\]\nEl error cuadrático medio de un estimador \\(T\\), es la suma de dos cantidades no negativas: una es la varianza del estimador, mientras que la otra es el sesgo al cuadrado.\nUn criterio para seleccionar un estimador, es que posea el ECM más pequeño entre los posibles estimadores de \\(\\theta\\)."
  },
  {
    "objectID": "slides/lec_week3.html#eficiencia-relativa",
    "href": "slides/lec_week3.html#eficiencia-relativa",
    "title": "Introducción a inferencia estadística",
    "section": "Eficiencia relativa",
    "text": "Eficiencia relativa\nSean \\(T_1\\) y \\(T_2\\) dos estimadores de \\(\\theta\\). Se define la eficiencia relativa entre \\(T_1\\) y \\(T_2\\) como:\n\\[Ef(T_1;T_2)=\\dfrac{ECM(T_1)}{ECM(T_2)}\\]\nSi la eficiencia relativa es menor que uno, se concluye que el estimador \\(T_1\\) es más eficiente que el estimador \\(T_2\\), en caso contrario, se concluye que el estimador \\(T_1\\) es más eficiente que el estimador \\(T_2\\)."
  },
  {
    "objectID": "slides/lec_week3.html#consistencia",
    "href": "slides/lec_week3.html#consistencia",
    "title": "Introducción a inferencia estadística",
    "section": "Consistencia",
    "text": "Consistencia\nLa consistencia mide la capacidad del estimador de acercarse cada vez más al verdadero valor del parámetro, a medida que el tamaño de muestra crece.\n\\[ T_n \\overset{p}{\\to} \\theta\\]\n\nConsistencia en media cuadrática:\n\n\nUn estimador \\(T\\), de un parámetro desconocido \\(\\theta\\), se dice consistente en media cuadrática, si se cumple:\n\\[\\lim_{n\\rightarrow\\infty} ECM(T_n)=0\\]"
  },
  {
    "objectID": "slides/lec_week3.html#definición-intervalo-de-confianza",
    "href": "slides/lec_week3.html#definición-intervalo-de-confianza",
    "title": "Introducción a inferencia estadística",
    "section": "Definición intervalo de confianza",
    "text": "Definición intervalo de confianza\nSea \\(X_1,X_2,\\cdots,X_n\\) una muestra aleatoria desde \\(f(x;\\theta)\\), donde \\(f(x;\\theta)\\) es una función de masa (densidad) de probabilidades dependiendo de un parámetro desconocido \\(\\theta\\). Sean \\(T_1\\) y \\(T_2\\) dos estadísticos tales que \\(T_1(x)<T_2(x)\\) para casi todo \\(x\\) y\n\\[\\mathbb{P}(T_1\\leq\\theta \\leq T_2)=\\gamma,\\]\ndonde \\(\\gamma\\) no depende de \\(\\theta\\). Se dice que \\([T_1,T_2]\\) es un intervalo de confianza para \\(\\theta\\) con \\(100\\gamma \\%\\) de confianza.\n\n\\(T_1\\) y \\(T_2\\) reciben el nombre de cota inferior y superior de confianza, respectivamente.\n\\(\\gamma\\) recibe el nombre de coeficiente de confianza.\n\n\\([T_1,T_2]\\) es un intervalo aleatorio, ya que sus extremos son variables aleatorias."
  },
  {
    "objectID": "slides/lec_week3.html#a",
    "href": "slides/lec_week3.html#a",
    "title": "Introducción a inferencia estadística",
    "section": "a",
    "text": "a\nDe la probabilidad del pivote, podemos despejar nuestro parámetro de interés \\(\\mu\\) obteniendo:\n\\[\\mathbb{P}\\left( \\overline{X}-Z_{1-\\alpha/2} \\dfrac{\\sigma}{\\sqrt{n}} \\leq \\mu \\leq \\overline{X}-Z_{\\alpha/2}\\dfrac{\\sigma}{\\sqrt{n}}\\right) =1- \\alpha\\]\nPero como \\(Z_{\\alpha/2}=-Z_{1-\\alpha/2}\\)\n\\[\\mathbb{P}\\left( \\overline{X}-Z_{1-\\alpha/2} \\dfrac{\\sigma}{\\sqrt{n}} \\leq \\mu \\leq \\overline{X}+Z_{1-\\alpha/2}\\dfrac{\\sigma}{\\sqrt{n}}\\right) =1-\\alpha\\]\nCon lo anterior se concluye que el intervalo de \\((1-\\alpha)\\%\\) de confianza para la media poblacional está dado por:\n\\[IC(\\mu):=\\left[\\overline{X}\\mp Z_{1-\\alpha/2}\\dfrac{\\sigma}{\\sqrt{n}}\\right]\\]"
  },
  {
    "objectID": "slides/lec_week3.html#cantidad-pivotal",
    "href": "slides/lec_week3.html#cantidad-pivotal",
    "title": "Introducción a inferencia estadística",
    "section": "Cantidad pivotal",
    "text": "Cantidad pivotal\nExisten técnicas para construir intervalos (regiones) de confianza, y una de ellas es la del pivote.\n\nSea \\(X_1,X_2,\\cdots,X_n\\) una muestra aleatoria \\(n\\) desde \\(f(x;\\theta)\\) y \\(Q=Q(X_1,X_2,\\cdots,X_n)\\). Si la distribución de \\(Q\\) es independiente de \\(\\theta\\), se dice que Q es una cantidad pivotal.\n\n\nEjemplo\nSea \\(X_1,X_2,\\cdots,X_n\\) una muestra aleatoria \\(n\\) desde una familia normal \\(F_{N}(\\mu,\\sigma^2)\\) con media \\(\\mu\\) y varianza conocida \\(\\sigma^2\\), luego:\n\\[Q=\\overline{X}-\\mu \\rightarrow Q \\approx N\\left(0,\\dfrac{\\sigma^2}{n}\\right)\\]"
  },
  {
    "objectID": "slides/lec_week3.html#intervalo-de-confianza-para-la-media-poblacional",
    "href": "slides/lec_week3.html#intervalo-de-confianza-para-la-media-poblacional",
    "title": "Introducción a inferencia estadística",
    "section": "Intervalo de confianza para la media poblacional",
    "text": "Intervalo de confianza para la media poblacional\nSea \\(X_1,X_2,\\cdots,X_n\\) una muestra aleatoria \\(n\\) de una familia normal \\(F_{N}(\\mu,\\sigma^2)\\), como \\(\\overline{X}\\) es el mejor estimador de \\(\\mu\\), entonces si se conoce \\(\\sigma^2\\), se tiene que:\n\\[Z=\\dfrac{(\\overline{X}-\\mu)\\sqrt{n}}{\\sigma} \\approx N(0,1) \\Rightarrow Z \\text{ pivote}\\]\nLuego dado \\(\\gamma\\), se requiere determinar los valores más apropiados de \\(q_1\\) y \\(q_2\\) que cumplan con:\n\\[\\mathbb{P}\\left(q_1 \\leq \\dfrac{(\\overline{X}-\\mu)\\sqrt{n}}{\\sigma} \\leq q_2\\right)=\\gamma\\]\n\nSe desea minimizar la longitud del intervalo de confianza, los valores \\(q_1\\) y \\(q_2\\) deben ser aquellos que produzcan igualdad de probabilidades en las colas."
  },
  {
    "objectID": "slides/lec_week3.html#desarrollo-intervalo-de-confianza",
    "href": "slides/lec_week3.html#desarrollo-intervalo-de-confianza",
    "title": "Introducción a inferencia estadística",
    "section": "Desarrollo intervalo de confianza",
    "text": "Desarrollo intervalo de confianza\nEsto es:\n\\[q_2=Z_{\\dfrac{1+\\gamma}{2}} \\hspace{30pt} q_1=-q_2\\]\nLuego, si tomamos \\(\\alpha=1-\\gamma\\), se tiene:\n\\[\\mathbb{P}\\left( Z_{\\alpha /2} \\leq \\dfrac{(\\overline{X}-\\mu)\\sqrt{n}}{\\sigma} \\leq Z_{1-\\alpha/2} \\right)=1-\\alpha\\]"
  },
  {
    "objectID": "slides/lec_week3.html#b",
    "href": "slides/lec_week3.html#b",
    "title": "Introducción a inferencia estadística",
    "section": "b",
    "text": "b\nSi se tiene una muestra aleatoria \\(n\\) \\(X_1,X_2,\\cdots,X_n\\) tal que \\(X_i \\approx N(\\mu,\\sigma^2)\\), con varianza poblacional \\(\\sigma^2\\) desconocida, como sabemos que \\(S^2\\) es el mejor estimador de \\(\\sigma^2\\), luego se tiene:\n\\[T=\\dfrac{(\\overline{X}-\\mu)\\sqrt{n}}{s} \\approx \\mathcal{T}(n-1) \\rightarrow T \\text{ pivote}\\]\nEn donde \\(\\mathcal{T}\\) es la distribución t-student con \\((n-1)\\) grados de libertad. Análogamente, podemos construir el Intervalo de confianza para \\(\\mu\\) utilizando esta distribución, obteniéndose:\n\\[IC(\\mu):=\\left[\\overline{X}\\mp t_{1-\\alpha/2}(n-1)\\dfrac{s}{\\sqrt{n}}\\right]\\]"
  },
  {
    "objectID": "slides/lec_week3.html#i.c.-para-la-media-con-varianza-población-conocida",
    "href": "slides/lec_week3.html#i.c.-para-la-media-con-varianza-población-conocida",
    "title": "Introducción a inferencia estadística",
    "section": "I.C. para la media con varianza población conocida",
    "text": "I.C. para la media con varianza población conocida\nDe la probabilidad del pivote, podemos despejar nuestro parámetro de interés \\(\\mu\\) obteniendo:\n\\[\\mathbb{P}\\left( \\overline{X}-Z_{1-\\alpha/2} \\dfrac{\\sigma}{\\sqrt{n}} \\leq \\mu \\leq \\overline{X}-Z_{\\alpha/2}\\dfrac{\\sigma}{\\sqrt{n}}\\right) =1- \\alpha\\]\nPero como \\(Z_{\\alpha/2}=-Z_{1-\\alpha/2}\\)\n\\[\\mathbb{P}\\left( \\overline{X}-Z_{1-\\alpha/2} \\dfrac{\\sigma}{\\sqrt{n}} \\leq \\mu \\leq \\overline{X}+Z_{1-\\alpha/2}\\dfrac{\\sigma}{\\sqrt{n}}\\right) =1-\\alpha\\]\nCon lo anterior se concluye que el intervalo de \\((1-\\alpha)\\%\\) de confianza para la media poblacional está dado por:\n\\[IC(\\mu):=\\left[\\overline{X}\\mp Z_{1-\\alpha/2}\\dfrac{\\sigma}{\\sqrt{n}}\\right]\\]"
  },
  {
    "objectID": "slides/lec_week3.html#i.c.-para-la-media-con-varianza-población-desconocida",
    "href": "slides/lec_week3.html#i.c.-para-la-media-con-varianza-población-desconocida",
    "title": "Introducción a inferencia estadística",
    "section": "I.C. para la media con varianza población desconocida",
    "text": "I.C. para la media con varianza población desconocida\nSi se tiene una muestra aleatoria de tamaño \\(n\\), \\(X_1,X_2,\\cdots,X_n\\) tal que \\(X_i \\approx N(\\mu,\\sigma^2)\\), con varianza poblacional \\(\\sigma^2\\) desconocida, como sabemos que \\(S^2\\) es el mejor estimador de \\(\\sigma^2\\), se tiene:\n\\[T=\\dfrac{(\\overline{X}-\\mu)\\sqrt{n}}{s} \\approx \\mathcal{T}(n-1) \\Rightarrow T \\text{ pivote}\\]\nEn donde \\(\\mathcal{T}\\) es la distribución t-student con \\((n-1)\\) grados de libertad. Análogamente, podemos construir el intervalo de confianza para \\(\\mu\\) utilizando esta distribución, obteniéndose:\n\\[IC(\\mu):=\\left[\\overline{X}\\mp t_{1-\\alpha/2}(n-1)\\dfrac{s}{\\sqrt{n}}\\right]\\]"
  },
  {
    "objectID": "slides/lec_week3.html#i.c.-para-la-media-con-tamaño-de-muestra-grande",
    "href": "slides/lec_week3.html#i.c.-para-la-media-con-tamaño-de-muestra-grande",
    "title": "Introducción a inferencia estadística",
    "section": "I.C. para la media con tamaño de muestra grande",
    "text": "I.C. para la media con tamaño de muestra grande\nSi el tamaño de muestra es muy grande (mayor que 50), utilizando el teorema de límite central, el intervalo de confianza toma la siguiente forma:\n\\[IC(\\mu):=\\left[\\overline{X}\\mp Z_{1-\\alpha/2}\\dfrac{s}{\\sqrt{n}}\\right]\\]\nNotamos que es importante distinguir cuando la varianza poblacional es conocida o desconocida. Si a partir de la muestra aleatoria se determina una varianza, ésta es la muestral, por lo tanto, lo correcto es utilizar un intervalo de confianza considerando la distribución t-student, caso contrario si la muestra es superior a 50, entonces empleamos el teorema de límite central para aproximar por distribución normal."
  },
  {
    "objectID": "slides/lec_week3.html#intervalos-de-confianza-para-una-proporción",
    "href": "slides/lec_week3.html#intervalos-de-confianza-para-una-proporción",
    "title": "Introducción a inferencia estadística",
    "section": "Intervalos de confianza para una proporción",
    "text": "Intervalos de confianza para una proporción\nSea \\(X_1,X_2,\\cdots,X_n\\) una muestra aleatoria de tamaño \\(n\\) de una familia binomial \\(\\mathcal{B} (1,p)\\). El estimador de \\(p\\) sobre la base de la muestra es \\(\\widehat{P}=\\overline{X}\\). La distribución de \\(\\widehat{P}=\\overline{X}\\), para muestras grandes, se puede aproximar mediante una distribución normal de parámetros \\(p\\) y \\(\\dfrac{p(1-p)}{n}\\). Con esto podemos aproximar la siguiente cantidad pivotal:\n\\[Z=\\dfrac{(\\widehat{P}-p)}{\\sqrt{\\dfrac{\\widehat{P}(1-\\widehat{P})}{n}}} \\approx N(0,1) \\Rightarrow Z \\text{ pivote}\\]\nLuego dado \\((1-\\alpha)\\), los valores de \\(q_1\\) y \\(q_2\\) que minimizan la longitud del intervalo serán:\n\\[\\mathbb{P}\\left(  \\widehat{P}-Z_{1-\\alpha /2} \\sqrt{\\dfrac{\\widehat{P}(1-\\widehat{P})}{n}} \\leq p \\leq \\widehat{P}+Z_{1-\\alpha /2} \\sqrt{\\dfrac{\\widehat{P}(1-\\widehat{P}) }{n} } \\right)=\\gamma \\]"
  },
  {
    "objectID": "slides/lec_week3.html#i.c.-final-para-una-proporción",
    "href": "slides/lec_week3.html#i.c.-final-para-una-proporción",
    "title": "Introducción a inferencia estadística",
    "section": "I.C. final para una proporción",
    "text": "I.C. final para una proporción\nLuego, el intervalo de confianza, del \\((100*\\gamma)\\%\\) para la proporción es:\n\\[IC(p):=\\left[ \\widehat{P}\\mp Z_{1-\\alpha/2}\\sqrt{\\dfrac{\\widehat{P}(1-\\widehat{P})}{n}}\\right] \\]\nSe puede apreciar que los intervalos de confianza anteriores están compuestos por un estimador puntual, más o menos una cantidad, ésta cantidad recibe el nombre de error de estimación, que resultará útil para determinar el tamaños de muestra."
  },
  {
    "objectID": "slides/lec_week3.html#intervalos-de-confianza-para-la-varianza-poblacional",
    "href": "slides/lec_week3.html#intervalos-de-confianza-para-la-varianza-poblacional",
    "title": "Introducción a inferencia estadística",
    "section": "Intervalos de confianza para la varianza poblacional",
    "text": "Intervalos de confianza para la varianza poblacional\nSea \\(X_1,X_2,\\dots,X_n\\) una muestra aleatoria de tamaño \\(n\\) desde una familia normal \\(F_N(\\mu,\\sigma^2)\\). Existen dos posibilidades para la estimación de la varianza, cuando la media población es conocida (caso no práctico) y cuando ésta es desconocida. Para ambos casos podemos definir cantidades pivotales:\n\n\\(\\dfrac{n S_{n}^{2}}{\\sigma^2} \\sim \\chi^2(n)\\)\n\n\\(\\dfrac{(n-1) S_{n-1}^{2}}{\\sigma^2} \\sim \\chi^2(n-1)\\)\n\n\nen donde:\n\\[S_{n}^{2}=\\sum_{i=1}^{n} \\dfrac{(X_i - \\mu)^2}{n},\\qquad S_{n-1}^{2}=\\sum_{i=1}^{n} \\dfrac{(X_i - \\overline{X})^2}{n-1}\\]"
  },
  {
    "objectID": "slides/lec_week3.html#i.c.-final-para-la-varianza-poblacional",
    "href": "slides/lec_week3.html#i.c.-final-para-la-varianza-poblacional",
    "title": "Introducción a inferencia estadística",
    "section": "I.C. final para la varianza poblacional",
    "text": "I.C. final para la varianza poblacional\nSiguiendo el mismo procedimiento para la cantidad pivotal, en particular, el caso donde la media poblacional es desconocida. Se tiene:\n\\[\\mathbb{P}\\left[ \\chi_{\\alpha/2}^{2}(n-1) \\leq \\dfrac{(n-1) S_{n-1}^{2}}{\\sigma^2} \\leq \\chi_{1-\\alpha/2}^{2}(n-1) \\right]=1-\\alpha\\]\nLuego, despejando el parámetro de interés \\(\\sigma^2\\), podemos definir un intervalo de \\((1-\\alpha)\\%\\) de confianza para la varianza poblacional:\n\\[IC(\\sigma^2)=\\left[ \\dfrac{(n-1)S_{n-1}^{2}}{\\chi_{1-\\alpha/2}^{2}(n-1)};\\dfrac{(n-1)S_{n-1}^{2}}{\\chi_{\\alpha/2}^{2}(n-1)}\\right]\\]"
  },
  {
    "objectID": "slides/lec_week3.html#test-de-hipótesis-1",
    "href": "slides/lec_week3.html#test-de-hipótesis-1",
    "title": "Introducción a inferencia estadística",
    "section": "Test de hipótesis:",
    "text": "Test de hipótesis:\nPara llegar a tomar decisiones, conviene hacer determinados supuestos o conjeturas acerca de las poblaciones que se estudian. Tales supuestos que pueden ser o no ciertos y se llaman hipótesis estadísticas y, en general, lo son sobre las distribuciones de probabilidad de las poblaciones.\nEn muchos casos se formulan las hipótesis estadísticas con el sólo propósito de rechazarlas o invalidarlas. Cualquier hipótesis que difiera de una hipótesis dada se llama hipótesis alternativa. Denotaremos por \\(H_0\\) a nuestro supuesto o hipótesis nula, y \\(H_1\\) a nuestra hipótesis alternativa."
  },
  {
    "objectID": "slides/lec_week3.html#tipos-de-error",
    "href": "slides/lec_week3.html#tipos-de-error",
    "title": "Introducción a inferencia estadística",
    "section": "Tipos de error",
    "text": "Tipos de error\nAl realizar nuestra prueba de hipótesis estamos sujetos al estado real de la naturaleza, es decir, la veracidad de nuestra conjetura (\\(H_0\\))\n\n\n\n\n\n\n\n\n\n\n\nEstado Real\nen la naturaleza\n\n\n\n\n\n\n\\(H_0\\) es Verdadera\n\\(H_0\\) es Falsa\n\n\nDecisión\nNo se rechaza \\(H_0\\)\nDecisión Correcta\nError Tipo II\n\n\n\nSe rechaza \\(H_0\\)\nError Tipo I\nDecisión Correcta\n\n\n\nPodemos cometer dos tipos de errores, tipo I y tipo II.\n\nError tipo I: Se comete al rechazar la hipótesis nula, cuando corresponde aceptarla por ser ésta verdadera. Lo denotamos por \\(\\alpha\\) y es llamado nivel de significación.\nError tipo II: Se comete al no rechazar la hipótesis nula, cuando corresponde rechazarla por ser esta falsa. Lo denotamos por \\(\\beta\\).\n\n\nEl error tipo I es fundamental debido a que es el error que el experimentador controla y pueda manejar."
  },
  {
    "objectID": "slides/lec_week3.html#prueba-para-la-media-poblacional",
    "href": "slides/lec_week3.html#prueba-para-la-media-poblacional",
    "title": "Introducción a inferencia estadística",
    "section": "Prueba para la media poblacional",
    "text": "Prueba para la media poblacional\nSea \\(X_1,X_2,\\dots,X_n\\) una muestra aleatoria de una distribución normal con media \\(\\mu\\) desconocida. En este caso el interés recae en probar uno de los siguientes conjuntos de hipotesis con respecto a \\(\\mu\\).\n\\[H_0:\\mu = \\mu_0 \\qquad H_0:\\mu= \\mu_0 \\qquad H_0:\\mu = \\mu_0 \\\\H_1:\\mu \\neq \\mu_0 \\qquad H_1:\\mu > \\mu_0 \\qquad H_1:\\mu < \\mu_0\\]\nSupongamos primero que la varianza poblacional \\(\\sigma^2\\) es conocida. Utilizando la estadística de prueba \\(\\overline{X}\\), bajo \\(H_0\\) se tiene que \\(\\overline{X}\\sim N\\left(\\mu_0,{\\sigma^2 \\over n}\\right)\\). La región crítica de tamaño \\(\\alpha\\) para la hipótesis bilateral es de la forma:\n\\[\\text{Rechazar }H_0 \\text{ si}\\begin{cases} \\overline{X}\\geq \\overline{x}_{1-\\alpha /2}\\\\ \\overline{X}\\leq \\overline{x}_{\\alpha /2} \\end{cases}\\]"
  },
  {
    "objectID": "slides/lec_week3.html#prueba-para-la-media-poblacional-desarrollo",
    "href": "slides/lec_week3.html#prueba-para-la-media-poblacional-desarrollo",
    "title": "Introducción a inferencia estadística",
    "section": "Prueba para la media poblacional: desarrollo",
    "text": "Prueba para la media poblacional: desarrollo\nEn donde \\(\\overline{x}_{1-\\alpha /2}\\) y, \\(\\overline{x}_{\\alpha /2}\\) son los valores cuantiles críticos de \\(\\overline{X}\\) de manera tal que:\n\\[\\mathbb{P}(\\overline{X}\\geq  \\overline{x}_{1-\\alpha /2})= \\alpha /2 \\hspace{20pt}\\text{y}\\hspace{20pt} \\mathbb{P}(\\overline{X}\\geq  \\overline{x}_{\\alpha /2})= \\alpha /2\\]\nDado que bajo \\(H_0, \\overline{X}\\sim N(\\mu_0,{\\sigma^2 \\over n})\\), entonces de forma equivalente:\n\\[\\mathbb{P}\\left( Z \\geq \\underbrace{\\dfrac{\\overline{x}_{1-\\alpha /2}-\\mu_0}{\\sigma / \\sqrt{n}}}_{z_{1-\\alpha /2}}\\right)=\\alpha /2\\hspace{20pt}\\text{y}\\hspace{20pt}\\mathbb{P}\\left( Z \\leq \\underbrace{\\dfrac{\\overline{x}_{\\alpha /2}-\\mu_0}{\\sigma / \\sqrt{n}}}_{z_{\\alpha /2}}\\right)=\\alpha /2\\]\nPor lo que, \\(H_0\\) debe rechazarse cuando un valor de \\(\\overline{x}\\) de la media muestral \\(\\overline{X}\\) es tal que:\n\\[\\overline{x} \\geq \\dfrac{\\sigma z_{1-\\alpha /2}}{\\sqrt{n}}+\\mu_0\\hspace{20pt}\\text{o}\\hspace{20pt}\\overline{x} \\leq \\dfrac{\\sigma z_{\\alpha /2}}{\\sqrt{n}}+\\mu_0\\]"
  },
  {
    "objectID": "slides/lec_week3.html#prueba-para-la-media-poblacional-regiones-de-rechazo",
    "href": "slides/lec_week3.html#prueba-para-la-media-poblacional-regiones-de-rechazo",
    "title": "Introducción a inferencia estadística",
    "section": "Prueba para la media poblacional: regiones de rechazo",
    "text": "Prueba para la media poblacional: regiones de rechazo\nDe manera equivalente, se rechazará \\(H_0\\) cuando,\n\\[z\\geq z_{1-\\alpha /2}\\hspace{20pt}\\text{o}\\hspace{20pt}z\\leq z_{\\alpha /2}\\]\nDonde \\(z=\\dfrac{\\overline{x}-\\mu_0}{\\sigma / \\sqrt{n}}\\) es el valor de la correspondiente normal estándar al valor \\(\\overline{x}\\) de \\(\\overline{X}\\).\nPara la hipótesis alternativa unilateral, \\(H_1: \\mu > \\mu_0\\), la región crítica de tamaño \\(\\alpha\\) es el extremo derecho de la distribución de muestreo de \\(\\overline{X}\\), ésta es de la forma:\n\\[\\text{Rechazar } H_0  \\text{ si } \\overline{X} \\geq \\overline{x}_{1-\\alpha}\\]\nDe forma similar, para la hipótesis alternativa unilateral \\(H_1:\\mu < \\mu_0\\), la región crítica es de la forma:\n\\[\\text{Rechazar } H_0 \\text{ si } \\overline{X} \\leq \\overline{x}_{1-\\alpha}\\]"
  },
  {
    "objectID": "slides/lec_week3.html#observaciones",
    "href": "slides/lec_week3.html#observaciones",
    "title": "Introducción a inferencia estadística",
    "section": "Observaciones",
    "text": "Observaciones\nNotar que lo anterior, sólo fue posible debido a que sabíamos \\(\\sigma^2\\). En caso de no conocerlo, si utilizamos la misma estadística de prueba \\(\\overline{X}\\), se tiene que:\n\\[T=\\dfrac{\\overline{X}-\\mu_0}{S / \\sqrt{n}} \\sim t(n-1)\\]\nPor lo que siguiendo el mismo procedimiento que antes, podemos llegar a regiones críticas similares."
  },
  {
    "objectID": "slides/lec_week3.html#pruebas-para-la-varianza-poblacional",
    "href": "slides/lec_week3.html#pruebas-para-la-varianza-poblacional",
    "title": "Introducción a inferencia estadística",
    "section": "Pruebas para la varianza poblacional",
    "text": "Pruebas para la varianza poblacional\nSea \\(X_1,\\dots,X_n\\) una muestra aleatoria de una distribución normal con media \\(\\mu\\) desconocida y varianza \\(\\sigma^2\\). Se considera el siguiente test de hipótesis:\n\\[H_0:\\sigma^2=\\sigma_{0}^{2}\\]\ncontra una de las siguientes alternativas:\n\\[H_1:\\sigma^2\\neq \\sigma_{0}^{2},\\hspace{5pt}H_1:\\sigma^2> \\sigma_{0}^{2},\\hspace{5pt}H_1:\\sigma^2< \\sigma_{0}^{2}\\]\ndonde \\(\\sigma_{0}^{2}\\) es el valor propuesto para \\(\\sigma^2\\). La estadística de interés es la varianza muestral \\(S^2\\). La hipótesis nula será rechazada si la realización de \\(s^2\\) calculada a partir de la muestra, es suficientemente diferente, mayor que o menos que \\(\\sigma_{0}^{2}\\), dependiendo de la hipótesis alternativa. Bajo \\(H_0\\):\n\\[\\dfrac{(n-1)s^2}{\\sigma_{0}^{2}}\\sim  \\chi^2(n-1)\\]"
  },
  {
    "objectID": "slides/lec_week3.html#pruebas-para-la-proporción-poblacional",
    "href": "slides/lec_week3.html#pruebas-para-la-proporción-poblacional",
    "title": "Introducción a inferencia estadística",
    "section": "Pruebas para la proporción poblacional",
    "text": "Pruebas para la proporción poblacional\nSea \\(X_1,\\dots,X_n\\) una muestra aleatoria de una distribución Bernoulli \\(Ber(1,p)\\). Consideramos el siguiente test de hipótesis:\n\\[H_0:p=p_0\\]\ncontra una de las siguientes alternativas:\n\\[H_1:p\\neq p_0,\\hspace{5pt}H_1:p> p_0,\\hspace{5pt}H_1:p<p_0\\]\ndonde \\(p_0\\) es el valor propuesto para \\(p\\). La estadística de interés bajo \\(H_0\\) es:\n\\[E=\\dfrac{\\hat{p}-p_0}{\\sqrt{\\dfrac{p_0(1-p_0)}{n}}}\\sim N(0,1)\\]\nPara \\(n>>50\\) y \\(\\hat{p}=\\sum_{i=1}^{n}X_i/n\\)"
  },
  {
    "objectID": "slides/lec_week3.html#t",
    "href": "slides/lec_week3.html#t",
    "title": "Introducción a inferencia estadística",
    "section": "t",
    "text": "t\n ## Pruebas para la varianza poblacional\nSea \\(X_1,\\dots,X_n\\) una muestra aleatoria de una distribución normal con media \\(\\mu\\) desconocida y varianza \\(\\sigma^2\\). Se considera el siguiente test de hipótesis:\n\\[H_0:\\sigma^2=\\sigma_{0}^{2}\\]\ncontra una de las siguientes alternativas:\n\\[H_1:\\sigma^2\\neq \\sigma_{0}^{2},\\hspace{5pt}H_1:\\sigma^2> \\sigma_{0}^{2},\\hspace{5pt}H_1:\\sigma^2< \\sigma_{0}^{2}\\]\ndonde \\(\\sigma_{0}^{2}\\) es el valor propuesto para \\(\\sigma^2\\). La estadística de interés es la varianza muestral \\(S^2\\). La hipótesis nula será rechazada si la realización de \\(s^2\\) calculada a partir de la muestra, es suficientemente diferente, mayor que o menos que \\(\\sigma_{0}^{2}\\), dependiendo de la hipótesis alternativa. Bajo \\(H_0\\):\n\\[\\dfrac{(n-1)s^2}{\\sigma_{0}^{2}}\\sim  \\chi^2(n-1)\\]"
  },
  {
    "objectID": "slides/lec_week3.html#tabla-resumen-i.c.-para-la-media-con-varianza-conocida",
    "href": "slides/lec_week3.html#tabla-resumen-i.c.-para-la-media-con-varianza-conocida",
    "title": "Introducción a inferencia estadística",
    "section": "Tabla resumen I.C. para la media con varianza conocida",
    "text": "Tabla resumen I.C. para la media con varianza conocida\nLo anterior puede ser resumido en:"
  },
  {
    "objectID": "slides/lec_week3.html#tabla-resumen-i.c.-para-la-media-con-varianza-desconocida",
    "href": "slides/lec_week3.html#tabla-resumen-i.c.-para-la-media-con-varianza-desconocida",
    "title": "Introducción a inferencia estadística",
    "section": "Tabla resumen I.C. para la media con varianza desconocida",
    "text": "Tabla resumen I.C. para la media con varianza desconocida\nLo anterior puede ser resumido en:"
  },
  {
    "objectID": "slides/lec_week3.html#tabla-resumen-pruebas-para-la-media-con-varianza-conocida",
    "href": "slides/lec_week3.html#tabla-resumen-pruebas-para-la-media-con-varianza-conocida",
    "title": "Introducción a inferencia estadística",
    "section": "Tabla resumen pruebas para la media con varianza conocida",
    "text": "Tabla resumen pruebas para la media con varianza conocida\nLo anterior puede ser resumido en:"
  },
  {
    "objectID": "slides/lec_week3.html#tabla-resumen-pruebas-para-la-media-con-varianza-desconocida",
    "href": "slides/lec_week3.html#tabla-resumen-pruebas-para-la-media-con-varianza-desconocida",
    "title": "Introducción a inferencia estadística",
    "section": "Tabla resumen pruebas para la media con varianza desconocida",
    "text": "Tabla resumen pruebas para la media con varianza desconocida\nLo anterior puede ser resumido en:"
  },
  {
    "objectID": "slides/lec_week3.html#tabla-resumen-pruebas-para-la-varianza",
    "href": "slides/lec_week3.html#tabla-resumen-pruebas-para-la-varianza",
    "title": "Introducción a inferencia estadística",
    "section": "Tabla resumen pruebas para la varianza",
    "text": "Tabla resumen pruebas para la varianza\nAsí, conforme la misma construcción realizada anteriormente, es posible encontrar las criterios de rechazo, en resumen:"
  },
  {
    "objectID": "slides/lec_week3.html#tabla-resumen-pruebas-para-la-proporción",
    "href": "slides/lec_week3.html#tabla-resumen-pruebas-para-la-proporción",
    "title": "Introducción a inferencia estadística",
    "section": "Tabla resumen pruebas para la proporción",
    "text": "Tabla resumen pruebas para la proporción\nAsí, conforme la misma construcción realizada anteriormente, es posible enconrtar los criterios de rechazo, en resumen:"
  },
  {
    "objectID": "slides/lec_week3.html#definición-formal",
    "href": "slides/lec_week3.html#definición-formal",
    "title": "Introducción a inferencia estadística",
    "section": "Definición formal",
    "text": "Definición formal\nUn modelo de regresión básico donde sólo hay una variable predictora y la función de regresión es lineal se define como:\n\\[Y_i=\\beta_0+\\beta_1 X_i + \\varepsilon_i\\]\ndonde,\n\n\\(Y_i\\) es el valor de la varible respuesta en la i-ésima observación\n\\(\\beta_0\\) y \\(\\beta_1\\) son parámetros\n\\(X_i\\) es una constante conocida: el valor de la variable predictora en la i-ésima observación.\n\\(\\varepsilon_i\\) es un término de error aleatorio con meadia \\(\\mathbb{E}(\\varepsilon_i)=0\\) y varianza \\(\\mathbb{V}(\\varepsilon_i)=\\sigma^2\\)\n\\(\\varepsilon_i\\) y \\(\\varepsilon_j\\) no están correlacionados, por lo que su covarianza es cero.\n\n\nEsto modelo se le conoce como modelo de regresión lineal simple."
  },
  {
    "objectID": "slides/lec_week3.html#características-importantes-del-modelo-de-regresión-lineal-simple",
    "href": "slides/lec_week3.html#características-importantes-del-modelo-de-regresión-lineal-simple",
    "title": "Introducción a inferencia estadística",
    "section": "Características importantes del modelo de regresión lineal simple",
    "text": "Características importantes del modelo de regresión lineal simple\nLa respuesta \\(Y_i\\) en la i-ésimo ensayo es la suma de dos componentes: - El término constante \\(\\beta_0+\\beta_1 X_i\\) y, - El término aleatorio \\(\\varepsilon_i\\). Por lo que \\(Y_i\\) es una variable aleatoria\nDebido a que \\(\\mathbb{E}(\\varepsilon_i)=0\\), sigue que:\n\\[\\mathbb{E}(Y_i)=\\mathbb{E}(\\beta_0+\\beta_1 X_i + \\varepsilon_i)=\\beta_0+\\beta_1 X_i + \\mathbb{E}(\\varepsilon_i)= \\beta_0+\\beta_1 X_i\\]\nAsí, la respuesta \\(Y_i\\), cuando el nivel de \\(X\\) en el i-ésimo ensayo es \\(X_i\\), viene desde una distribución de probabilidad cuya media está dada por:\n\\[\\mathbb{E}(Y_i)=\\beta_0+\\beta_1 X_i\\]\nSabremos que la función de regresión para este modelo es \\(\\mathbb{E}(Y)=\\beta_0+\\beta_1 X\\)\nDebido a que la función de regresión relaciona la media de la distribución de probabilidad de \\(Y\\) para un \\(X\\) dado para el nivel de \\(X\\)."
  },
  {
    "objectID": "slides/lec_week3.html#características-importantes-del-modelo-de-regresión-lineal-simple-continuación",
    "href": "slides/lec_week3.html#características-importantes-del-modelo-de-regresión-lineal-simple-continuación",
    "title": "Introducción a inferencia estadística",
    "section": "Características importantes del modelo de regresión lineal simple: continuación",
    "text": "Características importantes del modelo de regresión lineal simple: continuación\nLa respuesta \\(Y_i\\) en el i-ésimo ensayo excede o queda bajo el valor de la función de regresión por la cantidad del término \\(\\varepsilon_i\\). Además, Los errores \\(\\varepsilon_i\\) se asumen que tienen varianza constante \\(\\sigma^2\\), por lo que la variable respuesta \\(Y_i\\) tiene la misma varianza constante.\nAsí, el modelo de regresión lineal simple asume que la distribución de probabilidad de \\(Y\\) tiene la misma varianza \\(\\sigma^2\\), independiente del nivel de la variable predictora \\(X\\).\nLos errores se asumen independientes. Debido a que los términos \\(\\varepsilon_i\\) y \\(\\varepsilon_j\\) no están correlacionados, también no lo estarán las respuestas \\(Y_i\\) e \\(Y_j\\).\nEn resumen, el modelo de regresión lineal simple implica que la respuesta \\(Y_i\\) viene desde una distribución de probabilidad cuyas medias son \\(\\mathbb{E}(Y_i)=\\beta_0+\\beta_1 X_i\\) y cuyas varianzas son \\(\\sigma^2\\), para todos los niveles de \\(X\\). Además, dos respuestas distintas \\(Y_i\\) e \\(Y_j\\) no están correlacionadas."
  },
  {
    "objectID": "slides/lec_week3.html#interpretación-de-los-parámetros-de-regresión",
    "href": "slides/lec_week3.html#interpretación-de-los-parámetros-de-regresión",
    "title": "Introducción a inferencia estadística",
    "section": "Interpretación de los parámetros de regresión",
    "text": "Interpretación de los parámetros de regresión\nLos parámetros de regresión \\(\\beta_0\\) y \\(\\beta_1\\) en un modelo de regresión lineal simple son llamados coeficientes de regresión, siendo \\(\\beta_1\\) la pendiente y \\(\\beta_0\\) el intercepto. El primero indica el cambio en la media de la distribución de probabilidad de \\(Y\\) por el incremento unitario en \\(X\\).\nCuando el alcance del modelo incluye \\(X=0\\), \\(\\beta_0\\) entrega la media de la distribución de probabilidad de \\(Y\\) en \\(X=0\\). Cuando el alcance del modelo no incluye \\(X=0\\), \\(\\beta_0\\) no tienen ninguna interpretación particular como termino separado en la regresión."
  },
  {
    "objectID": "slides/lec_week3.html#teorema-de-gauss-markov",
    "href": "slides/lec_week3.html#teorema-de-gauss-markov",
    "title": "Introducción a inferencia estadística",
    "section": "Teorema de Gauss-Markov",
    "text": "Teorema de Gauss-Markov\n\nBajo las condiciones de un modelo de regresión lineal simple, los estimadores de mínimos cuadrados \\(b_0\\) y \\(b_1\\) son estimadores insesgados y tienen mínima varianza entre los estimadores insesgados lineales.\n\nEste teorema establece que \\(b_0\\) y \\(b_1\\) son estimadores insesgados, por lo que:\n\\[\\mathbb{E}(b_0)=\\beta_0 \\hspace{40pt} \\mathbb{E}(b_1)=\\beta_1\\]\nPor lo que ninguno de estos estimadores tiende a sobrestimar o subestimar sistemáticamente. Segundo, el teorema establece que los estimadores \\(b_0\\) y \\(b_1\\) son más precisos (esto es, su distribución muestral es menos variable) que cualquier otro estimador perteneciente a la clase de estimadores insesgados que son funciones lineales de las observaciones \\(Y_1,\\dots,Y_n\\).\nLos estimadores \\(b_0\\) y \\(b_1\\) son funciones lineal de \\(Y_i\\)."
  },
  {
    "objectID": "slides/lec_week3.html#propiedades-del-ajuste-de-regresión",
    "href": "slides/lec_week3.html#propiedades-del-ajuste-de-regresión",
    "title": "Introducción a inferencia estadística",
    "section": "Propiedades del ajuste de regresión",
    "text": "Propiedades del ajuste de regresión\nEl ajuste de regresión lineal al usar el método de mínimos cuadrados tiene un número de propiedades que valen la pena mencionar. Estas propiedades de los estimadores de mínimos cuadrados de una función de regresión no aplican para todos los modelos de regresión.\n\nLa suma de los residuos es cero: \\(\\sum_{i=1}^{n} e_i = 0\\)\nLa suma de los valores observados \\(Y_i\\) es igual a la suma de los valores ajustados \\(\\widehat{Y}_i\\):\n\n\n\\[\\sum_{i=1}^{n} Y_i = \\sum_{i=1}^{n} \\widehat{Y}_i\\]\n\n\nDe esto último, se desprende que la media de los valores ajustados \\(\\widehat{Y}_i\\) es la misma que la media de los valores observados \\(Y_i\\)."
  },
  {
    "objectID": "slides/lec_week3.html#propiedades-del-ajuste-de-regresión-continuación",
    "href": "slides/lec_week3.html#propiedades-del-ajuste-de-regresión-continuación",
    "title": "Introducción a inferencia estadística",
    "section": "Propiedades del ajuste de regresión: continuación",
    "text": "Propiedades del ajuste de regresión: continuación\n\nLa suma de los residuos ponderados es cero cuando el i-ésimo residuo es ponderado con el nivel de la variable predictora i-ésima, esto es:\n\n\n\\[\\sum_{i=1}^{n} X_i e_i = 0\\]\n\nUna consecuencia de las propiedades 1 y 3, es que la suma de los pesos ponderados es cero cuando el i-ésimo residuo es ponderado con el valor ajustado de la i-ésima variable respuesta, esto es:\n\n\n\n\\[\\sum_{i=1}^{n} \\widehat{Y}_i e_i = 0\\]\n\nLa recta de regresión siempre pasa por el punto \\((\\overline{X},\\overline{Y})\\)."
  },
  {
    "objectID": "slides/lec_week4.html#inferencia-sobre-la-pendiente",
    "href": "slides/lec_week4.html#inferencia-sobre-la-pendiente",
    "title": "Regresión lineal",
    "section": "Inferencia sobre la pendiente",
    "text": "Inferencia sobre la pendiente\nFrecuentemente es de particular interés la inferencia sobre el parámetro de la pendiente de regresión, pues nos entrega una noción de cambio medio por unidad en la variable regresora. Un tipo de test relevante en este contexto es:\n\\[H_0: \\beta_1=0 \\hspace{20pt} H_1: \\beta_1\\ne 0\\]\nEste test de hipótesis es relevante debido a que cuando \\(\\beta_1=0\\), no existe una asociación lineal entre las variables \\(X\\) e \\(Y\\).\nEn el caso de que el término de error en el modelo de regresión sea normal, la condición de que \\(\\beta_1=0\\) implica aún más cosas. Debido a que en este modelo todas las distribución de probabilidades de \\(Y\\) son normales con varianza constante, y que las medias son iguales cuando \\(\\beta_1=0\\), sigue que las distribuciones de probabilidad de \\(Y\\) son idénticas cuando \\(\\beta_1=0\\).\n\nAsí, \\(\\beta_1=0\\) para el modelo de regresión lineal normal implica que no sólo no existe relación lineal entre \\(X\\) e \\(Y\\), pero además no existe ningún tipo de relación entre \\(Y\\) y \\(X\\), dado que las distribuciones de probabilidad de \\(Y\\) son idénticas para todos los niveles de \\(X\\)."
  },
  {
    "objectID": "slides/lec_week4.html#distribución-muestral-de-b_1",
    "href": "slides/lec_week4.html#distribución-muestral-de-b_1",
    "title": "Regresión lineal",
    "section": "Distribución muestral de \\(b_1\\)",
    "text": "Distribución muestral de \\(b_1\\)\nPor lo visto antes, sabemos que el estimador puntual de \\(b_1\\) está dado por:\n\\[b_1=\\dfrac{\\sum (X_i-\\overline{X})(Y_i - \\overline{Y})}{\\sum (X_i-\\overline{X})^2}\\]\nLa distribución muestral de \\(b_1\\) hace referencia a los diferentes valores de \\(b_1\\) que serían obtenidos con un muestreo repetido cuando los niveles de la variable predictora \\(X\\) se mantiene constante entre las diferentes muestras. Para el modelo de regresión normal, la distribución muestral de \\(b_1\\) es normal con media y varianza dada por:\n\\[\\mathbb{E}(b_1)=\\beta_1\\qquad \\qquad\\mathbb{V}(b_1)=\\dfrac{\\sigma^2}{\\sum (X_i-\\overline{X})^2}\\]\nPara mostrar esto, debemos identificar que \\(b_1\\) es una combinación lineal de las observaciones \\(Y_i\\)."
  },
  {
    "objectID": "slides/lec_week4.html#b_1-como-combinación-lineal-de-y_i",
    "href": "slides/lec_week4.html#b_1-como-combinación-lineal-de-y_i",
    "title": "Regresión lineal",
    "section": "\\(b_1\\) como combinación lineal de \\(Y_i\\)",
    "text": "\\(b_1\\) como combinación lineal de \\(Y_i\\)\nSe puede mostrar que \\(b_1\\) puede ser reescrito como:\n\\[b_1=\\sum k_i Y_i\\]\ndonde,\n\\[k_i=\\dfrac{X_i-\\overline{X}}{\\sum (X_i-\\overline{X})^2}\\]\nNotamos que los \\(k_i\\) son funciones de \\(X_i\\) y por lo tanto son cantidades fijas, ya que los \\(X_i\\) son conocidos. Los coeficientes \\(k_i\\) tienen propiedades interesantes que usaremos más adelante: \\[\\begin{align*}\n\\sum k_i&=0 \\\\\n\\sum k_i X_i &= 1 \\\\\n\\sum k_{i}^{2}&=\\dfrac{1}{\\sum (X_i-\\overline{X})^2}\n\\end{align*}\\]\nLeer detalles de este cálculo página 42, Applied Lineal Statistical Models 5th Edition, Kutner et al."
  },
  {
    "objectID": "slides/lec_week4.html#normalidad-media-y-varianza",
    "href": "slides/lec_week4.html#normalidad-media-y-varianza",
    "title": "Regresión lineal",
    "section": "Normalidad, media y varianza",
    "text": "Normalidad, media y varianza\nDebido a que el término \\(b_1\\) es una combinación lineal de \\(Y_i\\), y este último son variables aleatoria normales independientes, sigue que \\(b_1\\) también lo es.\nLa insesgadez del estimador puntual de \\(b_1\\) es debido al teorema de Gauss-Markov, sigue que:\n\\[\\begin{align*}\n\\mathbb{E}(b_1)&=\\mathbb{E}\\left(\\sum k_i Y_i\\right)=\\sum k_i \\mathbb{E}(Y_i)= \\sum k_i(\\beta_0+\\beta_1 X_i)\\\\\n&= \\beta_0 \\sum k_i + \\beta_1 \\sum k_i X_i = \\beta_1\n\\end{align*}\\] En cuanto a la varianza de \\(b_1\\), sólo necesitamos recordar que \\(Y_i\\) son variables aleatorias independientes, cada una con varianza \\(\\sigma^2\\) y que \\(k_i\\) son constantes. Por lo que: \\[\\begin{align*}\n\\mathbb{V}(b_1)&=\\mathbb{V}\\left(\\sum k_i Y_i\\right)=\\sum k_{i}^{2} \\mathbb{V}(Y_i)\\\\\n&=\\sum k_{i}^{2} \\sigma^2=\\sigma^2 \\sum k_{i}^{2}\\\\\n&= \\dfrac{\\sigma^2}{\\sum (X_i -\\overline{X})^2}\n\\end{align*}\\]"
  },
  {
    "objectID": "slides/lec_week4.html#varianza-estimada",
    "href": "slides/lec_week4.html#varianza-estimada",
    "title": "Regresión lineal",
    "section": "Varianza estimada",
    "text": "Varianza estimada\nPodemos estimar la varianza de la distribución muestral de \\(b_1\\):\n\\[\\mathbb{V}(b_1)=\\dfrac{\\sigma^2}{\\sum (X_i - \\overline{X})^2}\\]\nReemplazando el parámetro \\(\\sigma^2\\) con el ECM, el estimador insesgado de \\(\\sigma^2\\):\n\\[\\widehat{\\mathbb{V}(b_1)}=\\dfrac{MSE}{\\sum (X_i - \\overline{X})^2}\\]\nEsta estimación puntual es un estimador insesgada de \\(\\mathbb{V}(b_1)\\). Tomando la raíz cuadrado podemos obtener la estimación puntual para la desviación estándar."
  },
  {
    "objectID": "slides/lec_week4.html#distribución-muestral-útil",
    "href": "slides/lec_week4.html#distribución-muestral-útil",
    "title": "Regresión lineal",
    "section": "Distribución muestral útil",
    "text": "Distribución muestral útil\nCon vistas en obtener intervalos de confianza para los parámetros de regresión, necesitamos obtener las distribuciones muestrales de cantidades pivotales, entre ellas la cantidad:\n\\[(b_1-\\beta_1)/\\sqrt{\\widehat{\\mathbb{V}(b_1)}}\\]\nDebido a que \\(b_1\\) está distribuido normalmente, sabemos que la estandarización:\n\\[\\dfrac{(b_1-\\beta_1)}{\\sqrt{\\mathbb{V}(b_1)}}\\]\nes una variable aleatoria normal estándar. En la práctica, no se tiene acceso a la varianza teórica por lo que esta cantidad debe ser estimada por \\(\\widehat{\\mathbb{V}(b_1)}\\) por que estamos particularmente interesados en la distribución de \\((b_1-\\beta_1)/\\sqrt{\\widehat{\\mathbb{V}(b_1)}}\\)"
  },
  {
    "objectID": "slides/lec_week4.html#distribución-muestral-útil-continuación",
    "href": "slides/lec_week4.html#distribución-muestral-útil-continuación",
    "title": "Regresión lineal",
    "section": "Distribución muestral útil: continuación",
    "text": "Distribución muestral útil: continuación\nCuando una estadístico está estandarizado pero el denominador es una estimación de la desviación estándar en vez de su valor real, se le llama estadístico estudentizado. Un teorema importante en estadística establece que el estadístico:\n\\[\\dfrac{(b_1-\\beta_1)}{\\sqrt{\\widehat{\\mathbb{V}(b_1)}}}\\sim t(n-2)\\]\nPara el modelo de regresión que estamos estudiando. Esto viene del hecho que \\(SSE/\\sigma^2 \\sim \\chi^2(n-2)\\) y es independiente de \\(b_0\\) y \\(b_1\\)."
  },
  {
    "objectID": "slides/lec_week4.html#intervalo-de-confianza-para-la-pendiente",
    "href": "slides/lec_week4.html#intervalo-de-confianza-para-la-pendiente",
    "title": "Regresión lineal",
    "section": "Intervalo de confianza para la pendiente",
    "text": "Intervalo de confianza para la pendiente\nDebido a que esta cantidad sigue una distribución t-student, podemos establecer que:\n\\[\\mathbb{P}(t(\\alpha/2,n-2)\\leq (b_1-\\beta_1)/\\sqrt{\\widehat{\\mathbb{V}(b_1)}} \\leq  t(1-\\alpha/2,n-2))=1-\\alpha\\]\nLuego, operando de igual manera que en la construcción de intervalos de confianza usual (vía pivote). Podemos llegar a un intervalo de confianza para \\(\\beta_1\\):\n\\[\\left[ b_1 \\pm t(1-\\alpha/2, n-2) \\sqrt{\\widehat{\\mathbb{V}(b_1)}}\\right]\\]"
  },
  {
    "objectID": "slides/lec_week4.html#test-de-hipótesis-para-la-pendiente",
    "href": "slides/lec_week4.html#test-de-hipótesis-para-la-pendiente",
    "title": "Regresión lineal",
    "section": "Test de hipótesis para la pendiente",
    "text": "Test de hipótesis para la pendiente\nDebido a que:\n\\[\\dfrac{(b_1-\\beta_1)}{\\sqrt{\\widehat{\\mathbb{V}(b_1)}}}\\sim t(n-2)\\]\nToda la teoría de test de hipótesis usuales es válida (tests unilaterales y bilaterales).\nTenemos particular interés en un test del tipo:\n\\[H_0: \\beta_1 = 0 \\hspace{20pt} H_1:\\beta_1 \\neq 0\\]\nPues con ello probamos si existe una asociación lineal entre las variables del modelo bajo un cierto nivel de confianza."
  },
  {
    "objectID": "slides/lec_week4.html#inferencia-sobre-el-intercepto",
    "href": "slides/lec_week4.html#inferencia-sobre-el-intercepto",
    "title": "Regresión lineal",
    "section": "Inferencia sobre el intercepto",
    "text": "Inferencia sobre el intercepto\nComo lo mencionamos antes, rara vez tendremos interés en hacer inferencia sobre el parámetro \\(\\beta_0\\), y estos son sólo válidos cuando el rango de la variable predictora incluye \\(X=0\\).\nComo hemos visto antes la estimación puntal del intercepto está dado por:\n\\[b_0=\\overline{Y}-b_1\\overline{X}\\]\nPara el modelo de regresión en estudio, la distribución muestral de \\(b_0\\) es normal, con media y varianza:\n\\[\\mathbb{E}(b_0)=\\beta_0\\qquad \\qquad \\mathbb{V}(b_0)=\\sigma^2\\left[ \\dfrac{1}{n}+\\dfrac{\\overline{X}^2}{\\sum (X_i-\\overline{X})^2}\\right]\\]\nLa normalidad es obtenida debido a que \\(b_0\\) al igual que \\(b_1\\), es una combinación lineal de observaciones \\(Y_i\\). Al igual que antes, una estimador de la varianza viene dado al reemplazar \\(\\sigma^2\\) por su estimación puntual (ECM). El estimador de la desviación estándar es obtenido aplicando raíz cuadrada."
  },
  {
    "objectID": "slides/lec_week4.html#intervalo-de-confianza-para-el-intercepto",
    "href": "slides/lec_week4.html#intervalo-de-confianza-para-el-intercepto",
    "title": "Regresión lineal",
    "section": "Intervalo de confianza para el intercepto",
    "text": "Intervalo de confianza para el intercepto\nAl igual que antes, se tiene que:\n\\[\\dfrac{b_0-\\beta_0}{\\sqrt{\\widehat{\\mathbb{V}(b_0)}}}\\sim t(n-2)\\]\npara este modelo de regresión. Así, los intervalos de confianza pueden ser construidos al igual que para \\(\\beta_1\\). Esto es:\n\\[\\left[ b_0 \\pm t(1-\\alpha/2, n-1)\\sqrt{\\widehat{\\mathbb{V}(b_0)}}\\right]\\]"
  },
  {
    "objectID": "slides/lec_week4.html#análisis-de-varianza-para-análisis-de-regresión",
    "href": "slides/lec_week4.html#análisis-de-varianza-para-análisis-de-regresión",
    "title": "Regresión lineal",
    "section": "Análisis de Varianza para análisis de regresión",
    "text": "Análisis de Varianza para análisis de regresión\nCon lo anterior, ya hemos visto gran parte de la teoría de un modelo de regresión básico. En lo que sigue, estudiaremos el análisis de regresión desde la perspectiva de análisis de varianza.\nNociones básicas: El enfoque desde el análisis de varianza se base en particionar la suma de cuadrado y grados de libertad asociados con la variable respuesta \\(Y\\). Identificaremos 3 términos que usaremos frecuentemente:\n\nSuma de cuadrados total (SSTO): \\(\\sum (Y_i - \\overline{Y})^2\\)\nSuma de los cuadrados del error (SSE): \\(\\sum (Y_i - \\hat{Y}_i)^2\\)\nSuma de los cuadrados de la regresión (SSR): \\(\\sum (\\hat{Y}_i-\\overline{Y})^2\\)\n\n\nen donde se tiene la relación:\n\\[SSTO=SSE+SSR\\]"
  },
  {
    "objectID": "slides/lec_week4.html#desglose-de-los-grados-de-libertad",
    "href": "slides/lec_week4.html#desglose-de-los-grados-de-libertad",
    "title": "Regresión lineal",
    "section": "Desglose de los grados de libertad",
    "text": "Desglose de los grados de libertad\nAl igual que para la varianza, podemos desglosar los grados de libertad. Es claro ver que:\n\nSSTO tiene asociado \\(n-1\\) grados de libertad, debido a que estimamos la media poblacional.\nSSE tiene asociado \\(n-2\\) grados de libertad, debido a que para obtener \\(\\hat{Y}_i\\) debemos estimar \\(\\beta_0\\) y \\(\\beta_1\\)\nSSR tiene asociado \\(1\\) grado de libertad debido a que los valores ajustados son calculados a partir de la recta de regresión, por lo que \\(2\\) grados de libertad están a asociado a esta, pero uno de ello es perdido debido a la estimación \\(\\overline{Y}\\).\n\n\nAsí, se tiene que:\n\\[n-1=1+(n-2)\\]"
  },
  {
    "objectID": "slides/lec_week4.html#cuadrados-medios",
    "href": "slides/lec_week4.html#cuadrados-medios",
    "title": "Regresión lineal",
    "section": "Cuadrados medios",
    "text": "Cuadrados medios\nLlamamos cuadrados medios a las sumas cuadradas divididas por sus grados de libertad respectivos. Por lo que tenemos:\n\nError cuadrático medio: \\(\\dfrac{SSE}{n-2}\\)\nCuadrado medio de regresión: \\(\\dfrac{SSR}{1}\\)\n\n\nEn este caso, los cuadrados medios no son aditivos"
  },
  {
    "objectID": "slides/lec_week4.html#tabla-anova",
    "href": "slides/lec_week4.html#tabla-anova",
    "title": "Regresión lineal",
    "section": "Tabla ANOVA",
    "text": "Tabla ANOVA\nLo que hemos visto anteriormente, puede ser resumido en la tabla ANOVA usual, en donde se incorporó además la esperanza de los cuadrados medios.\n\n\n\n\n\n\n\n\n\n\nF.V.\nSS\ng.l.\nMS\n\\(\\mathbf{\\mathbb{E}(MS)}\\)\n\n\n\n\nRegresión\n\\(SSR = \\sum (\\hat{Y}_i-\\overline{Y})^2\\)\n\\(1\\)\n\\(MSR=SSR\\)\n\\(\\sigma^2+\\beta_{1}^{2}\\sum (X_i-\\overline{X})^2\\)\n\n\nError\n\\(SSE = \\sum (Y_i - \\hat{Y}_i)^2\\)\n\\(n-2\\)\n\\(MSE=\\dfrac{SSE}{n-2}\\)\n\\(\\sigma^2\\)\n\n\nTotal\n\\(SSTO=\\sum (Y_i - \\overline{Y})^2\\)\n\\(n-1\\)"
  },
  {
    "objectID": "slides/lec_week4.html#test-f",
    "href": "slides/lec_week4.html#test-f",
    "title": "Regresión lineal",
    "section": "Test F",
    "text": "Test F\nEl enfoque de análisis de varianza nos permite realizar fácilmente test para modelos de regresión (y otros modelos lineales). Por ejemplo, consideremos:\n\\[H_0: \\beta_1 = 0 \\hspace{20pt} H_1:\\beta_1 \\neq 0\\]\nEstadístico de prueba\nBajo este enfoque consideramos el estadístico \\(F^*\\), definido como:\n\\[F^*=\\dfrac{MSR}{MSE}\\]\nDistribución muestral de \\(F^*\\)\nEs posible mostrar que bajo \\(H_0\\), \\(F^*\\) sigue una distribución \\(F(1,n-2)\\)"
  },
  {
    "objectID": "slides/lec_week4.html#introducción",
    "href": "slides/lec_week4.html#introducción",
    "title": "Regresión lineal",
    "section": "Introducción",
    "text": "Introducción\nCon lo anterior, ya hemos visto gran parte de la teoría de un modelo de regresión básico. En lo que sigue, estudiaremos el análisis de regresión desde la perspectiva de análisis de varianza.\nNociones básicas: El enfoque desde el análisis de varianza se base en particionar la suma de cuadrado y grados de libertad asociados con la variable respuesta \\(Y\\). Identificaremos 3 términos que usaremos frecuentemente:\n\nSuma de cuadrados total (SSTO): \\(\\sum (Y_i - \\overline{Y})^2\\)\nSuma de los cuadrados del error (SSE): \\(\\sum (Y_i - \\hat{Y}_i)^2\\)\nSuma de los cuadrados de la regresión (SSR): \\(\\sum (\\hat{Y}_i-\\overline{Y})^2\\)\n\n\nen donde se tiene la relación:\n\\[SSTO=SSE+SSR\\]"
  },
  {
    "objectID": "slides/lec_week4.html#test-f-continuación",
    "href": "slides/lec_week4.html#test-f-continuación",
    "title": "Regresión lineal",
    "section": "Test F: continuación",
    "text": "Test F: continuación\nRegla de decisión\nDebido a que \\(F^*\\) sigue una distribución \\(F(1,n-2)\\) bajo \\(H_0\\), la regla de decisión será:\n\nSi \\(F^* \\leq F(1-\\alpha; 1,n-2)\\), optamos por \\(H_0\\)\nSi \\(F^* > F(1-\\alpha; 1,n-2)\\), optamos por \\(H_1\\)"
  },
  {
    "objectID": "slides/lec_week4.html#coeficiente-de-determinación",
    "href": "slides/lec_week4.html#coeficiente-de-determinación",
    "title": "Regresión lineal",
    "section": "Coeficiente de determinación",
    "text": "Coeficiente de determinación\nEl coeficiente de determinación lo definimos como:\n\\[R^2=\\dfrac{SSR}{SSTO}=1-\\dfrac{SSE}{SSTO}\\]\ny lo interpretamos como la proporción de la variabilidad que es explicada por el ajuste de regresión lineal.\nEste coeficiente se mueve entre 0 y 1, siendo 1 un ajuste perfecto. Un buen ajuste de regresión suele estar entre 0.7 - 0.9, pero esto puede variar dependiendo del contexto del problema."
  },
  {
    "objectID": "slides/lec_week4.html#limitaciones-del-coeficiente-de-determinación",
    "href": "slides/lec_week4.html#limitaciones-del-coeficiente-de-determinación",
    "title": "Regresión lineal",
    "section": "Limitaciones del coeficiente de determinación",
    "text": "Limitaciones del coeficiente de determinación\n\nUn coeficiente de determinación alto no indica que se puedan hacer predicciones buenas\nUn coeficiente de determinación alto no indica que el ajuste es necesariamente bueno\nUn coeficiente de determinación cercano a cero no indica que \\(X\\) e \\(Y\\) no estén relacionados."
  },
  {
    "objectID": "slides/lec_week4.html#coeficiente-de-correlación",
    "href": "slides/lec_week4.html#coeficiente-de-correlación",
    "title": "Regresión lineal",
    "section": "Coeficiente de correlación",
    "text": "Coeficiente de correlación\nEste coeficiente puede ser definido como la raíz del coeficiente de determinación.\n\\[r=\\pm \\sqrt{R^2}\\]\ny lo interpretamos como el coeficiente de correlación de Pearson."
  },
  {
    "objectID": "slides/lec_week4.html#aplicación-computacional",
    "href": "slides/lec_week4.html#aplicación-computacional",
    "title": "Regresión lineal",
    "section": "Aplicación computacional",
    "text": "Aplicación computacional\n\nrequire(tidyverse)\nrequire(MASS)\nrequire(car)\nrequire(mosaic)\nset.seed(163)\ndata(UScereal)\nplot<-ggplot(UScereal,aes(x=fibre,y=calories)) + geom_point() +\n  geom_smooth(method=lm,se=FALSE,color=\"red\")"
  },
  {
    "objectID": "slides/lec_week4.html#aplicación-computacional-continuación",
    "href": "slides/lec_week4.html#aplicación-computacional-continuación",
    "title": "Regresión lineal",
    "section": "Aplicación computacional: continuación",
    "text": "Aplicación computacional: continuación\n\nmodel <- lm(calories~fibre,data=UScereal)\nsummary(model)\n\n\nCall:\nlm(formula = calories ~ fibre, data = UScereal)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-144.73  -28.07  -17.48   15.51  258.48 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  134.117      8.522  15.738   <2e-16 ***\nfibre          3.950      1.181   3.344   0.0014 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 57.97 on 63 degrees of freedom\nMultiple R-squared:  0.1507,    Adjusted R-squared:  0.1372 \nF-statistic: 11.18 on 1 and 63 DF,  p-value: 0.001396"
  },
  {
    "objectID": "slides/lec_week4.html#aplicación-computacional-continuación-1",
    "href": "slides/lec_week4.html#aplicación-computacional-continuación-1",
    "title": "Regresión lineal",
    "section": "Aplicación computacional: continuación",
    "text": "Aplicación computacional: continuación\n\nconfint(model)\n\n                 2.5 %    97.5 %\n(Intercept) 117.087793 151.14595\nfibre         1.589422   6.31138\n\nanova(model)\n\nAnalysis of Variance Table\n\nResponse: calories\n          Df Sum Sq Mean Sq F value   Pr(>F)   \nfibre      1  37572   37572   11.18 0.001396 **\nResiduals 63 211723    3361                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "slides/lec_week4.html#diagnóstico",
    "href": "slides/lec_week4.html#diagnóstico",
    "title": "Regresión lineal",
    "section": "Diagnóstico",
    "text": "Diagnóstico\nCuando realizamos un modelo de regresión, como por ejemplo el modelo de regresión lineal simple antes visto, frecuentemente no podemos estar seguros por adelantado si el modelo es apropiado para aplicación que se le desea dar. Muchas de las características del modelo, tales como la linealidad de la función de regresión o normalidad de los errores podría no ser apropiada, por lo que toma relevancia saber si el modelo puede ser aplicado.\nEn lo que sigue estudiaremos métodos gráficos y test formales, para saber si un modelo es apropiado usarlo. Nos concentramos en el modelo de regresión lineal simple, pero los mismos principios son válidos para todos los modelos estadísticos que veremos."
  },
  {
    "objectID": "slides/lec_week4.html#diagnóstico-para-las-variables-predictoras",
    "href": "slides/lec_week4.html#diagnóstico-para-las-variables-predictoras",
    "title": "Regresión lineal",
    "section": "Diagnóstico para las variables predictoras",
    "text": "Diagnóstico para las variables predictoras\nPrimero debemos analizar las variables predictora para detectar la presencia de datos anómalos o outliers, que puedan influenciar la viabilidad del modelo.\n\nLa presencia de outliers, puede provocar residuos grandes en magnitud, influenciando enormemente el ajuste de regresión."
  },
  {
    "objectID": "slides/lec_week4.html#diagnóstico-para-residuos",
    "href": "slides/lec_week4.html#diagnóstico-para-residuos",
    "title": "Regresión lineal",
    "section": "Diagnóstico para residuos",
    "text": "Diagnóstico para residuos\nEn general, los gráficos de diagnósticos utilizando directamente la variable respuesta \\(Y\\) no son muy útiles en el análisis de regresión debido a que el valor de las observaciones en la variable respuesta son una función del nivel de la variable predictora. Por lo que usualmente, se analizan indirectamente mediante la inspección de los residuos.\nLos residuos \\(e_i\\) son la diferencia entre el valor observado \\(Y_i\\) y el valor ajustado \\(\\hat{Y}_i\\):\n\\[e_i=Y_i-\\hat{Y}_i\\]\nEstos pueden ser considerados como el error observado, a diferencia de valor real del error \\(\\varepsilon_i\\) en el modelo de regresión:\n\\[\\varepsilon_i=Y_i - \\mathbb{E}(Y_i)\\]\nPara el modelo de regresión lineal simple, los errores \\(\\varepsilon_i\\) se asumen variables aleatorias normales independientes, con media 0 y varianza constante \\(\\sigma^2\\). Si el modelo es apropiado para los datos disponibles, el residuo observado \\(e_i\\) deben reflejar las propiedades que se asumieron para \\(\\varepsilon_i\\).\nEsta es la idea básica del análisis de residuos, una herramienta útil para evaluar la viabilidades de los modelos."
  },
  {
    "objectID": "slides/lec_week4.html#propiedades-de-los-residuos-media",
    "href": "slides/lec_week4.html#propiedades-de-los-residuos-media",
    "title": "Regresión lineal",
    "section": "Propiedades de los residuos: media",
    "text": "Propiedades de los residuos: media\nLa media de los \\(n\\) residuos \\(e_i\\) para el modelo de regresión lineal simple es:\n\\[\\overline{e}=\\dfrac{\\sum e_i}{n}=0\\]\ndonde \\(\\overline{e}\\) denota la media de los residuos. Así, debido a que \\(\\overline{e}\\) es siempre 0, este no provee información sobre si los errores reales \\(\\varepsilon_i\\) tienen valor esperado \\(\\mathbb{E}(\\varepsilon_i)=0\\)."
  },
  {
    "objectID": "slides/lec_week4.html#propiedades-de-los-residuos-varianza",
    "href": "slides/lec_week4.html#propiedades-de-los-residuos-varianza",
    "title": "Regresión lineal",
    "section": "Propiedades de los residuos: varianza",
    "text": "Propiedades de los residuos: varianza\nLa varianza de los \\(n\\) residuos \\(e_i\\) está definida como:\n\\[s^2=\\dfrac{\\sum (e_i - \\overline{e})^2}{n-2}=\\dfrac{\\sum e_{i}^{2}}{n-2}=\\dfrac{SSE}{n-2}=MSE\\]\nSi el modelo es apropiado, el error cuadrático medio es un estimador insesgado de la varianza del error \\(\\sigma^2\\)."
  },
  {
    "objectID": "slides/lec_week4.html#propiedades-de-los-residuos-no-independencia",
    "href": "slides/lec_week4.html#propiedades-de-los-residuos-no-independencia",
    "title": "Regresión lineal",
    "section": "Propiedades de los residuos: no independencia",
    "text": "Propiedades de los residuos: no independencia\nLos residuos \\(e_i\\) no son variables aleatorias independientes debido a que involucran los valores ajustados \\(\\hat{Y}_i\\), los cuales están basado en la misma función de regresión ajustada. Como resultado de lo anterior, los residuos para el modelo de regresión están sujetos a dos restricciones:\n\nLa suma de \\(e_i\\) debe ser 0\nla suma de \\(X_i e_i\\) debe ser 0\n\n\nCuando el tamaño de muestra es grande en comparación con el número de parámetros en el modelo de regresión, la efecto de dependencia entre los residuos \\(e_i\\) no tiene mayor importancia y puede ser ignorado."
  },
  {
    "objectID": "slides/lec_week4.html#propiedades-de-los-residuos-residuos-semi-studentizados",
    "href": "slides/lec_week4.html#propiedades-de-los-residuos-residuos-semi-studentizados",
    "title": "Regresión lineal",
    "section": "Propiedades de los residuos: residuos semi-studentizados",
    "text": "Propiedades de los residuos: residuos semi-studentizados\nFrecuentemente, sirve estandarizar los residuos para realizar el análisis. debido a que la desviación estándar de los términos de error \\(\\varepsilon_i\\) es \\(\\sigma\\), el cual puede ser estimado mediante \\(\\sqrt{MSE}\\), por lo que es natural considerar la estandarización:\n\\[e_{i}^{*}=\\dfrac{e_i-\\overline{e}}{\\sqrt{MSE}}=\\dfrac{e_i}{\\sqrt{MSE}}\\]\nSi \\(\\sqrt{MSE}\\) fuese una estimación de la desviación estándar de los residuos \\(e_i\\), llamaríamos \\(e_{i}^{*}\\) residuos studentizados. Sin embargo, la desviación estándar de \\(e_i\\) es compleja y varía para los diferentes residuos \\(e_i\\), y \\(\\sqrt{MSE}\\) es sólo una aproximación de la desviación estándar de \\(e_i\\).\nPor lo que llamamos el estadístico \\(e_{i}^{*}\\) un residuo semi-studentizado. Estos tipo de residuos nos sirven para identificar la presencia de datos anómalos."
  },
  {
    "objectID": "slides/lec_week4.html#diferencias-con-el-modelo-estudiado",
    "href": "slides/lec_week4.html#diferencias-con-el-modelo-estudiado",
    "title": "Regresión lineal",
    "section": "Diferencias con el modelo estudiado",
    "text": "Diferencias con el modelo estudiado\nUsualmente, estaremos en busca de 6 formas en la cuales un modelo de regresión lineal simple con errores normales no es adecuado.\n\nLa función de regresión no es lineal\nLos errores no tienen varianza constante\nLos errores no son independientes\nEl modelo ajusta todas las observaciones exceptuando algunas\nLos errores no se distribuyen de manera normal\nUnas o varias variables predictoras fueron omitidas del modelo"
  },
  {
    "objectID": "slides/lec_week4.html#diagnóstico-de-los-residuos",
    "href": "slides/lec_week4.html#diagnóstico-de-los-residuos",
    "title": "Regresión lineal",
    "section": "Diagnóstico de los residuos",
    "text": "Diagnóstico de los residuos\nUtilizaremos varios gráficos para identificar si ocurre alguna de las 6 situaciones antes planteadas. Los siguientes gráficos son usualmente usados para este fin\n\nGráficos de los residuos vs la variable predictora\nGráfico del valor absoluto o el cuadrado de los residuos vs la variable predictora\nGráfico de los residuos vs valores ajustados\nGráfico de los residuos vs tiempo u otra secuencia\nGráfico de los residuos vs variables predictoras omitidas\nBox-Plot de los residuos\nGráfico de probabilidad normal de los residuos"
  },
  {
    "objectID": "slides/lec_week4.html#test-relacionados-con-los-residuos",
    "href": "slides/lec_week4.html#test-relacionados-con-los-residuos",
    "title": "Regresión lineal",
    "section": "Test relacionados con los residuos",
    "text": "Test relacionados con los residuos\nEl análisis de residuos mediante gráficos es inherentemente subjetivo. Aún así, este análisis subjetivo de una variedad de gráficos de residuos frecuentemente revela dificultades en la implementación del modelo más claramente que un test formal.\n\nTest de aleatoriedad: Durbin-Watson Test\nTest para la consistencia de varianza: Brown-Forsythe test y Breusch-Pagan test\nTest de normalidad: Test Chi-cuadrado, Kolmogorov-Smirnov, Lilliefors test."
  },
  {
    "objectID": "slides/lec_week4.html#medidas-correctivas",
    "href": "slides/lec_week4.html#medidas-correctivas",
    "title": "Regresión lineal",
    "section": "Medidas correctivas",
    "text": "Medidas correctivas\nSi el modelo de regresión lineal simple no es apropiado para el conjunto de datos que se está analizando, se tienen dos opciones:\n\nAbandonar el modelo de regresión lineal simple y desarrollar otro modelo\nAplicar alguna transformación a los datos tal que el modelo de regresión lineal simple sea apropiado para los datos transformados."
  },
  {
    "objectID": "slides/lec_week4.html#modelo-de-regresión-lineal-general-forma-equivalente",
    "href": "slides/lec_week4.html#modelo-de-regresión-lineal-general-forma-equivalente",
    "title": "Regresión lineal",
    "section": "Modelo de regresión lineal general: forma equivalente",
    "text": "Modelo de regresión lineal general: forma equivalente\nSi consideramos \\(X_{i0}=1\\), el modelo de regresión anterior puede reescrito como:\n\\[Y_i=\\beta_0 X_{i0}+\\beta_1 X_{i1}+\\beta_2 X_{i2} + \\cdots + \\beta_{p-1}X_{i,p-1}+\\varepsilon_i\\]\npor lo que,\n\\[Y_i=\\sum_{k=0}^{p-1} \\beta_k X_{ik}+\\varepsilon_i\\]\nLa respuesta media para este modelo de regresión está dado por:\n\\[\\mathbb{E}(Y)=\\beta_0+\\beta_1 X_1 + \\beta_2 X_2 + \\cdots+\\beta_{p-1} X_{p-1}\\]\ndebido a que \\(\\mathbb{E}(\\varepsilon_i)=0\\)\nAsí, el modelo de regresión lineal general con errores normales implica que las observaciones \\(Y_i\\) son variables aleatorias normales, con media \\(\\mathbb{E}(Y_i)\\) dado por la expresión anterior y con varianza constante \\(\\sigma^2\\)."
  },
  {
    "objectID": "slides/lec_week4.html#variables-predictoras-cualitativas",
    "href": "slides/lec_week4.html#variables-predictoras-cualitativas",
    "title": "Regresión lineal",
    "section": "Variables predictoras cualitativas",
    "text": "Variables predictoras cualitativas\nEl modelo de regresión lineal general abarca no sólo variables predictoras cuantitativas, sino también variables cualitativas. Estas se conocen como variables indicadoras que toman los valores 0 y 1 para identificar las clases de la variable cualitativa.\nEjemplo\nConsideramos el siguiente análisis de regresión para predecir el largo de la estadía en un hospital \\((Y)\\) basado en la edad \\((X_1)\\) y género \\((X_2)\\) del paciente. Definimos \\(X_2\\) como:\n\\[X_2=\\begin{cases}1 \\hspace{20pt} \\text{si el paciente es mujer}\\\\  0 \\hspace{20pt} \\text{si el paciente es hombre}\\end{cases}\\]\nEl modelo de regresión lineal de primer order estará dado por:\n\\[Y_i=\\beta_0+\\beta_1 X_{i1} + \\beta_2 X_{i2}+\\varepsilon_i\\]\ndonde:\n\\[\\begin{align*}\nX_{i1}&= \\text{ Edad del paciente}\\\\\nX_{i2}&=\\begin{cases}1 \\hspace{20pt} \\text{si el paciente es mujer}\\\\  0 \\hspace{20pt} \\text{si el paciente es hombre}\\end{cases}\n\\end{align*}\\]"
  },
  {
    "objectID": "slides/lec_week4.html#ejemplo-1",
    "href": "slides/lec_week4.html#ejemplo-1",
    "title": "Regresión lineal",
    "section": "Ejemplo",
    "text": "Ejemplo\nEn este caso, la función de respuesta estará dada por:\n\\[\\mathbb{E}(Y)=\\beta_0+\\beta_1 X_1 +\\beta_2 X_2\\]\nPara los pacientes hombres, \\(X_2=0\\) y la respuesta media será:\n\\[\\mathbb{E}(Y)=\\beta_0+\\beta_1 X_1\\]\nY para los pacientes mujeres, \\(X_2=1\\) y la respuesta media será:\n\\[\\mathbb{E}(Y)=(\\beta_0+\\beta_2)+\\beta_1 X_1\\]\n\nEn general, representamos una variable cualitativa con \\(c\\) clases mediante \\(c-1\\) variables indicadoras."
  },
  {
    "objectID": "slides/lec_week4.html#ejemplo-continuación",
    "href": "slides/lec_week4.html#ejemplo-continuación",
    "title": "Regresión lineal",
    "section": "Ejemplo: continuación",
    "text": "Ejemplo: continuación\nPor ejemplo, si en el ejemplo anterior se agrega una variable cualitativa que representa el estado de discapacidad. Podemos agregar dos variable indicadoras \\(X_3\\) y \\(X_4\\) como:\n\\[X_3=\\begin{cases}1 \\hspace{20pt} \\text{si el paciente no es discapacitado}\\\\  0 \\hspace{20pt} \\text{en otro caso}\\end{cases}\\]\ny,\n\\[X_4=\\begin{cases}1 \\hspace{20pt} \\text{si el paciente es discapacitado}\\\\  0 \\hspace{20pt} \\text{en otro caso}\\end{cases}\\]\nAsí, el modelo quedaría como:\n\\[Y_i=\\beta_0+\\beta_1 X_{i1} + \\beta_2 X_{i2}+ \\beta_3 X_{i3} + \\beta_4 X_{i4} + \\varepsilon_i\\]\ndonde las variables predictoras están definidas como antes."
  },
  {
    "objectID": "slides/lec_week4.html#regresión-polinómica",
    "href": "slides/lec_week4.html#regresión-polinómica",
    "title": "Regresión lineal",
    "section": "Regresión polinómica",
    "text": "Regresión polinómica\nLas regresiones polinómicas son casos especiales del modelo de regresión lineal general. Estos contienen términos cuadrados o de grados mayores de las variables predictoras, provocando que la función de respuesta sea curvilínea. Un ejemplo de una regresión polinómica sería:\n\\[Y_i=\\beta_0 + \\beta_1 X_i + \\beta_2 X_{i}^{2}+\\varepsilon_i\\]"
  },
  {
    "objectID": "slides/lec_week4.html#variables-transformadas",
    "href": "slides/lec_week4.html#variables-transformadas",
    "title": "Regresión lineal",
    "section": "Variables transformadas",
    "text": "Variables transformadas\nLos modelos con variables transformadas involucran funciones respuesta complejas y curvilíneas, aún así son casos especiales de un modelo de regresión lineal general.\nConsideremos el siguiente modelo:\n\\[\\log Y_i = \\beta_0 + \\beta_1 X_{i1} +\\beta_2 X_{i2}+\\beta_3 X_{i3} +\\varepsilon_i\\]\nAcá, la superficie de respuesta (desde el punto de vista geométrico) es compleja, aún así puede ser tratada como un modelo de regresión lineal general. Si consideramos \\(Y_{i}^{'}=\\log Y_i\\), podemos reescribir el modelo de regresión anterior como:\n\\[Y_{i}^{'}=\\beta_0 + \\beta_1 X_{i1} +\\beta_2 X_{i2}+\\beta_3 X_{i3} +\\varepsilon_i\\]\nEl cual tiene la forma del modelo general. La variable respuesta es el logaritmo de \\(Y\\)."
  },
  {
    "objectID": "slides/lec_week4.html#variables-transformadas-continuación",
    "href": "slides/lec_week4.html#variables-transformadas-continuación",
    "title": "Regresión lineal",
    "section": "Variables transformadas: continuación",
    "text": "Variables transformadas: continuación\nMuchos modelos pueden ser transformados al modelo de regresión lineal general, por ejemplo el modelo:\n\\[Y_i=\\dfrac{1}{\\beta_0 + \\beta_1 X_{i1} +\\beta_2 X_{i2}+\\varepsilon_i}\\]\nPuede ser transformado al modelo de regresión lineal general al considerar \\(Y_{i}^{'}=1/Y_i\\). Así, se puede reescribir como:\n\\[Y_{i}^{'}=\\beta_0 + \\beta_1 X_{i1} +\\beta_2 X_{i2}+\\varepsilon_i\\]"
  },
  {
    "objectID": "slides/lec_week4.html#efectos-de-interacción",
    "href": "slides/lec_week4.html#efectos-de-interacción",
    "title": "Regresión lineal",
    "section": "Efectos de interacción",
    "text": "Efectos de interacción\nCuando los efectos de la variables predictoras en la variable respuesta no son aditivos, el efecto de un predictor depende del nivel en otra variable predictora. El modelo de regresión lineal general abarca modelos con efectos no aditivos o que interactúan entre sí. Un ejemplo de un modelo de regresión lineal no aditivo con dos variables predictoras \\(X_1\\) y \\(X_2\\) es:\n\\[Y_i=\\beta_0 + \\beta_1 X_{i1}+\\beta_2 X_{i2} + \\beta_3 X_{i1} X_{2i} +\\varepsilon_i\\]\nAcá, la función de respuesta es compleja debido a la término de interacción \\(\\beta_3 X_{i1} X_{2i}\\). Aún así, el modelo anterior, es un caso especial de un modelo de regresión lineal general. Sea \\(X_{i3}=X_{i1}X_{i2}\\), podemos reescribir el modelos anterior como:\n\\[Y_i=\\beta_0 + \\beta_1 X_{i1}+\\beta_2 X_{i2} + \\beta_3 X_{i3} +\\varepsilon_i\\]\nEn el cual es claro ver que tiene la forma general buscada."
  },
  {
    "objectID": "slides/lec_week4.html#combinación-de-casos",
    "href": "slides/lec_week4.html#combinación-de-casos",
    "title": "Regresión lineal",
    "section": "Combinación de casos",
    "text": "Combinación de casos\nUn modelo de regresión puede combinar muchos de los elementos que hemos mencionado, y aún así ser tratado como un modelo de regresión lineal general. Consideremos el siguiente modelo de regresión que contiene términos lineal y cuadráticos para cada una de las variables predictoras, y un término de interacción.\n\\[Y_i=\\beta_0 + \\beta_1 X_{i1}+\\beta_{2}X_{i1}^{2} + \\beta_3 X_{i2} + \\beta_4 X_{i2}^{2}+\\beta_5 X_{i1}X_{i2}+\\varepsilon_i\\]\nSi definimos,\n\\[Z_{i1}=X_{i1} \\hspace{15pt} Z_{i2}=X_{i1}^{2} \\hspace{15pt} Z_{i3}=X_{i2} \\hspace{15pt} Z_{i4}=X_{i2}^{2} \\hspace{15pt} Z_{i5}=X_{i1}X_{i2}\\]\nPodemos representar el modelo como:\n\\[Y_i=\\beta_0 + \\beta_1 Z_{i1}+\\beta_2 Z_{i2}+\\beta_3 Z_{i3} + \\beta_4 Z_{i4} + \\beta_5 Z_{i5} +\\varepsilon\\]"
  },
  {
    "objectID": "slides/lec_week4.html#interpretación",
    "href": "slides/lec_week4.html#interpretación",
    "title": "Regresión lineal",
    "section": "Interpretación",
    "text": "Interpretación\nDebe estar claro, por lo ejemplos, que el modelo de regresión lineal general no está restringido a una respuesta lineal. El término modelo lineal hace referencia al hecho que el modelo en estudio es lineal en los parámetros; no hace referencia a la forma de la superficie de respuesta.\nDecimos que un modelo de regresión es lineal en los parámetros cuando puede ser escrito de la forma:\n\\[Y_i=c_{i0}\\beta_0 + c_{i1}\\beta_1 + c_{i2}\\beta_2 + \\dots + c_{i,p-1}\\beta_{p-1} +\\varepsilon_i\\]\ndonde los términos \\(c_{i0},c_{i1},\\)etc, son coeficientes que acompañan a las variables predictoras. Un ejemplo de un modelo de regresión lineal no lineal sería:\n\\[Y_i=\\beta_0 \\exp (\\beta_1 X_i) + \\varepsilon\\]\nEste último modelo no puede ser expresado en la forma de un modelo de regresión lineal."
  },
  {
    "objectID": "slides/lec_week4.html#bibliografía-recomendada-para-modelos-lineales",
    "href": "slides/lec_week4.html#bibliografía-recomendada-para-modelos-lineales",
    "title": "Regresión lineal",
    "section": "Bibliografía recomendada para modelos lineales",
    "text": "Bibliografía recomendada para modelos lineales\nPara profundizar en la teoría de modelos lineales (y sus aplicaciones) se recomienda el libro: Applied lineal statistical models. Kutner Michael H., Nachtsheim Christopher J. , Neter John ,Li William. 5th Edition, 2004."
  },
  {
    "objectID": "pages/week5.html",
    "href": "pages/week5.html",
    "title": "Semana 5",
    "section": "",
    "text": "Guía ejemplo - Certamen #1\nBase de datos: Advertising\nGuía Certamen #1\nBase de datos: Marketing\nBase de datos: Real Estate"
  },
  {
    "objectID": "documents/G1/IND163C_2022_02_G1.html",
    "href": "documents/G1/IND163C_2022_02_G1.html",
    "title": "Ejemplo resulto - Certamen #1",
    "section": "",
    "text": "Pregunta tipo prueba\nPublicidad El conjunto de datos Advertising consiste en las ventas (sales) en miles de unidades de un producto en 200 mercados diferentes, junto con los presupuestos en dólares de publicidad en cada uno de estos mercados para tres medios diferentes: televisión (TV), radio y periódicos (newspaper).\n\nRealice un análisis exploratorio del conjunto de datos Advertising.\n\n\nlibrary(tidyverse) \nlibrary(modelr)\nlibrary(broom)\nlibrary(readr)\nAdvertising <- read_csv(\"Advertising.csv\") %>% select(-X1)\n\n⊕Cargamos algunos paquetes que serán útiles para el análisis, luego leémos el conjunto de datos y descartamos la primera columna (por ser una columna que no nos entrega información). Adicionalmente, imprimimos parte de los datos para verificar que están siendo correctamente ingresados.\n\nhead(Advertising)\n\n# A tibble: 6 x 4\n     TV radio newspaper sales\n  <dbl> <dbl>     <dbl> <dbl>\n1 230.   37.8      69.2  22.1\n2  44.5  39.3      45.1  10.4\n3  17.2  45.9      69.3   9.3\n4 152.   41.3      58.5  18.5\n5 181.   10.8      58.4  12.9\n6   8.7  48.9      75     7.2\n\n\nPara realizar el análisis exploratorio de datos (EDA por sus siglas en inglés), existen varias formas de abarcar el problema. Una manera sencilla aunque sólo preliminar para realizar un EDA sistemático a un conjunto de datos, es usar el paquete DataExplorer\n\nlibrary(DataExplorer)\nplot_intro(Advertising)\n\n\n\n\nExploración del tipo de variables y datos faltantes\n\n\n\n\nLa función plot_intro() nos entrega el tipo de variables en las columnas y el porcentaje de datos faltantes. Alternativamente, se puede obtener la misma información en formato de tabla usando introduce().\nEn el caso que existan datos faltantes a lo largo del conjunto de datos en distintas variables, es posible obtener el detalle del porcentaje de estos utilizando la función plot_missing(). El paquete DataExplorer entrega además sugerencias sobre la calidad de las variables conforme el nivel de datos faltantes presentes, sin embargo, la eliminación de columnas debe ser estudiada cuidadosamente y siempre dependerá del contexto del problema.\nEn el caso de que existan datos discretos, es posible visualizar la distribución de frecuencias para todas estas variables utilizando la función plot_bar(). De manera similar, es posible obtener los histogramas para las variables continuas utilizando la función plot_histogram():\n\nplot_histogram(Advertising)\n\n\n\n\nHistograma para las variables continuas\n\n\n\nplot_density(Advertising)\n\n\n\n\nHistograma para las variables continuas\n\n\n\n\nLa primera función nos entrega los histogramas hechos sistemáticamente usando el paquete ggplot2, mientras que el segundo realiza una estimación de densidad por kernel, que vendría siendo algo así como una versión suavizada del histograma. Esta técnica tomará relevancia más adelante en el curso.\nPara comparar visualmente la distribución de las variables en estudio con distribuciones teóricas conocidas, es posible utilizar QQ-plot mediante la función plot_qq().\n\nplot_qq(Advertising)\n\n\n\n\nQQ plot de las variables\n\n\n\n\nPor defecto, el comando plot_qq() compara con una distribución normal, por lo que es una buena herramienta visual para el análisis de residuos bajo un modelo lineal. Adicionalmente, es posible agrupar las variables continuas graficadas por factores o variables categóricas mediante el argumento plot_qq(... , by=\"\").\nPara realizar un análisis correlacional de las variables en estudio, es posible utilizar la función plot_correlation()\n\nplot_correlation(Advertising)\n\n\n\n\nAnálisis correlacional\n\n\n\n\nPara realizar un análisis de componentes principales (que veremos más adelante en detalle) se puede utilizar la función plot_prcomp(). Omitiremos estos gráficos por el momento.\n⊕Hay que ser particularmente cuidadoso en la interpretación de este análisis, pues se debe tener claro que tipo de correlación se está calculando (y graficando). Este comando utiliza la función cor(). Es posible, realizar este análisis para los dos tipos de variables: discretos y continuos. Se recomienda tratar los datos faltantes antes de realizar este proceso.\nComo recordarán de cursos anteriores, uno de los mejores gráficos disponibles es el boxplot que puede ser calculado fácilmente utilizando la función plot_boxplot(..., by=\"\") si deseamos agrupar por alguna variable categórica. Para ver cada uno de manera univariada usamos la siguiente función.\n\np <- ggplot(Advertising, aes(TV)) + geom_boxplot()\np \n\n\n\n\n⊕Este tipo de gráficos toma más relevancia cuando podemos analizar una misma variable agrupada por una categórica, como veremos más adelante.\nTambién es posible obtener los gráficos de dispersión de cada una de las variables en estudio mediante la función plot_scatterplot(... ,by=\"\") agrupada por una variable categórica.\nFinalmente, cabe mencionar que los estadísticos descriptivos (media, varianza, cuartiles, etc) también son parte del EDA. Todo el proceso anterior puede ser en su totalidad automatizado con el comando create_report(), este creo un archivo .html con las funciones que puede hacer con el conjunto de datos, sin embargo, hay que tomar atención a lo que hace en cada uno de los pasos pues es sólo un proceso sistematizado con parámetros por defecto. Se recomienda realizar cada paso por separado.\nEn este ejemplo introductorio, al no tener datos faltantes y categóricos, el EDA es bastante sencillo y se reduce a la creación de gráficos básicos y estadística descriptiva.\n\nRealice un ajuste lineal simple para las ventas (sales) medidas en miles de unidades vs cada uno de los tres medios utilizados. Explicite los ajustes realizados.\n\n\np1<- ggplot(data = Advertising, mapping = aes(x = TV, y = sales)) + \n  geom_point() + geom_smooth(method = \"lm\", se = FALSE)\np2<- ggplot(data = Advertising, mapping = aes(x = radio, y = sales)) + \n  geom_point() + geom_smooth(method = \"lm\", se = FALSE)\np3<- ggplot(data = Advertising, mapping = aes(x = newspaper, y = sales)) + \n  geom_point() + geom_smooth(method = \"lm\", se = FALSE)\n\nLa creación de gráficos utilizando ggplot2 funciona de manera modular, primero se establece el conjunto de datos a utilizar, y se especifica que variables serán los ejes (ggplot()). Luego, se grafican los puntos (geom_point()) y finalmente la recta geom_smooth(), respectivamente.\n\nlibrary(gridExtra)\ngrid.arrange(p1, p2, p3, nrow = 1)\n\n\n\n\nAjuste lineal simple para las ventas en función de los tres medios utilizados\n\n\n\n\nLos modelos de regresión ajustados tienen la forma:\n\\[Y=\\beta_0+\\beta_1 X +\\epsilon\\]\ndonde:\n\n\\(Y\\) representa las ventas en miles de unidades\n\\(X\\) representa el presupuesto en cada uno de los medios, respectivamente.\n\\(\\beta_0\\) es el intercepto\n\\(\\beta_1\\) es la pendiente, que representa la relación lineal\n\\(\\epsilon\\) es el término de error aleatorio con media cero.\n\nPara analizar el detalle de nuestro ajusto lineal, guardamos los modelos lineales en tres objetivos distintos:\n⊕El comando lm viene de linear models y existen versiones más generales y específicas dentro de R\n\nmodelo_1<-lm(sales ~ TV, data=Advertising)\nmodelo_2<-lm(sales ~ radio, data=Advertising)\nmodelo_3<-lm(sales ~ newspaper, data=Advertising)\n\nLa función lm() utiliza por defecto el método de mínimos cuadrados para estimar los coeficientes de regresión, pero es posible definir otras metodologías utilizando la función glm().\nLos ajustos especificos obtenidos (con sus estimaciones de los parámetros) los podemos obtener simplemente haciendo un summary() a los modelos calculados.\n\n# Sales vs TV \nsummary(modelo_1)\n\n\nCall:\nlm(formula = sales ~ TV, data = Advertising)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-8.3860 -1.9545 -0.1913  2.0671  7.2124 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 7.032594   0.457843   15.36   <2e-16 ***\nTV          0.047537   0.002691   17.67   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.259 on 198 degrees of freedom\nMultiple R-squared:  0.6119,    Adjusted R-squared:  0.6099 \nF-statistic: 312.1 on 1 and 198 DF,  p-value: < 2.2e-16\n\n# Sales vs radio\nsummary(modelo_2)\n\n\nCall:\nlm(formula = sales ~ radio, data = Advertising)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-15.7305  -2.1324   0.7707   2.7775   8.1810 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  9.31164    0.56290  16.542   <2e-16 ***\nradio        0.20250    0.02041   9.921   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.275 on 198 degrees of freedom\nMultiple R-squared:  0.332, Adjusted R-squared:  0.3287 \nF-statistic: 98.42 on 1 and 198 DF,  p-value: < 2.2e-16\n\n# Sales vs newspaper\nsummary(modelo_3)\n\n\nCall:\nlm(formula = sales ~ newspaper, data = Advertising)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-11.2272  -3.3873  -0.8392   3.5059  12.7751 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 12.35141    0.62142   19.88  < 2e-16 ***\nnewspaper    0.05469    0.01658    3.30  0.00115 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.092 on 198 degrees of freedom\nMultiple R-squared:  0.05212,   Adjusted R-squared:  0.04733 \nF-statistic: 10.89 on 1 and 198 DF,  p-value: 0.001148\n\n\n\n¿Qué modelo ajustado es mejor? Comente e interprete los resultados de este modelo.\n\nEs claro notar que el modelo que mejor se ajusta es el primero, las ventas (sales) vs TV, lo cual era esperable desde la figura exploratoria. El modelo ajustado corresponde a:\n\\[Y=7.032594+0.047537 X + \\epsilon\\]\nEn otras palabras, nuestra estimación del intercepto es 7.032594, por lo que cuando el presupuesto para el medio televisivo es cero, esperaremos ventas de 7032 unidades, y por cada $1000 dólares adicionales en el presupuesto esperaremos un incremento promedio en las ventas de 47 unidades. Además, es claro notar que ambos coeficientes son** estadísticamente significativos**, y podemos calcular sus intervalos de confianza como:\n\nconfint(modelo_1)\n\n                 2.5 %     97.5 %\n(Intercept) 6.12971927 7.93546783\nTV          0.04223072 0.05284256\n\n\nDebido a que el cero no está incluido en el intervalo de confianza para el coeficiente de pendiente, podemos concluir que por cada $1000 dólares adicionales de presupuesto en el medio televisivo, esperaremos un incremento promedio en las ventas entre 42 y 52 unidades.\nPara justificar en detalle, podemos el R^2 del modelo_1 es el mayor entre los realizados, y podemos realizar una tabla anova para verificar que mediante el test F, los coeficientes no son nulos:\n\nanova(modelo_1)\n\nAnalysis of Variance Table\n\nResponse: sales\n           Df Sum Sq Mean Sq F value    Pr(>F)    \nTV          1 3314.6  3314.6  312.14 < 2.2e-16 ***\nResiduals 198 2102.5    10.6                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nPor lo que, de ser viable nuestro modelo realizado, esto es, que cumpla con los supuestos de una regresión lineal, sería el modelo más adecuado entre los realizados. Para ello, primero visualizamos -nuevamente-:\n\nggplot(Advertising, aes(TV, sales)) +\n  geom_point() +\n  geom_smooth(method = \"lm\") +\n  geom_smooth(se = FALSE, color = \"red\")\n\n\n\n\nAjuste lineal simple para ventas vs TV\n\n\n\n\nPara ver el análisis de residuos, es posible utilizar el comando plot(modelo_1) el cual entregará 4 gráficos en formato básico. En lo que sigue, los creamos uno por uno utilizando el paquete ggplot2.\n\nggplot(modelo_1, aes(.fitted, .resid)) +\n  geom_ref_line(h = 0) +\n  geom_point() +\n  geom_smooth(se = FALSE) +\n  ggtitle(\"Residuos vs Ajuste\")\n\n\n\n\nGráfico de residuos vs ajuste\n\n\n\n\nUna forma de visualizar más claramente los residuos, es estandarizándolos y reescalándolos, respectivamente.\n\nmodelo_1_res <- augment(modelo_1, Advertising)\np4 <- ggplot(modelo_1_res, aes(.fitted, .std.resid)) +\n  geom_ref_line(h = 0) +\n  geom_point() +\n  geom_smooth(se = FALSE) +\n  ggtitle(\"Residuos Estadarizados vs Ajuste\")\n\np5 <- ggplot(modelo_1_res, aes(.fitted, sqrt(.std.resid))) +\n  geom_ref_line(h = 0) +\n  geom_point() +\n  geom_smooth(se = FALSE) +\n  ggtitle(\"Reescalamiento\")\n\ngridExtra::grid.arrange(p4, p5, nrow = 1)\n\n\n\n\nGráfico de residuos estandarizados y reescalados vs ajuste\n\n\n\n\nEn el primer gráfico podemos identificar fácilmente cuando un residuo se desvía por varias desviaciones estándar, en donde usualmente estamos en busca de los residuos que difieren por más de 3 desviaciones estándar. El segundo gráfico muestra si los residuos están dispersos equitativamente a lo largo del rango de los predictores. Luego, como hemos asumido normalidad en los errores, debemos realizar un QQ plot\n\nqq_plot <- qqnorm(modelo_1_res$.resid)\nqq_plot <- qqline(modelo_1_res$.resid)\n\n\n\n\nQQ plot de los residuos\n\n\n\n\nComo lo cuantiles esperados se asemejan a los teóricos, podemos asumir normalidad.\nSiguiendo, si deseamos encontrar datos u observaciones anómales podemos calculos las distancias de cook de las observaciones y graficar los apalancamientos.\n\npar(mfrow=c(1, 2))\n\nplot(modelo_1, which = 4, id.n = 5)\nplot(modelo_1, which = 5, id.n = 5)\n\n\n\n\nDistancias de Cook y apalancamientos\n\n\n\n\nEn el gráfico anterior, buscamos las observaciones que tienen mayor distancia de cook, y estas serán sospechosas de ser outliers, siendo esta sospecha reforzada si su apalancamiento está muy a la derecha en el gráfico respectivo. Para extraer las n observaciones con mayor distancia de cook, podemos escribir:\n\nmodelo_1_res %>%\n  top_n(3, wt = .cooksd)\n\n# A tibble: 3 x 10\n     TV radio newspaper sales .fitted .resid   .hat .sigma .cooksd .std.resid\n  <dbl> <dbl>     <dbl> <dbl>   <dbl>  <dbl>  <dbl>  <dbl>   <dbl>      <dbl>\n1  263.   3.5      19.5  12      19.5  -7.53 0.0142   3.22  0.0389      -2.33\n2  291.   4.1       8.5  12.8    20.9  -8.05 0.0191   3.22  0.0605      -2.49\n3  277.   2.3      23.7  11.8    20.2  -8.39 0.0165   3.21  0.0563      -2.59\n\n\nConforme lo anterior, se cumplen todos los supuestos del modelo de regresión lineal simple, por lo que la regresión ajustada es la mejor entre las realizadas.\n\nAjustar mediante un ajuste de regresión múltiple las ventas en miles de unidades (sales), sin incorporar interacciones. Interprete los resultados.\n\nDe manera similar, podemos realizar un ajuste de regresión múltiple utilizando los presupuestos en los distintos medios de manera conjunta:\n\nmodelo_4<-lm(sales ~ TV + radio + newspaper, data= Advertising)\nsummary(modelo_4)\n\n\nCall:\nlm(formula = sales ~ TV + radio + newspaper, data = Advertising)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-8.8277 -0.8908  0.2418  1.1893  2.8292 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  2.938889   0.311908   9.422   <2e-16 ***\nTV           0.045765   0.001395  32.809   <2e-16 ***\nradio        0.188530   0.008611  21.893   <2e-16 ***\nnewspaper   -0.001037   0.005871  -0.177     0.86    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.686 on 196 degrees of freedom\nMultiple R-squared:  0.8972,    Adjusted R-squared:  0.8956 \nF-statistic: 570.3 on 3 and 196 DF,  p-value: < 2.2e-16\n\n\nLa interpretación de los coeficientes de regresión es similar a caso de la regresión simple. Primero, notamos que los coeficientes asociados a los presupuestos en televisión y radio son significativos bajo un test de hipótesis t (p-valor \\(< 0.05\\)), mientras que el coeficiente asociado al presupuesto en periódicos no lo es. Por lo que, bajo un modelo de regresión múltiple, cambios en el presupuesto en periódicos no pareciera tener una relación con los cambios en las ventas. Sin embargo, en el caso del presupuesto televisivo, si este aumenta en $1000 dólares y se mantienen los otros predictores constantes, esperaríamos un incremento de 45 unidades en las ventas, en promedio. Análogamente, para un aumento de igual monto en el presupuesto radial, se esperaría un aumento de 188 unidades en promedio.\n\nInvestigue la viabilidad del modelo de regresión múltiple y compare los resultados con el mejor modelo de regresión lineal simple. Obtenga intervalos de confianza para los parámetros de la regresión.\n\nDe manera similar al caso de regresión lineal simple, podemos calcular intervalos de confianza para los parámetros de regresión como:\n\nconfint(modelo_4)\n\n                  2.5 %     97.5 %\n(Intercept)  2.32376228 3.55401646\nTV           0.04301371 0.04851558\nradio        0.17154745 0.20551259\nnewspaper   -0.01261595 0.01054097\n\n\nLuego, podemos hacemos un análisis de residuos:\n\nmodelo_1_res <- modelo_1_res %>%\n  mutate(Model = \"Modelo de regresión lineal simple\")\n\nmodelo_4_res <- augment(modelo_4, Advertising) %>%\n  mutate(Model = \"Modelo de regresión lineal múltiple\") %>%\n  rbind(modelo_1_res)\n\nggplot(modelo_4_res, aes(.fitted, .resid)) +\n  geom_ref_line(h = 0) +\n  geom_point() +\n  geom_smooth(se = FALSE) +\n  facet_wrap(~ Model) +\n  ggtitle(\"Residuos vs Ajuste\")\n\n\n\n\nDistancias de Cook y apalancamientos\n\n\n\n\nComo vemos, la variabilidad de los residuos pareciera ser más constante en el modelo de regresión lineal simple, por lo que sugiere que los supuestos sobre la varianza se cumple. Comparamos los QQ-plot:\n\npar(mfrow=c(1, 2))\n\n# Izquierda: Modelo de regresión lineal simple\nqqnorm(modelo_1_res$.resid); qqline(modelo_1_res$.resid)\n\n# Derecha: Modelo de regresión lineal múltiple\nqqnorm(modelo_4_res$.resid); qqline(modelo_4_res$.resid)\n\n\n\n\nDistancias de Cook y apalancamientos\n\n\n\n\nSin embargo, en el caso de los supuestos distribucionales, lo contrario pareciera suceder. El modelo de regresión lineal múltiple pareciera tener colas de distribución más pesadas que una distribución normal, por lo que el supuesto de normalidad de los errores podría no estar cumpliéndose.\nLuego, podemos comparar las medidas de desempeño de ambos modelos de la forma:\n⊕El paquete stargazer es útil para exportar los resultados de modelos estadísticos de manera tabulada a LaTeX y otros formatos.\n\nlibrary(stargazer)\nstargazer(modelo_1,modelo_4, type=\"latex\", header = FALSE)\n\nComo vemos, el modelo de regresión múltiple aumenta considerablemente nuestros \\(R^2\\) y \\(R^2\\) ajustado, de 0.612 a 0.897 y 0.61 a 0.896, sugiriendo que el modelo de regresión múltiple es más adecuado para modelar la venta de productos. Adicionalmente, nuestro estadístico F es mayor en el caso múltiple, sugiriendo un mayor ajuste de curva. ⊕Estos criterios los veremos detalladamente más adelante en el curso Complementariamente, es posible calcular los medidas de AIC (criterio de información de Akaike) y BIC (criterio de información Bayesiano), en las que el modelo de regresión múltiple también supera al modelo de regresión simple, al tener menor valor en estos indicadores.\n\n¿Cómo se podría justificar -dentro del contexto del problema- una incorporación de interacción en el modelo de regresión múltiple? Proponga una modelo de regresión múltiple con interacción adecuado, analice y compare con los modelos anteriores.\n\nEs claro que en el modelo de regresión múltiple, los incrementos en las ventas se han interpretado manteniendo los otros presupuestos constantes, y que además, estos son independientes. Sin embargo, esto podría ser erróneo, pues es posible que aumentando el presupuesto de publicidad en radio, se aumente la efectividad de la publicidad en televisión, por lo que el coeficiente asociado a la variable TV se verá aumentado conforme la variable radio aumenta. Bajo este escenario, es posible que al tener un monto fijo de presupuesto, repartirlo en ambos medios (tv y radio) sea más efectivo que simplemente asignarlo a publicidad televisiva (como el modelo de regresión múltiple sin interacción sugiere). Así, una segunda iteración del modelo propuesto sería incorporar una interacción entre los dos medios de publicidad mencionados y además, descartar el medio de publicidad en periódicos pues este no fue significativo anteriormente.\n\nmodelo_5<-lm(sales~ TV + radio + TV * radio, data= Advertising)\nsummary(modelo_5)\n\n\nCall:\nlm(formula = sales ~ TV + radio + TV * radio, data = Advertising)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-6.3366 -0.4028  0.1831  0.5948  1.5246 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 6.750e+00  2.479e-01  27.233   <2e-16 ***\nTV          1.910e-02  1.504e-03  12.699   <2e-16 ***\nradio       2.886e-02  8.905e-03   3.241   0.0014 ** \nTV:radio    1.086e-03  5.242e-05  20.727   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.9435 on 196 degrees of freedom\nMultiple R-squared:  0.9678,    Adjusted R-squared:  0.9673 \nF-statistic:  1963 on 3 and 196 DF,  p-value: < 2.2e-16\n\n\n⊕Alternativamente, se puede escribir solo TV * radio, y R interpretará el modelo de la misma manera\nNotamos que todos nuestros coeficientes, incluida la interacción son estadísticamente significativos. Por lo que, tras un aumento de $1000 dólares en el presupuesto de televisión esperaremos, en promedio, un\n\\[(\\beta_1+ \\beta_3 \\times radio) \\times 1000 = 19 + 1\\times radio\\]\ny análogamente, ante un equitativo en el presupuesto de radio, se esperará:\n\\[(\\beta_2+ \\beta_3 \\times TV) \\times 1000 = 28 + 1\\times radio\\]\nLuego, comparamos nuestro nuevo modelo con los dos modelos anterior:\n\nlibrary(stargazer)\nstargazer(modelo_1,modelo_4, modelo_5, type=\"latex\", header = FALSE)\n\nEs claro notar que la incorporación de la interacción en nuestro modelo de regresión múltiple mejoró aún más nuestro ajuste de curva, bajo la perspectiva de los mismos indicadores utilizas para comparar los primeros dos modelos. Finalmente, realizamos un análisis de residuos comparando los modelos realizados:\n\nmodelo_5_res <- augment(modelo_5, Advertising) %>%\n  mutate(Model = \"Model de regresión lineal múltiple con interacción\") %>%\n  rbind(modelo_4_res)\n\nggplot(modelo_5_res, aes(.fitted, .resid)) +\n  geom_ref_line(h = 0) +\n  geom_point() +\n  geom_smooth(se = FALSE) +\n  facet_wrap(~ Model) +\n  ggtitle(\"Residuos vs Ajuste\")\n\n\n\n\nDistancias de Cook y apalancamientos\n\n\n\n\nEl modelo con interacción provee una varianza constante que los otros dos modelos, sin embargo, parecieran haber datos anómalos. Un manera alternativa de analizar visualmente la distribución de los residuos, es utilizando histogramas apropiadamente (en vez de QQ-plot):\n\nggplot(modelo_5_res, aes(.resid)) +\n  geom_histogram(binwidth = .25) +\n  facet_wrap(~ Model, scales = \"free_x\") +\n  ggtitle(\"Histograma de residuos\")\n\n\n\n\nDistancias de Cook y apalancamientos\n\n\n\n\nEs posible que si analizamos para distintas magnitudes de ventas veamos mayor grado de normalidad en los residuos, digamos que si ventas sales mayores a 10, obtenemos:\n\nmodelo_5_res %>%\n  filter(sales > 10) %>%\n  ggplot(aes(.resid)) +\n  geom_histogram(binwidth = .25) +\n  facet_wrap(~ Model, scales = \"free_x\") +\n  ggtitle(\"Histograma de residuos\")\n\n\n\n\nDistancias de Cook y apalancamientos\n\n\n\n\nEs claro ver la normalidad en el modelo de regresión lineal con interacción es bastante viable. En cuanto a las observaciones anómalas, las diagnosticamos como:\n\npar(mfrow=c(1, 2))\n\nplot(modelo_5, which = 4, id.n = 5)\nplot(modelo_5, which = 5, id.n = 5)\n\n\n\n\nDistancias de Cook y apalancamientos\n\n\n\n\nEn el gráfico de la distancia de Cook, se ve claramente que las observaciones 6, 9, 109, 131 y 156 parecieran ser outliers. Por lo que vemos estas observaciones.\n⊕La coma final, ordena a R que nos entregue todas las columnas.\n\nAdvertising[c(6,9,109,131,156),]\n\n# A tibble: 5 x 4\n     TV radio newspaper sales\n  <dbl> <dbl>     <dbl> <dbl>\n1   8.7  48.9      75     7.2\n2   8.6   2.1       1     4.8\n3  13.1   0.4      25.6   5.3\n4   0.7  39.6       8.7   1.6\n5   4.1  11.6       5.7   3.2\n\n\nNotamos que en todas estas observaciones se tienen pocas ventas, lo que reafirma que nuestro modelo no se desempeña bien para niveles bajos de ventas."
  },
  {
    "objectID": "slides/lec_week6.html#ejemplo",
    "href": "slides/lec_week6.html#ejemplo",
    "title": "Introducción a machine learning",
    "section": "Ejemplo",
    "text": "Ejemplo\nTomemos como ejemplo el reconocer dígitos escritos a mano."
  },
  {
    "objectID": "slides/lec_week6.html#ejemplo-continuación",
    "href": "slides/lec_week6.html#ejemplo-continuación",
    "title": "Introducción a machine learning",
    "section": "Ejemplo: continuación",
    "text": "Ejemplo: continuación\nEstos dígitos corresponden a imágenes de 28x28 pixeles, por lo que pueden ser representados en un vector \\(\\mathbf{x}\\) que contiene 784 números reales.\nEl objetivo es construir una máquina que tome el vector \\(\\mathbf{x}\\) como entrada y produzca la identidad del dígito \\(0,\\dots,9\\) como salida.\nEste problema es claramente no-trivial debido a la gran variedad de escrituras. Podría abordarse utilizando reglas heurísticas para distinguir los dígitos en función de las formas de los trazos, pero en la práctica, tal enfoque conduce a una proliferación de reglas y de excepciones a las reglas, etc., e invariablemente da malos resultados."
  },
  {
    "objectID": "slides/lec_week6.html#introducción-continuación",
    "href": "slides/lec_week6.html#introducción-continuación",
    "title": "Introducción a machine learning",
    "section": "Introducción: continuación",
    "text": "Introducción: continuación\nMejores resultados pueden ser obtenidos adoptando un enfoque de machine learning, en donde un conjunto grande de datos de \\(N\\) dígitos \\(\\{x_1 ,\\ldots, x_n\\}\\) llamados conjunto de entrenamiento (training set) se utiliza para ajustar los parámetros de un modelo adaptativo.\nLas categorías de los dígitos en el conjunto de entrenamiento se conocen de antemano, normalmente inspeccionándolos individualmente y etiquetándolos a mano.\nPodemos expresar la categoría de un dígito usando un vector objetivo (target vector) \\(\\mathbf{t}\\), que representa la identidad del dígito correspondiente. Notar que hay un vector objetivo \\(\\mathbf{t}\\) para cada dígito de la imagen \\(\\mathbf{x}\\)."
  },
  {
    "objectID": "slides/lec_week6.html#introducción-continuación-1",
    "href": "slides/lec_week6.html#introducción-continuación-1",
    "title": "Introducción a machine learning",
    "section": "Introducción: continuación",
    "text": "Introducción: continuación\nEl resultado tras aplicar el algoritmo de machine learning puede ser expresado como una función \\(\\mathbf{y}(\\mathbf{x})\\), que toma una nueva imagen del dígito \\(\\mathbf{x}\\) como entrada y que genera como salida un vector \\(\\mathbf{y}\\), codificada de la misma manera que los vector objetivos.\nLa forma exacta de la función \\(\\mathbf{y}(\\mathbf{x})\\) es determinada durante la fase de entrenamiento, también conocida como la fase de aprendizaje, en base al conjunto de entrenamiento.\nUna vez que el modelo es entrenado, este puede ser usado para identificar nuevas imágenes de dígitos, que les llamamos conjunto de prueba (test set).\nLa habilidad de categorizar correctamente nuevos ejemplos que difieren de los utilizados en la fase de aprendizaje es conocido como generalización."
  },
  {
    "objectID": "slides/lec_week6.html#introducción-continuación-2",
    "href": "slides/lec_week6.html#introducción-continuación-2",
    "title": "Introducción a machine learning",
    "section": "Introducción: continuación",
    "text": "Introducción: continuación\nEn la mayoría de las aplicaciones reales, las variables de entrada son típicamente preprocesadas para transformarlas a un nuevo espacio de variables donde, se espera que la problemática de reconocer patrones sea más fácil de resolver.\nPor ejemplo, en el reconocimiento de dígitos escritos a mano, las imágenes de los dígitos generalmente se transforman y escalan tal que cada dígito esté contenido dentro de un cuadro de tamaño fijo. Esto reduce en gran medida la variabilidad dentro de cada clase de dígito, debido a que la localización y la escala de todos los dígitos serán las mismas, por lo que la identificación de patrones se facilitará.\nLa etapa de de pre-procesamiento es usualmente conocida como extracción de características (feature extraction).\nNotar que los nuevos datos, incluidos en el conjunto de entrenamiento, deben ser preprocesados de igual manera que los del conjunto de entrenamiento."
  },
  {
    "objectID": "slides/lec_week6.html#introducción-continuación-5",
    "href": "slides/lec_week6.html#introducción-continuación-5",
    "title": "Introducción a machine learning",
    "section": "Introducción: continuación",
    "text": "Introducción: continuación\nOtra técnica utilizada en machine learning es el aprendizaje reforzado (reinforcement learning), que se ocupa del problema de encontrar acciones adecuadas para tomar en una situación específica con el fin de maximizar una recompensa.\nEn este caso, el algoritmo de aprendizaje no recibe ejemplos de resultados óptimos (como se tienen en el aprendizaje supervisado), sino que debe descubrirlos mediante un proceso de prueba y error."
  },
  {
    "objectID": "slides/lec_week6.html#introducción-continuación-4",
    "href": "slides/lec_week6.html#introducción-continuación-4",
    "title": "Introducción a machine learning",
    "section": "Introducción: continuación",
    "text": "Introducción: continuación\nLas aplicaciones en donde la entrada son los datos de entrenamiento (training set) sin sus correspondientes vectores objetivos son conocidas como problemas de aprendizaje no supervisado (unsupervised learning problems). Varios pueden ser los objetivos en este tipo de problemas:\n\nDescubrir grupos de elementos similares dentro de los datos, en este caso le llamamos agrupamiento (clustering)\nEstimar la distribución de los datos dentro del espacio de los datos, a esto le llamamos estimación de densidad\nProyectar los datos desde un espacio multidimensional a uno de 2 o 3 dimensiones, para así poder visualizarlo, a esto le llamamos visualización."
  },
  {
    "objectID": "slides/lec_week6.html#introducción-continuación-3",
    "href": "slides/lec_week6.html#introducción-continuación-3",
    "title": "Introducción a machine learning",
    "section": "Introducción: continuación",
    "text": "Introducción: continuación\nLa etapa de preprocesamiento también puede ser utilizada para acelerar el cálculo del algoritmo utilizado. Se debe tener especial cuidado en esta etapa debido a que usualmente, cierta información es descartada, y si esta es importante para la solución del problema, la precisión general del sistema confeccionado puede verse afectada.\nLas aplicaciones en donde la entrada son los datos de entrenamiento (training set) en conjunto con sus correspondientes vectores objetivo son conocidas como problemas de aprendizaje supervisado (supervised learning problems).\nLos casos en donde el objetivo es asignar a cada vector de entrada una categoría, se conocen como problemas de clasificación.\nSi se desean salidas que consisten en una o más variables continuas, entonces le llamamos regresión."
  },
  {
    "objectID": "slides/lec_week6.html#ejemplo-1",
    "href": "slides/lec_week6.html#ejemplo-1",
    "title": "Introducción a machine learning",
    "section": "Ejemplo",
    "text": "Ejemplo\nSe desea mejorar las ventas de un producto en particular. El siguiente conjunto de datos contiene datos de las ventas de aquel producto en 200 mercados diferentes, junto con el presupuesto de publicidad para el producto en cada uno de los mercados para 3 medios de publicidad: TV, radio y diario.\n\n\n  X    TV Radio Newspaper Sales\n1 1 230.1  37.8      69.2  22.1\n2 2  44.5  39.3      45.1  10.4\n3 3  17.2  45.9      69.3   9.3\n4 4 151.5  41.3      58.5  18.5\n5 5 180.8  10.8      58.4  12.9\n6 6   8.7  48.9      75.0   7.2"
  },
  {
    "objectID": "slides/lec_week6.html#ejemplo-continuación-1",
    "href": "slides/lec_week6.html#ejemplo-continuación-1",
    "title": "Introducción a machine learning",
    "section": "Ejemplo: continuación",
    "text": "Ejemplo: continuación"
  },
  {
    "objectID": "slides/lec_week6.html#ejemplo-continuación-2",
    "href": "slides/lec_week6.html#ejemplo-continuación-2",
    "title": "Introducción a machine learning",
    "section": "Ejemplo: continuación",
    "text": "Ejemplo: continuación"
  },
  {
    "objectID": "slides/lec_week6.html#ejemplo-continuación-3",
    "href": "slides/lec_week6.html#ejemplo-continuación-3",
    "title": "Introducción a machine learning",
    "section": "Ejemplo: continuación",
    "text": "Ejemplo: continuación\nEn este ejemplo, los presupuestos son las variables de entrada (input) mientras que las ventas es la variable de salida (output). Usualmente denotaremos a las variables de entrada por la letra \\(X\\), así \\(X_1\\) es el presupuesto en televisión, \\(X_2\\) en Radio y \\(X_3\\) en periódicos.\nEstas variables de entregada también se le conocen como predictores, variables independientes, features o simplemente variables.\nLa variable respuesta Sales es usualmente llamada respuesta o variable dependiente, y se denota por la letra \\(Y\\)."
  },
  {
    "objectID": "slides/lec_week6.html#ejemplo-continuación-4",
    "href": "slides/lec_week6.html#ejemplo-continuación-4",
    "title": "Introducción a machine learning",
    "section": "Ejemplo: continuación",
    "text": "Ejemplo: continuación\nEn general, supongamos que observamos una variable respuesta cuantitativa \\(Y\\) y \\(p\\) diferentes predictores \\(X_1,\\dots,X_p\\). Asumiremos que existe algún tipo de relación entre \\(Y\\) y \\(X=(X_1,X_2,\\dots,X_p)\\) que puede ser escrito de forma general como\n\\[Y=f(X)+\\varepsilon\\]\nDonde \\(f\\) es una función fija de \\(X_1,\\dots,X_p\\) y \\(\\varepsilon\\) es un error aleatorio, que es independiente de \\(X\\) y tiene media cero. En lo anterior, \\(f\\) representa la información sistemática que \\(X\\) provee sobre \\(Y\\)."
  },
  {
    "objectID": "slides/lec_week6.html#aprendizaje-estadístico-1",
    "href": "slides/lec_week6.html#aprendizaje-estadístico-1",
    "title": "Regresión lineal",
    "section": "Aprendizaje estadístico",
    "text": "Aprendizaje estadístico\nEl aprendizaje estadístico refiere al conjunto de herramientas y enfoques para estimar \\(f\\).\n¿Para qué estimar \\(f\\)?\nPredicción\nEn muchas situaciones, un conjunto de variables de entrada \\(X\\) son fácilmente obtenibles, pero las salidas \\(Y\\) tienen difícil acceso. Bajo esta configuración, debido a que el promedio de los errores tiene media cero, podemos predecir \\(Y\\) usando:\n\\[\n\\hat{Y}=\\hat{f}(X)\n\\]\ndonde \\(\\hat{f}\\) representa nuestra estimación para \\(f\\) e \\(\\hat{Y}\\) representa la predicción obtenida para \\(Y\\). En este contexto, \\(\\hat{f}\\) es usualmente tratada como una caja negra, en el sentido que no estamos usualmente preocupados con la forma exacta de \\(\\hat{f}\\), si es que esta entrega predicciones precisas de \\(Y\\)."
  },
  {
    "objectID": "slides/lec_week6.html#predicción",
    "href": "slides/lec_week6.html#predicción",
    "title": "Introducción a machine learning",
    "section": "Predicción",
    "text": "Predicción\nEn muchas situaciones, un conjunto de variables de entrada \\(X\\) son fácilmente obtenibles, pero las salidas \\(Y\\) tienen difícil acceso. Bajo esta configuración, debido a que el promedio de los errores tiene media cero, podemos predecir \\(Y\\) usando:\n\\[\n\\hat{Y}=\\hat{f}(X)\n\\]\ndonde \\(\\hat{f}\\) representa nuestra estimación para \\(f\\) e \\(\\hat{Y}\\) representa la predicción obtenida para \\(Y\\). En este contexto, \\(\\hat{f}\\) es usualmente tratada como una caja negra, en el sentido que no estamos usualmente preocupados con la forma exacta de \\(\\hat{f}\\), si es que esta entrega predicciones precisas de \\(Y\\)."
  },
  {
    "objectID": "slides/lec_week6.html#ejemplo-2",
    "href": "slides/lec_week6.html#ejemplo-2",
    "title": "Introducción a machine learning",
    "section": "Ejemplo",
    "text": "Ejemplo\n\nlibrary(plot3D)\nlibrary(tidyverse)\nIncome2<- read.csv(\"./db/Income2.csv\")\n# Ajuste\nfit_2_3_loess <- loess(Income ~ Education + Seniority, data = Income2) \n# Predicción de valores\nx.pred <- seq(min(Income2$Education), max(Income2$Education), length.out = 30)\ny.pred <- seq(min(Income2$Seniority), max(Income2$Seniority), length.out = 30)\nxy     <- expand.grid(Education = x.pred, Seniority = y.pred)\nz.pred <- matrix(predict(fit_2_3_loess, newdata = xy), nrow = 30, ncol = 30)"
  },
  {
    "objectID": "slides/lec_week6.html#ejemplo-continuación-5",
    "href": "slides/lec_week6.html#ejemplo-continuación-5",
    "title": "Introducción a machine learning",
    "section": "Ejemplo: continuación",
    "text": "Ejemplo: continuación\n\nIncome2 %>% \n  scatter3D(\n    type = \"p\",\n    x = Income2$Education, \n    y = Income2$Seniority, \n    z = Income2$Income,\n    colvar = NA, pch = 19, col = \"gold\", cex = 1.75,\n    phi = 25, theta = 45, expand = 0.6,\n    xlab = \"Years of Education\", ylab = \"Seniority\", zlab = \"Income\",\n    panel.first = scatter3D(x = Income2$Education,y = Income2$Seniority,\n    z = Income2$Income,colvar = NA, col = \"black\", add = T,\n    surf = list(x = x.pred, y = y.pred, z = z.pred, \n    fit = predict(fit_2_3_loess), facets = T, col = \"skyblue\",\n    border = \"royalblue\", alpha = 0.45)))"
  },
  {
    "objectID": "slides/lec_week6.html#ejemplo-continuación-6",
    "href": "slides/lec_week6.html#ejemplo-continuación-6",
    "title": "Introducción a machine learning",
    "section": "Ejemplo: continuación",
    "text": "Ejemplo: continuación"
  },
  {
    "objectID": "slides/lec_week6.html#ejemplo-continuación-7",
    "href": "slides/lec_week6.html#ejemplo-continuación-7",
    "title": "Introducción a machine learning",
    "section": "Ejemplo: continuación",
    "text": "Ejemplo: continuación\nConsideremos que un estimador \\(\\hat{f}\\) y un conjunto de variables \\(X\\) entregan la predicción \\(\\hat{Y}=\\hat{f}(X)\\) . Asumiendo que \\(\\hat{f}\\) y \\(X\\) son fijos, entonces se tiene:\n\\[\\begin{align*}\n\\mathbb{E}(Y-\\hat{Y})^2 &= \\mathbb{E}(f(X)+\\varepsilon - \\hat{f}(X))^2 \\\\\n&= \\underbrace{[f(X) - \\hat{f}(X)]^2}_\\text{Reducible} + \\underbrace{\\mathbb{V}(\\varepsilon)}_\\text{Irreducible}\n\\end{align*}\\]\nNosotros nos concentraremos en técnicas para estimar \\(f\\) con el fin de poder minimizar el error reducible."
  },
  {
    "objectID": "slides/lec_week6.html#inferencia",
    "href": "slides/lec_week6.html#inferencia",
    "title": "Introducción a machine learning",
    "section": "Inferencia",
    "text": "Inferencia\nUsualmente estamos interesados en entender la forma en que \\(Y\\) se ve afectada conforme \\(X_1,\\dots,X_p\\) cambia. En este tipo de situaciones, deseamos estimar \\(f\\), pero nuestro objetivo no es necesariamente hacer predicciones para \\(Y\\). En cambio, se quiere entender la relación entre \\(X\\) e \\(Y\\), por lo que ya no podemos tratar \\(\\hat{f}\\) como una caja negra, debido a que para poder explicar el fenómeno debemos tener una forma exacta. Usualmente nos preguntamos:\n\n¿Qué predictores están asociados con la respuesta?\n¿Cuál es la relación entre la respuesta y cada predictor?\n¿La relación entre \\(Y\\) y cada predictor ser explicada adecuadamente usando una ecuación lineal o la relación es más complicada?"
  },
  {
    "objectID": "slides/lec_week6.html#cómo-estimamos-f",
    "href": "slides/lec_week6.html#cómo-estimamos-f",
    "title": "Introducción a machine learning",
    "section": "¿Cómo estimamos \\(f\\)?",
    "text": "¿Cómo estimamos \\(f\\)?\nA lo largo del curso, veremos enfoques lineales y no lineales para estimar \\(f\\). Estos métodos usualmente comparten ciertas características.\nEn general, la mayoría de las técnicas de aprendizaje estadístico pueden ser categorizadas como paramétricas o no-paramétricas."
  },
  {
    "objectID": "slides/lec_week6.html#métodos-paramétricos",
    "href": "slides/lec_week6.html#métodos-paramétricos",
    "title": "Introducción a machine learning",
    "section": "Métodos paramétricos",
    "text": "Métodos paramétricos\nEste enfoque tiene dos pasos y se base en modelos que reducen el problema de estimar \\(f\\) a estimar un conjunto de parámetros.\n\nPros\n\nEs mucho más fácil que ajustar una función arbitraria cualquiera\n\n\n\nContras\n\nEl modelo usualmente no seguirá la forma real de \\(f\\)\nSi el ajuste está muy lejano a la forma real, la estimación será mala\nSe puede caer en sobreajuste."
  },
  {
    "objectID": "slides/lec_week6.html#métodos-paramétricos-continuación",
    "href": "slides/lec_week6.html#métodos-paramétricos-continuación",
    "title": "Introducción a machine learning",
    "section": "Métodos paramétricos: continuación",
    "text": "Métodos paramétricos: continuación\n¿Cuales serían los pasos de un enfoque paramétrico?\n\nAsumir la forma de \\(f\\)\nRealizar un proceso que ajuste el conjunto de datos (training set) para el modelo."
  },
  {
    "objectID": "slides/lec_week6.html#métodos-no-paramétricos",
    "href": "slides/lec_week6.html#métodos-no-paramétricos",
    "title": "Introducción a machine learning",
    "section": "Métodos no paramétricos",
    "text": "Métodos no paramétricos\nEl enfoque no paramétrico se caracteriza por no asumir la forma de \\(f\\), pero en lugar de eso intenta obtener una estimación de \\(f\\) que sea lo más cercano al conjunto de datos sin llegar a un sobreajuste.\n\nPros\n\nAl no asumir nada sobre \\(f\\), estos métodos permiten un vasto rango de formas que se ajustan con precisión a \\(f\\)\n\n\n\nContras\n\nUn gran número de datos es necesario para estimar de forma precisa \\(f\\), mucho más que bajo un enfoque paramétrico."
  },
  {
    "objectID": "slides/lec_week6.html#compensación-entre-precisión-vs-interpretabilidad",
    "href": "slides/lec_week6.html#compensación-entre-precisión-vs-interpretabilidad",
    "title": "Introducción a machine learning",
    "section": "Compensación entre precisión vs interpretabilidad",
    "text": "Compensación entre precisión vs interpretabilidad\nComo sabemos hay métodos de aprendizaje estadístico que son menos flexibles que otros, por ejemplo la regresión lineal. Sin embargo, existen razones para escoger estas metodologías en vez de una más flexible.\n\nSi la inferencia es nuestro principal objetivo, los modelos más restrictivos son recomendados debido a que la relación entre \\(X\\) e \\(Y\\) es fácilmente interpretable.\nMétodos más flexibles usualmente llegar a estimación más complejas que dificultan el análisis de alguna relación individual entre un predictor y la variable respuesta.\nIncluso cuando la predicción es el único objetivo, modelos más restrictivos pueden entregar mayor precisión que la mayoría de los métodos más flexible, debido a que estos últimos pueden sobreajustar."
  },
  {
    "objectID": "slides/lec_week6.html#diagrama-de-modelos",
    "href": "slides/lec_week6.html#diagrama-de-modelos",
    "title": "Introducción a machine learning",
    "section": "Diagrama de modelos",
    "text": "Diagrama de modelos"
  },
  {
    "objectID": "slides/lec_week6.html#teorema-del-no-free-lunch",
    "href": "slides/lec_week6.html#teorema-del-no-free-lunch",
    "title": "Introducción a machine learning",
    "section": "Teorema del No-Free-Lunch",
    "text": "Teorema del No-Free-Lunch\n¿Por qué no simplemente elegimos el mejor método para todos los problemas?\nEl teorema de No-Free-Lunch establece que todos los algoritmos de optimización se desempeñan igualmente bien cuando su desempeño es promediado sobre todas las funciones objetivos posibles."
  },
  {
    "objectID": "slides/lec_week6.html#compromiso-sesgo-varianza",
    "href": "slides/lec_week6.html#compromiso-sesgo-varianza",
    "title": "Introducción a machine learning",
    "section": "Compromiso sesgo-varianza",
    "text": "Compromiso sesgo-varianza\nUna de las herramientas que tenemos para cuantificar que tan bueno es nuestro ajuste es el Error cuadrático medio, lo notamos por sus siglas en inglés MSE. Para un valor \\(x_0\\) dado, es posible mostrar que el error cuadrático medio se puede descomponer de la forma\n\\[\n\\mathbb{E}\\left(y_0 - \\hat{f}(x_0)\\right)^2=\\mathbb{V}(\\hat{f}(x_0))+[Bias(\\hat{f}(x_0))]^2+\\mathbb{V}(\\varepsilon)\n\\]\nEn donde el lado izquierdo representa el error cuadrado medio esperado cuando se estima \\(f\\) y se evalúan en el punto \\(x_0\\).\nDe la ecuación anterior se desprende que para minimizar el error cuadrático medio se debe seleccionar una metodología que simultáneamente logre una varianza baja y un bajo sesgo."
  },
  {
    "objectID": "slides/lec_week6.html#compromiso-sesgo-varianza-continuación",
    "href": "slides/lec_week6.html#compromiso-sesgo-varianza-continuación",
    "title": "Introducción a machine learning",
    "section": "Compromiso sesgo-varianza: continuación",
    "text": "Compromiso sesgo-varianza: continuación\nA esta relación le llamamos un compromiso, debido a que es fácil obtener un método con extremadamente bajo sesgo pero varianza alta o un modelo con baja varianza pero alto sesgo.\nComo regla general, si se utilizan metodologías más flexibles, la varianza crecerá y el sesgo disminuirá."
  },
  {
    "objectID": "slides/lec_week7.html#ejemplo",
    "href": "slides/lec_week7.html#ejemplo",
    "title": "Métodos supervisados",
    "section": "Ejemplo",
    "text": "Ejemplo\n\nlibrary(ISLR)\ndata<-Default\nhead(data)\n\n  default student   balance    income\n1      No      No  729.5265 44361.625\n2      No     Yes  817.1804 12106.135\n3      No      No 1073.5492 31767.139\n4      No      No  529.2506 35704.494\n5      No      No  785.6559 38463.496\n6      No     Yes  919.5885  7491.559"
  },
  {
    "objectID": "slides/lec_week7.html#ejemplo-continuación",
    "href": "slides/lec_week7.html#ejemplo-continuación",
    "title": "Métodos supervisados",
    "section": "Ejemplo: continuación",
    "text": "Ejemplo: continuación\n\nlibrary(ggplot2)\nggplot(data) + aes(x = balance, y = income, colour = default) + geom_point(shape = \"bullet\", size = 1.5) +\n scale_color_hue(direction = -1) + theme_gray()"
  },
  {
    "objectID": "slides/lec_week7.html#ejemplo-continuación-1",
    "href": "slides/lec_week7.html#ejemplo-continuación-1",
    "title": "Métodos supervisados",
    "section": "Ejemplo: continuación",
    "text": "Ejemplo: continuación\n\nggplot(data) +  aes(x = default, y = balance, fill = default) +  geom_boxplot(shape = \"circle\") +\n  scale_fill_hue(direction = -1) +  theme_gray()"
  },
  {
    "objectID": "slides/lec_week7.html#ejemplo-continuación-2",
    "href": "slides/lec_week7.html#ejemplo-continuación-2",
    "title": "Métodos supervisados",
    "section": "Ejemplo: continuación",
    "text": "Ejemplo: continuación\n\nggplot(data) +  aes(x = default, y = income, fill = default) +  geom_boxplot(shape = \"circle\") +\n  scale_fill_hue(direction = -1) +  theme_gray()"
  },
  {
    "objectID": "slides/lec_week7.html#por-qué-no-usar-una-regresión-lineal",
    "href": "slides/lec_week7.html#por-qué-no-usar-una-regresión-lineal",
    "title": "Métodos supervisados",
    "section": "¿Por qué no usar una regresión lineal?",
    "text": "¿Por qué no usar una regresión lineal?\nSupongamos que se intenta predecir la condición médica de un paciente en la sala de emergencia con base a sus síntomas. Para simplificar, imaginemos que sólo que tienen 3 posibles diagnósticos: accidente cardiovascular, sobredosis y ataque epiléptico. Por lo que podríamos clasificar la variable respuesta como\n\\[\nY=\\begin{cases} 1 \\quad \\text{si Accidente cardiovascular}\\\\\n2 \\quad \\text{si Sobredosis} \\\\\n3 \\quad \\text{si Ataque epiléptico}\n\\end{cases}\n\\]\nUsando esta codificación, se puede usar el método de mínimos cuadrados para ajustar una regresión lineal para predecir \\(Y\\) en base a los predictores \\(X_1,\\dots, X_p\\)."
  },
  {
    "objectID": "slides/lec_week7.html#por-qué-no-usar-una-regresión-lineal-continuación",
    "href": "slides/lec_week7.html#por-qué-no-usar-una-regresión-lineal-continuación",
    "title": "Métodos supervisados",
    "section": "¿Por qué no usar una regresión lineal?: continuación",
    "text": "¿Por qué no usar una regresión lineal?: continuación\nDesafortunadamente, esta codificación implica un ordenamiento de las salidas, estableciendo sobredosis entre accidente cardiovascular y Ataque epiléptico, e inherentemente afirmando que la diferencia entre categorías contiguas son la misma.\nEs claro notar que si usamos otra codificación, el ajuste de regresión lineal obtenido será diferente al primero. En general, no hay una forma natural de convertir una variable respuesta cualitativa con más de dos niveles en una variable cuantitativa que esté lista para hacer una regresión lineal."
  },
  {
    "objectID": "slides/lec_week7.html#por-qué-no-usar-una-regresión-lineal-continuación-1",
    "href": "slides/lec_week7.html#por-qué-no-usar-una-regresión-lineal-continuación-1",
    "title": "Métodos supervisados",
    "section": "¿Por qué no usar una regresión lineal?: continuación",
    "text": "¿Por qué no usar una regresión lineal?: continuación\nEn el caso de variable respuesta binaria, la situación es algo más favorable, debido a que si se cambia la codificación, el ajuste de regresión obtenido será el mismo. Sin embargo, el método de mínimos cuadrados no tiene sentido, provocando que algunas de nuestras estimación estén fuera del intervalo [0,1], haciendo difícil la interpretación de las probabilidades.\nLo anterior debido a que se puede mostrar que el \\(X\\hat{\\beta}\\) obtenido con la regresión lineal con codificación binaria, es simplemente una estimación de \\(\\mathbb{P}(\\text{Sobredosis})\\) si la codificación es\n\\[\nY = \\begin{cases} 0 \\quad \\text{si Accidente cardiovascular}\\\\\n1 \\quad \\text{si Sobredosis}\n\\end{cases}\n\\]"
  },
  {
    "objectID": "slides/lec_week7.html#regresión-logística",
    "href": "slides/lec_week7.html#regresión-logística",
    "title": "Métodos supervisados",
    "section": "Regresión logística",
    "text": "Regresión logística\nUsando el mismo conjunto de datos Default, donde la variable respuesta default cae dentro de dos categorías Yes y No. En vez de modelar la respuesta \\(Y\\) directamente, la regresión logística modela la probabilidad que \\(Y\\) pertenezca a una categoría particular.\nPara el conjunto de datos Default, la regresión logística modela la probabilidad de que haya default (morosidad). Por ejemplo, la probabilidad de default dado cierto balance puede ser escrito como\n\\[\n\\mathbb{P}( \\text{default}=\\text{Yes}|\\text{balance})\n\\]\nLos valores de esta probabilidad, que la abreviamos como \\(p(\\text{balance})\\), estarán entre 0 y 1. Por lo que para un valor particular de balance, se puede hacer una predicción para default. Por ejemplo, se podría predecir que default=Yes para cualquier individuo cuyo \\(p(\\text{balance})>0.5\\). Alternativamente, si una compañía quisiese ser más conservador en la predicción, podría definir \\(p(\\text{balance})>0.1\\)."
  },
  {
    "objectID": "slides/lec_week7.html#modelo-logístico",
    "href": "slides/lec_week7.html#modelo-logístico",
    "title": "Métodos supervisados",
    "section": "Modelo logístico",
    "text": "Modelo logístico\n¿Cómo deberíamos modelar la relación entre \\(p(X)=\\mathbb{P}(Y=1|X)\\) y \\(X\\)?\nPodemos utilizar un enfoque de regresión lineal para representar estar probabilidades, esto es:\n\\[\np(X)=\\beta_0 + \\beta_1 X\n\\]\nSi usamos este enfoque para predecir default=Yes usando balance, entonces obtendremos el siguiente modelo."
  },
  {
    "objectID": "slides/lec_week7.html#modelo-logístico-continuación",
    "href": "slides/lec_week7.html#modelo-logístico-continuación",
    "title": "Métodos supervisados",
    "section": "Modelo logístico: continuación",
    "text": "Modelo logístico: continuación"
  },
  {
    "objectID": "slides/lec_week7.html#modelo-logístico-continuación-1",
    "href": "slides/lec_week7.html#modelo-logístico-continuación-1",
    "title": "Métodos supervisados",
    "section": "Modelo logístico: continuación",
    "text": "Modelo logístico: continuación\nPara evitar lo anterior, debemos modelar \\(p(X)\\) usando una función que entregue salidas entre 0 y 1 para todos los valores de \\(X\\). Muchas funciones cumplen estas condiciones. En una regresión logística, usamos la función logística.\n\\[\np(X)=\\dfrac{\\exp(\\beta_0 + \\beta_1 X)}{1+\\exp(\\beta_0 + \\beta_1 X)}\n\\]\nPara ajustar el modelo anterior, usamos el método de máxima verosimilitud."
  },
  {
    "objectID": "slides/lec_week7.html#modelo-logístico-continuación-2",
    "href": "slides/lec_week7.html#modelo-logístico-continuación-2",
    "title": "Métodos supervisados",
    "section": "Modelo logístico: continuación",
    "text": "Modelo logístico: continuación"
  },
  {
    "objectID": "slides/lec_week7.html#modelo-logístico-continuación-3",
    "href": "slides/lec_week7.html#modelo-logístico-continuación-3",
    "title": "Métodos supervisados",
    "section": "Modelo logístico: continuación",
    "text": "Modelo logístico: continuación\nManipulando un poco la fórmula anterior, se tiene que\n\\[\n\\dfrac{p(X)}{1-p(X)}=\\exp(\\beta_0 + \\beta_1 X)\n\\]\nLa cantidad \\({p(X) \\over 1-p(X)}\\) se le llaman odds, que pueden toman cualquier valor en \\(\\mathbb{R}^{+}\\). Valores cercanos a cero y tendiendo a infinito, indican muy baja y alta probabilidad de default, respectivamente."
  },
  {
    "objectID": "slides/lec_week7.html#introducción",
    "href": "slides/lec_week7.html#introducción",
    "title": "Métodos supervisados",
    "section": "Introducción",
    "text": "Introducción\nComo hemos mencionado a lo largo del curso, una regresión lineal simple asume que la variable respuesta \\(Y\\) es cuantitativa, pero en muchas situaciones esta es cualitativa (también referida como categórica). En lo que sigue, veremos métodos para predecir respuestas cualitativas, más comúnmente llamado clasificación.\nExisten mucha técnicas de clasificación o clasificadores, que se pueden usar para predecir una variable cualitativa. Entre ellos se encuentras:\n\nRegresión logística\nAnálisis discriminante lineal\nk-NN (k- nearest neighbors / k-vecinos cercanos)\nModelos generalizados aditivos\nÁrboles y bosques aleatorios\nBoosting\nSVM"
  },
  {
    "objectID": "slides/lec_week7.html#modelo-logístico-continuación-4",
    "href": "slides/lec_week7.html#modelo-logístico-continuación-4",
    "title": "Métodos supervisados",
    "section": "Modelo logístico: continuación",
    "text": "Modelo logístico: continuación\nTomando el logaritmo en ambos lados, se tiene\n\\[\n\\log \\left(\\dfrac{p(X)}{1-p(X)}\\right)=\\beta_0 + \\beta_1 X\n\\]\na esta cantidad la llamamos log-odds o logit. Notamos que el modelo de regresión logística tiene un logit lineal en \\(X\\)."
  },
  {
    "objectID": "slides/lec_week7.html#estimación-de-los-coeficientes-de-regresión",
    "href": "slides/lec_week7.html#estimación-de-los-coeficientes-de-regresión",
    "title": "Métodos supervisados",
    "section": "Estimación de los coeficientes de regresión",
    "text": "Estimación de los coeficientes de regresión\nLos coeficiente \\(\\beta_0\\) y \\(\\beta_1\\) en la ecuación\n\\[\np(X)=\\dfrac{\\exp(\\beta_0 + \\beta_1 X)}{1+\\exp(\\beta_0 + \\beta_1 X)}\n\\]\nson desconocidos, por lo que deben ser estimados basándose en los datos de entrenamiento. Si bien podríamos ocupar una metodología de métodos cuadrados no lineales para ajustar el modelo:\n\\[\n\\log \\left(\\dfrac{p(X)}{1-p(X)}\\right)=\\beta_0 + \\beta_1 X\n\\]\nLa metodología de máxima verosimilitud es usualmente preferida, debido a que tiene mejores propiedades estadísticas."
  },
  {
    "objectID": "slides/lec_week7.html#estimación-de-los-coeficientes-de-regresión-continuación",
    "href": "slides/lec_week7.html#estimación-de-los-coeficientes-de-regresión-continuación",
    "title": "Métodos supervisados",
    "section": "Estimación de los coeficientes de regresión: continuación",
    "text": "Estimación de los coeficientes de regresión: continuación\nFormalmente, definimos la función de verosimilitud como:\n\\[\n\\ell(\\beta_0,\\beta_1)=\\prod_{i:y_i=1}p(x_i)\\prod_{i':y_{i'}=0}(1-p(x_{i'}))\n\\]\nLas estimaciones \\(\\hat{\\beta}_0\\) y \\(\\hat{\\beta}_1\\) son escogidos para maximizar la función de verosimilitud."
  },
  {
    "objectID": "slides/lec_week7.html#ejemplo-1",
    "href": "slides/lec_week7.html#ejemplo-1",
    "title": "Métodos supervisados",
    "section": "Ejemplo",
    "text": "Ejemplo\n\nlogit <- glm(default ~ balance, data = data, family = \"binomial\")\nsummary(logit)\n\n\nCall:\nglm(formula = default ~ balance, family = \"binomial\", data = data)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-2.2697  -0.1465  -0.0589  -0.0221   3.7589  \n\nCoefficients:\n              Estimate Std. Error z value Pr(>|z|)    \n(Intercept) -1.065e+01  3.612e-01  -29.49   <2e-16 ***\nbalance      5.499e-03  2.204e-04   24.95   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 2920.6  on 9999  degrees of freedom\nResidual deviance: 1596.5  on 9998  degrees of freedom\nAIC: 1600.5\n\nNumber of Fisher Scoring iterations: 8"
  },
  {
    "objectID": "slides/lec_week7.html#predicciones",
    "href": "slides/lec_week7.html#predicciones",
    "title": "Métodos supervisados",
    "section": "Predicciones",
    "text": "Predicciones\nUna vez que los coeficientes han sido estimados, lo que resta es calcular la probabilidad de default para una balance dado. Por ejemplo, la predicción para una persona con balance \\(\\$1000\\) es\n\\[\n\\hat{p}(X)=\\dfrac{\\exp(-10.65+ 0.0055 \\times 1000)}{1+\\exp(-10.65+ 0.0055 \\times 1000)}\\approx 0.00576\n\\]\nque es bajo \\(1\\%\\). En contraste con alguien que adeuda \\(\\$2000\\), en cuyo caso \\(\\hat{p}(X)=0.586\\)."
  },
  {
    "objectID": "slides/lec_week7.html#predicciones-continuación",
    "href": "slides/lec_week7.html#predicciones-continuación",
    "title": "Métodos supervisados",
    "section": "Predicciones: continuación",
    "text": "Predicciones: continuación\nSi utilizamos dummy variables para el predictor student codificado como 0 y 1. tendremos el siguiente ajuste\n\n\n\nCall:\nglm(formula = default ~ student, family = \"binomial\", data = data)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-0.2970  -0.2970  -0.2434  -0.2434   2.6585  \n\nCoefficients:\n            Estimate Std. Error z value Pr(>|z|)    \n(Intercept) -3.50413    0.07071  -49.55  < 2e-16 ***\nstudentYes   0.40489    0.11502    3.52 0.000431 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 2920.6  on 9999  degrees of freedom\nResidual deviance: 2908.7  on 9998  degrees of freedom\nAIC: 2912.7\n\nNumber of Fisher Scoring iterations: 6"
  },
  {
    "objectID": "slides/lec_week7.html#predicciones-continuación-1",
    "href": "slides/lec_week7.html#predicciones-continuación-1",
    "title": "Métodos supervisados",
    "section": "Predicciones: continuación",
    "text": "Predicciones: continuación\nAsí, podemos calcular las probabilidades\n\\[\n\\mathbb{P}\\left( \\text{default=Yes }| \\text{ student=Yes}\\right)=\\dfrac{\\exp(-3.5041+ 0.4049 \\times 1)}{1+\\exp(-3.5041+ 0.4049 \\times 1)}\\approx 0.0431\n\\]\ny,\n\\[\n\\mathbb{P}\\left( \\text{default=Yes }| \\text{ student=No}\\right)=\\dfrac{\\exp(-3.5041+ 0.4049 \\times 0)}{1+\\exp(-3.5041+ 0.4049 \\times 0)}\\approx 0.0292\n\\]"
  },
  {
    "objectID": "slides/lec_week7.html#regresión-logística-múltiple",
    "href": "slides/lec_week7.html#regresión-logística-múltiple",
    "title": "Métodos supervisados",
    "section": "Regresión logística múltiple",
    "text": "Regresión logística múltiple\nAhora consideramos el problema de predecir una respuesta binaria usando múltiples predictores. La extensión natural del modelo de regresión es\n\\[\n\\log \\left(\\dfrac{p(X)}{1-p(X)}\\right)=\\beta_0 + \\beta_1 X_1 +\\dots + \\beta_p X_p\n\\]\ndonde \\(X=(X_1,\\dots,X_p)\\) son \\(p\\) predictores. La ecuación anterior la podemos reescribir como\n\\[\np(X)=\\dfrac{\\exp(\\beta_0 + \\beta_1 X_1 +\\dots + \\beta_p X_p)}{1+ \\exp(\\beta_0 + \\beta_1 X_1 +\\dots + \\beta_p X_p)}\n\\]\nAl igual que antes, usamos el método de máxima verosimilitud para estimar \\(\\mathbf{\\beta}\\)."
  },
  {
    "objectID": "slides/lec_week7.html#ejemplo-2",
    "href": "slides/lec_week7.html#ejemplo-2",
    "title": "Métodos supervisados",
    "section": "Ejemplo",
    "text": "Ejemplo\n\n\n\nCall:\nglm(formula = default ~ balance + student + income, family = \"binomial\", \n    data = data)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-2.4691  -0.1418  -0.0557  -0.0203   3.7383  \n\nCoefficients:\n              Estimate Std. Error z value Pr(>|z|)    \n(Intercept) -1.087e+01  4.923e-01 -22.080  < 2e-16 ***\nbalance      5.737e-03  2.319e-04  24.738  < 2e-16 ***\nstudentYes  -6.468e-01  2.363e-01  -2.738  0.00619 ** \nincome       3.033e-06  8.203e-06   0.370  0.71152    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 2920.6  on 9999  degrees of freedom\nResidual deviance: 1571.5  on 9996  degrees of freedom\nAIC: 1579.5\n\nNumber of Fisher Scoring iterations: 8"
  },
  {
    "objectID": "slides/lec_week7.html#ejemplo-continuación-3",
    "href": "slides/lec_week7.html#ejemplo-continuación-3",
    "title": "Métodos supervisados",
    "section": "Ejemplo: continuación",
    "text": "Ejemplo: continuación"
  },
  {
    "objectID": "slides/lec_week7.html#regresión-logística-para-2-clases-en-la-respuesta",
    "href": "slides/lec_week7.html#regresión-logística-para-2-clases-en-la-respuesta",
    "title": "Métodos supervisados",
    "section": "Regresión logística para \\(>2\\) clases en la respuesta",
    "text": "Regresión logística para \\(>2\\) clases en la respuesta\nEn el caso en que tengamos más de dos clases en la variable respuesta, es posible extender la regresión lineal. En el ejemplo de determinación de diagnóstico en una sala de emergencia se tenían las categorías accidente cardiovascular, sobredosis y ataque epiléptico, por lo que se desearía modelar\n\\[\n\\mathbb{P}\\left( Y= \\text{ acc. card. }| X\\right)\n\\]\ny\n\\[\n\\mathbb{P}\\left( Y= \\text{ sobredosis }| X\\right)\n\\]\nsiendo el remanente,\n\\[\n\\mathbb{P}\\left( Y= \\text{ ataque epiléptico }| X\\right)= 1-\\mathbb{P}\\left( Y= \\text{ acc. card }| X\\right)-\\mathbb{P}\\left( Y= \\text{ sobredosis }| X\\right)\n\\]\nSi bien es posible la extensión, en la práctica no es frecuentemente usado, pues se prefiere realizar un análisis discriminante."
  },
  {
    "objectID": "slides/lec_week7.html#teorema-de-bayes-para-clasificación",
    "href": "slides/lec_week7.html#teorema-de-bayes-para-clasificación",
    "title": "Métodos supervisados",
    "section": "Teorema de Bayes para clasificación",
    "text": "Teorema de Bayes para clasificación\nSupongamos que queremos clasificar una observación entre \\(K\\) clases, donde \\(K\\geq 2\\). Esto es, que la variable respuesta \\(Y\\) puede tomar \\(K\\) posibles valores distintos y no-ordenados.\nSea \\(\\pi_k\\) la probabilidad apriori que una observación escogida aleatoriamente provenga de la clase \\(k-\\)ésima. Sea \\(f_k(X)=\\mathbb{P}(X=x|Y=k)\\) la función de densidad de \\(X\\) para una observación que proviene de la clase \\(k-\\)ésima. Luego, por el teorema de Bayes se tiene\n\\[\n\\mathbb{P}(Y=k|X=x)=\\dfrac{\\pi_k f_k(x)}{\\sum_{l=1}^{K} \\pi_l f_l(x)}\n\\]\nal igual que antes usamos la notación \\(p_k(X)=\\mathbb{P}(Y=k|X)\\)."
  },
  {
    "objectID": "slides/lec_week7.html#introducción-1",
    "href": "slides/lec_week7.html#introducción-1",
    "title": "Métodos supervisados",
    "section": "Introducción",
    "text": "Introducción\nLa regresión logística que vimos antes involucra modelar directamente \\(\\mathbb{P}\\left( Y=k|X=x\\right)\\) usando la función logística dada por\n\\[\np(X)=\\dfrac{\\exp(\\beta_0 + \\beta_1 X_1 +\\dots + \\beta_p X_p)}{1+ \\exp(\\beta_0 + \\beta_1 X_1 +\\dots + \\beta_p X_p)}\n\\]\npara el caso de dos clases en la variable respuesta. En lo que sigue, consideramos una manera alternativa y menos directa para estimar estas probabilidades. En esta metodología, modelamos la distribución de los predictores \\(X\\) por separado en cada una de las categorías de la variable respuesta \\((Y)\\), y luego usamos el teorema de Bayes para convertir estos resultados en estimaciones de \\(\\mathbb{P}\\left(Y=k|X=x\\right)\\).\nCuando estas distribuciones se asumen normales, la forma de este modelo es muy similar a una regresión logística."
  },
  {
    "objectID": "slides/lec_week7.html#teorema-de-bayes-para-clasificación-continuación",
    "href": "slides/lec_week7.html#teorema-de-bayes-para-clasificación-continuación",
    "title": "Métodos supervisados",
    "section": "Teorema de Bayes para clasificación: continuación",
    "text": "Teorema de Bayes para clasificación: continuación\nLa idea general, es no estimar \\(p_k(X)\\) directamente, sino estimar \\(\\pi_k\\) y \\(f_k\\) para obtener lo deseado.\nUsualmente \\(\\pi_k\\) es fácil de obtener si se tiene una muestra aleatoria de \\(Y\\), pues obtenemos estas estimaciones como las proporciones de cada clase.\nEn cambio, estimar \\(f_k(X)\\) tiende a ser más difícil, a menos que se asuman formas simples para las densidades.\nLlamamos a la cantidad \\(p_k(x)\\) la probabilidad posterior que una observación \\(X=x\\) pertenezca a la clase \\(k-\\)ésima."
  },
  {
    "objectID": "slides/lec_week7.html#análisis-discriminante-lineal-con-p1",
    "href": "slides/lec_week7.html#análisis-discriminante-lineal-con-p1",
    "title": "Métodos supervisados",
    "section": "Análisis discriminante lineal con \\(p=1\\)",
    "text": "Análisis discriminante lineal con \\(p=1\\)\nPrimero asumiremos que \\(p=1\\), es decir, sólo tenemos un predictor. Deseamos obtener una estimación para \\(f_k(x)\\) para utilizarlo en la ecuación\n\\[\n\\mathbb{P}(Y=k|X=x)=\\dfrac{\\pi_k f_k(x)}{\\sum_{l=1}^{K} \\pi_l f_l(x)}\n\\]\ny así poder estimar \\(p_k(x)\\). Para poder estimar \\(f_k\\), primero debemos asumir su forma, por lo que asumiremos que \\(f_k\\) es Gaussiana. Por lo que,\n\\[\nf_k(x)=\\dfrac{1}{\\sqrt{2\\pi}\\sigma_k}\\exp\\left( -\\dfrac{1}{2\\sigma_{k}^{2}}(x-\\mu_k)^2\\right)\n\\]\ndonde \\(\\mu_k\\) y \\(\\sigma_{k}^{2}\\) son la media y la varianza de la clase \\(k-\\)ésima. Por ahora, asumiremos que \\(\\sigma_{1}^{2}=\\dots=\\sigma_{K}^{2}=\\sigma^2\\)"
  },
  {
    "objectID": "slides/lec_week7.html#análisis-discriminante-lineal-con-p1-continuación",
    "href": "slides/lec_week7.html#análisis-discriminante-lineal-con-p1-continuación",
    "title": "Métodos supervisados",
    "section": "Análisis discriminante lineal con \\(p=1\\): continuación",
    "text": "Análisis discriminante lineal con \\(p=1\\): continuación\nPor lo anterior, se tendrá\n\\[\np_k(x)=\\dfrac{\\pi_k \\dfrac{1}{\\sqrt{2\\pi}\\sigma}\\exp\\left( -\\dfrac{1}{2\\sigma^{2}}(x-\\mu_k)^2\\right)}{\\sum_{l=1}^{K}\\pi_l\\dfrac{1}{\\sqrt{2\\pi}\\sigma}\\exp\\left( -\\dfrac{1}{2\\sigma^{2}}(x-\\mu_l)^2\\right) }\n\\]\nEl clasificador Bayesiano asigna una observacion \\(X=x\\) a la clase que su \\(p_k(x)\\) es más grande. Si tomamos el logaritmo y arreglamos términos en la expresión anterior, se tiene que el proceso es equivalente a asignar la observación a la clase en la que\n\\[\n\\delta_k(x)=x \\dfrac{\\mu_k}{\\sigma^2}-\\dfrac{\\mu_{k}^{2}}{2\\sigma^2}+\\log \\pi_k\n\\]\nes más grande."
  },
  {
    "objectID": "slides/lec_week7.html#análisis-discriminante-lineal-con-p1-continuación-1",
    "href": "slides/lec_week7.html#análisis-discriminante-lineal-con-p1-continuación-1",
    "title": "Métodos supervisados",
    "section": "Análisis discriminante lineal con \\(p=1\\): continuación",
    "text": "Análisis discriminante lineal con \\(p=1\\): continuación\nPor ejemplo, si \\(K=2\\) Y \\(\\pi_1=\\pi_2\\), entonces el clasificador Bayesiano asigna una observación a la clase 1 si \\(2x(\\mu_1-\\mu_2)>\\mu_{1}^{2}-\\mu_{2}^{2}\\) y a la clase 2 en caso contrario. En este caso, el límite de decisión de Bayes (Bayes decision boundary) corresponde al punto donde\n\\[\nx=\\dfrac{\\mu_{1}^{2}-\\mu_{2}^{2}}{2(\\mu_1-\\mu_2)}=\\dfrac{\\mu_1+\\mu_2}{2}\n\\]\nLlamamos a este, el punto (o área) en donde la clasificación es ambigua."
  },
  {
    "objectID": "slides/lec_week7.html#análisis-discriminante-lineal-con-p1-continuación-2",
    "href": "slides/lec_week7.html#análisis-discriminante-lineal-con-p1-continuación-2",
    "title": "Métodos supervisados",
    "section": "Análisis discriminante lineal con \\(p=1\\): continuación",
    "text": "Análisis discriminante lineal con \\(p=1\\): continuación\n\nggplot(data.frame(x = c(-4, 4)), aes(x)) + stat_function(fun = dnorm, args = list(mean = -1.25, sd = 1), color = \"firebrick\") + stat_function(fun = dnorm, args = list(mean = 1.25, sd = 1), color = \"green3\") +geom_vline(xintercept = 0, linetype = \"longdash\") + theme_bw()"
  },
  {
    "objectID": "slides/lec_week7.html#análisis-discriminante-lineal-con-p1-continuación-3",
    "href": "slides/lec_week7.html#análisis-discriminante-lineal-con-p1-continuación-3",
    "title": "Métodos supervisados",
    "section": "Análisis discriminante lineal con \\(p=1\\): continuación",
    "text": "Análisis discriminante lineal con \\(p=1\\): continuación\nEl análisis discriminante lineal (LDA) aproxima el clasificador bayesiano ingresando estimaciones para \\(pi_k,\\mu_k\\) y \\(\\sigma^2\\) en \\(\\delta_k(x)\\). Particularmente, las siguientes estimaciones son usadas.\n\\[\n\\hat{\\mu}_k=\\dfrac{1}{n_k}\\sum_{i:y_i=k}x_i\n\\]\ny,\n\\[\n\\hat{\\sigma}^{2}=\\dfrac{1}{n-K}\\sum_{k=1}^{K}\\sum_{i:y_i=K}(x_i-\\hat{\\mu}_k)^2\n\\]\ndonde \\(n\\) es el número total de observaciones en el conjunto de entrenamiento, \\(n_k\\) es el número de observaciones en el conjunto de entrenamiento en la clase \\(k-\\)ésima."
  },
  {
    "objectID": "slides/lec_week7.html#análisis-discriminante-lineal-con-p1-continuación-4",
    "href": "slides/lec_week7.html#análisis-discriminante-lineal-con-p1-continuación-4",
    "title": "Métodos supervisados",
    "section": "Análisis discriminante lineal con \\(p=1\\): continuación",
    "text": "Análisis discriminante lineal con \\(p=1\\): continuación\nEn el caso de que no tengamos información de \\(\\pi_1,\\dots,\\pi_K\\), el análisis discriminante lineal estima \\(\\pi_k\\) usando la proporción de las observaciones en el conjunto de entrenamiento que pertenece a la clase \\(k-\\)ésima. Esto es,\n\\[\n\\hat{\\pi}_k=\\dfrac{n_k}{n}\n\\]\nEl clasificador LDA reemplaza las estimaciones anteriores en \\(\\delta_k(x)\\) y asigna una observación \\(X=x\\) a la clase en la cual\n\\[\n\\hat{\\delta}_k=x\\dfrac{\\hat{\\mu}_k}{\\hat{\\sigma}^2}-\\dfrac{\\hat{\\mu}_{k}^{2}}{\\hat{2\\sigma}^2}+\\log \\hat{\\pi}_k\n\\]\nes más grande. El nombre de lineal viene de la linealidad de la función discriminante \\(\\hat{\\delta}_k\\) para \\(x\\)."
  },
  {
    "objectID": "slides/lec_week7.html#análisis-discriminante-lineal-con-p1-continuación-5",
    "href": "slides/lec_week7.html#análisis-discriminante-lineal-con-p1-continuación-5",
    "title": "Métodos supervisados",
    "section": "Análisis discriminante lineal con \\(p=1\\): continuación",
    "text": "Análisis discriminante lineal con \\(p=1\\): continuación"
  },
  {
    "objectID": "slides/lec_week7.html#análisis-discriminante-lineal-con-p1-1",
    "href": "slides/lec_week7.html#análisis-discriminante-lineal-con-p1-1",
    "title": "Métodos supervisados",
    "section": "Análisis discriminante lineal con \\(p>1\\)",
    "text": "Análisis discriminante lineal con \\(p>1\\)\nEn lo que sigue, vamos a extender las nociones de análisis discriminante cuando se tienen múltiples predictores, para ello asumiremos que \\(X=(X_1,X_2,\\dots,X_p)\\) es obtenido desde una distribución normal multivariada, con medias por clase e igual matriz de varianza-covarianza.\nRecordar que si \\(X\\sim N(\\mu,\\Sigma)\\) con \\(\\mathbb{E}(X)=\\mu\\) (vector de medias) y \\(Cov(X)=\\Sigma\\) la matriz \\(p\\times p\\) de covarianza de \\(X\\). Formalmente, la densidad de \\(X\\) se define como:\n\\[\nf(x)=\\dfrac{1}{(2\\pi)^{p/2}|\\Sigma|^{1/2}}\\exp\\left( -\\dfrac{1}{2}(x-\\mu)^{T} \\Sigma^{-1}(x-\\mu)\\right)\n\\]\nEn el caso de \\(p>1\\) predictores, el análisis discriminante lineal asume que las observaciones en la clase \\(k-\\)ésima son obtenidos desde una distribución normal multivariada."
  },
  {
    "objectID": "slides/lec_week7.html#análisis-discriminante-lineal-con-p1-continuación-6",
    "href": "slides/lec_week7.html#análisis-discriminante-lineal-con-p1-continuación-6",
    "title": "Métodos supervisados",
    "section": "Análisis discriminante lineal con \\(p>1\\): continuación",
    "text": "Análisis discriminante lineal con \\(p>1\\): continuación\nSi reemplazamos la función de densidad para la clase \\(k-\\)ésima, \\(f_k(X=x)\\) en la ecuación\n\\[\n\\mathbb{P}(Y=k|X=x)=\\dfrac{\\pi_k f_k(x)}{\\sum_{l=1}^{K} \\pi_l f_l(x)}\n\\]\ny usando un poco de álgebra, se puede reescribir \\(\\delta_k(x)\\) como\n\\[\n\\delta_k(x)=x^T\\Sigma^{-1} \\mu_k-\\dfrac{1}{2}\\mu_{k}^{T} \\Sigma^{-1} \\mu_k +\\log \\pi_k\n\\]\ny el clasificador bayesiano asigna la observación \\(X=x\\) a la clase que tienen mayor \\(\\delta_{k}(x)\\)."
  },
  {
    "objectID": "slides/lec_week7.html#análisis-discriminante-lineal-con-p1-continuación-7",
    "href": "slides/lec_week7.html#análisis-discriminante-lineal-con-p1-continuación-7",
    "title": "Métodos supervisados",
    "section": "Análisis discriminante lineal con \\(p>1\\): continuación",
    "text": "Análisis discriminante lineal con \\(p>1\\): continuación"
  },
  {
    "objectID": "slides/lec_week7.html#análisis-discriminante-lineal-con-p1-continuación-8",
    "href": "slides/lec_week7.html#análisis-discriminante-lineal-con-p1-continuación-8",
    "title": "Métodos supervisados",
    "section": "Análisis discriminante lineal con \\(p>1\\): continuación",
    "text": "Análisis discriminante lineal con \\(p>1\\): continuación\nEn la figura anterior, las elipses representan las regiones que contienen \\(95\\%\\) de la probabilidad de cada una de las clases. Al igual que antes, la línea punteada es el Límite de decisión Bayes. Es decir, representan el conjunto de valores \\(x\\) para los cuales \\(\\delta_k(x)=\\delta_\\ell(x)\\), esto es:\n\\[\nx^T\\Sigma^{-1} \\mu_k-\\dfrac{1}{2}\\mu_{k}^{T} \\Sigma^{-1} \\mu_k=x^T\\Sigma^{-1} \\mu_l-\\dfrac{1}{2}\\mu_{l}^{T} \\Sigma^{-1} \\mu_l\n\\]\npara \\(k\\neq l\\)."
  },
  {
    "objectID": "slides/lec_week7.html#ejemplo-3",
    "href": "slides/lec_week7.html#ejemplo-3",
    "title": "Métodos supervisados",
    "section": "Ejemplo",
    "text": "Ejemplo\n\nlibrary(MASS)\nmod_lda <- lda(Species ~ Sepal.Width + Sepal.Length + Petal.Length + Petal.Width, data = iris)\nmod_lda\n\nCall:\nlda(Species ~ Sepal.Width + Sepal.Length + Petal.Length + Petal.Width, \n    data = iris)\n\nPrior probabilities of groups:\n    setosa versicolor  virginica \n 0.3333333  0.3333333  0.3333333 \n\nGroup means:\n           Sepal.Width Sepal.Length Petal.Length Petal.Width\nsetosa           3.428        5.006        1.462       0.246\nversicolor       2.770        5.936        4.260       1.326\nvirginica        2.974        6.588        5.552       2.026\n\nCoefficients of linear discriminants:\n                    LD1         LD2\nSepal.Width   1.5344731  2.16452123\nSepal.Length  0.8293776  0.02410215\nPetal.Length -2.2012117 -0.93192121\nPetal.Width  -2.8104603  2.83918785\n\nProportion of trace:\n   LD1    LD2 \n0.9912 0.0088"
  },
  {
    "objectID": "slides/lec_week7.html#ejemplo-continuación-4",
    "href": "slides/lec_week7.html#ejemplo-continuación-4",
    "title": "Métodos supervisados",
    "section": "Ejemplo: continuación",
    "text": "Ejemplo: continuación\n\npredicciones <- predict(object = mod_lda, newdata = iris[, -5])\ntable(iris$Species, predicciones$class, dnn = c(\"Clase real\", \"Clase predicha\"))\n\n            Clase predicha\nClase real   setosa versicolor virginica\n  setosa         50          0         0\n  versicolor      0         48         2\n  virginica       0          1        49"
  },
  {
    "objectID": "slides/lec_week7.html#ejemplo-continuación-5",
    "href": "slides/lec_week7.html#ejemplo-continuación-5",
    "title": "Métodos supervisados",
    "section": "Ejemplo: continuación",
    "text": "Ejemplo: continuación\n\nlibrary(klaR)\npartimat(Species ~ Sepal.Width + Sepal.Length + Petal.Length + Petal.Width, data = iris, method = \"lda\", prec = 200,  image.colors = c(\"darkgoldenrod1\", \"snow2\", \"skyblue2\"), col.mean = \"firebrick\")"
  },
  {
    "objectID": "slides/lec_week7.html#métricas-para-clasificación",
    "href": "slides/lec_week7.html#métricas-para-clasificación",
    "title": "Métodos supervisados",
    "section": "Métricas para clasificación",
    "text": "Métricas para clasificación\nEn problemas de clasificación, existen un gran número de métricas para evaluar el desempeño de un modelo. Por ejemplo, para el ejemplo de morosidad:\n\nlibrary(caret)\nconfusionMatrix(table(predict(logit2, type=\"response\") >= 0.5, data$default == \"Yes\"))\n\nConfusion Matrix and Statistics\n\n       \n        FALSE TRUE\n  FALSE  9627  228\n  TRUE     40  105\n                                          \n               Accuracy : 0.9732          \n                 95% CI : (0.9698, 0.9763)\n    No Information Rate : 0.9667          \n    P-Value [Acc > NIR] : 0.0001044       \n                                          \n                  Kappa : 0.4278          \n                                          \n Mcnemar's Test P-Value : < 2.2e-16       \n                                          \n            Sensitivity : 0.9959          \n            Specificity : 0.3153          \n         Pos Pred Value : 0.9769          \n         Neg Pred Value : 0.7241          \n             Prevalence : 0.9667          \n         Detection Rate : 0.9627          \n   Detection Prevalence : 0.9855          \n      Balanced Accuracy : 0.6556          \n                                          \n       'Positive' Class : FALSE"
  },
  {
    "objectID": "slides/lec_week7.html#análisis-discriminante-cuadrático",
    "href": "slides/lec_week7.html#análisis-discriminante-cuadrático",
    "title": "Métodos supervisados",
    "section": "Análisis discriminante cuadrático",
    "text": "Análisis discriminante cuadrático\nEl análisis discriminante cuadrático es una alternativa a LDA, en la que se asumía distribución normal e igual varianza en cada una de las clases. Si bien, en el análisis discriminante cuadrático (QDA) también se asume que los datos provienen desde una distribución normal y estima los parámetros para predecir. Sin embargo, el QDA asume que cada clase tienen su propia matriz de covarianza.\nEsto es, se asume que una observación proveniente de la clase \\(k-\\)ésima es de la forma \\(X\\sim N(\\mu_k,\\Sigma_k)\\), donde \\(\\Sigma_k\\) es la matriz de covarianza para la clase \\(k-\\)ésima."
  },
  {
    "objectID": "slides/lec_week7.html#métricas-para-clasificación-continuación",
    "href": "slides/lec_week7.html#métricas-para-clasificación-continuación",
    "title": "Métodos supervisados",
    "section": "Métricas para clasificación: continuación",
    "text": "Métricas para clasificación: continuación\nLa función confusionMatrix() nos entrega la matriz de confusión junto con varias métricas asociadas. Esta matriz en su forma más esencial es:"
  },
  {
    "objectID": "slides/lec_week7.html#análisis-discriminante-cuadrático-continuación",
    "href": "slides/lec_week7.html#análisis-discriminante-cuadrático-continuación",
    "title": "Métodos supervisados",
    "section": "Análisis discriminante cuadrático: continuación",
    "text": "Análisis discriminante cuadrático: continuación\nBajo estos supuestos, el clasificador bayesiano asigna una observación \\(X=x\\) a la clase en la que\n\\[\\begin{align*}\n\\delta_k(x)&=-\\dfrac{1}{2}(x-\\mu_k)^{T}\\Sigma_{k}^{-1}(x-\\mu_k)+\\log \\pi_k \\\\\n&=-\\dfrac{1}{2}x^{T} \\Sigma_{k}^{-1}x+x^{T}\\Sigma_{k}^{-1}\\mu_k-\\dfrac{1}{2}\\mu_{k}^{T}\\mu_k+\\log \\pi_k\n\\end{align*}\\]\nes mayor. Así, se requerirá estimar \\(\\Sigma_k,\\mu_k\\) y \\(\\pi_k\\). El nombre de cuadrático viene debido a que \\(x\\) aparece como una función cuadrática en la ecuación anterior."
  },
  {
    "objectID": "slides/lec_week7.html#lda-o-qda",
    "href": "slides/lec_week7.html#lda-o-qda",
    "title": "Métodos supervisados",
    "section": "¿LDA o QDA?",
    "text": "¿LDA o QDA?\nSi tenemos \\(p\\) predictores, estimar la matriz de covarianza requiere estimar \\(p(p+1)/2\\) parámetros. En el caso de QDA se estima una matriz de covarianza para cada clase, por lo que se deben estimar \\(Kp(p+1)/2\\) parámetros. Si asumimos que las \\(K\\) clases comparten la misma matriz de covarianza, el modelo de LDA es lineal en \\(x\\), lo que significa que se debe estimar \\(Kp\\) parámetros.\nEn general, el discriminante lineal es menos flexible que su contraparte cuadrática, y tiene una varianza sustancialmente menor. Sin embargo, si el supuesto de igualdad de matrices de covarianza entre las clases es erróneo, provocará que el discriminante lineal tenga un enorme sesgo."
  },
  {
    "objectID": "slides/lec_week7.html#lda-o-qda-continuación",
    "href": "slides/lec_week7.html#lda-o-qda-continuación",
    "title": "Métodos supervisados",
    "section": "¿LDA o QDA?: continuación",
    "text": "¿LDA o QDA?: continuación\nUsualmente, LDA tiende a ser mejor que QDA si se tienen pocas observaciones en el conjunto de entrenamiento, por lo que reducir la varianza es particularmente importante.\nEn contraste, QDA es recomendado si el conjunto de entrenamiento es grande, de manera que la varianza del clasificador no sea tan relevante, o si el supuesto de igual matriz de covarianza en las distintas clases es claramente insostenible."
  },
  {
    "objectID": "slides/lec_week7.html#lda-o-qda-continuación-1",
    "href": "slides/lec_week7.html#lda-o-qda-continuación-1",
    "title": "Métodos supervisados",
    "section": "¿LDA o QDA?: continuación",
    "text": "¿LDA o QDA?: continuación"
  },
  {
    "objectID": "pages/week7.html",
    "href": "pages/week7.html",
    "title": "Semana 7",
    "section": "",
    "text": "Capítulo 1 , Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems. Géron, Aurélien.\nCapítulo 4, An Introduction to Statistical Learning with Applications in R."
  },
  {
    "objectID": "pages/week8.html",
    "href": "pages/week8.html",
    "title": "Semana 8",
    "section": "",
    "text": "Capítulo 3 , Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems. Géron, Aurélien.\nCapítulo 4, An Introduction to Statistical Learning with Applications in R."
  },
  {
    "objectID": "slides/lec_week8.html#k-vecinos-cercanos",
    "href": "slides/lec_week8.html#k-vecinos-cercanos",
    "title": "Métodos supervisados: continuación",
    "section": "K-vecinos cercanos",
    "text": "K-vecinos cercanos\nComo sabemos, un clasificador Bayesiano tiene la forma:\n\\[\n\\mathbb{P}(Y=j|X=x_o)\n\\]\nque es simplemente una probabilidad condicional. Sin embargo, tomamos este clasificador como el idóneo no-obtenible, debido a que nos entrega el error de testeo. En la práctica, este clasificador no es alcanzable debido a que no sabemos la distribución condicional de \\(Y\\) dado \\(X\\)."
  },
  {
    "objectID": "slides/lec_week8.html#rl-vs-lda-vs-qda-vs-knn",
    "href": "slides/lec_week8.html#rl-vs-lda-vs-qda-vs-knn",
    "title": "Métodos supervisados: continuación",
    "section": "RL vs LDA vs QDA vs KNN",
    "text": "RL vs LDA vs QDA vs KNN\nEs natural preguntarse que técnica utilizar en distintas circunstancias, pues todas ellas tienen por finalidad clasificar observaciones. En lo que sigue se lista comentarios respecto a los nexos entre estas metodologías.\n\nDebido a que RL y LDA producen límites de decisión lineales, usualmente entregan resultados similares.\nDebido a los supuestos distribucionales de LDA, si estos se cumplen, suele entregar mejores resultados que una regresión logística. De no cumplirse los supuestos, la regresión puede superar a LDA.\nKNN al tener un enfoque enteramente no-paramétrico, esto es: no asume nada sobre la forma del límite de decisión. Si el límite de decisión es altamente no-lineal, KNN superará a la regresión logística y LDA. Sin embargo, no tendremos información de cuales predictores son importantes."
  },
  {
    "objectID": "slides/lec_week8.html#rl-vs-lda-vs-qda-vs-knn-continuación",
    "href": "slides/lec_week8.html#rl-vs-lda-vs-qda-vs-knn-continuación",
    "title": "Métodos supervisados: continuación",
    "section": "RL vs LDA vs QDA vs KNN: continuación",
    "text": "RL vs LDA vs QDA vs KNN: continuación\n\nQDA puede ser visto como un punto medio entre KNN y LDA/RL. Como el QDA asume un límite de decisión cuadrático, puede modelar más problemas que al asumir linealidad.\nSi bien QDA no es tan flexible como KNN, puede entregar mejores resultados bajo un número limitado de observaciones de entrenamiento debido a que se hacen ciertos supuestos sobre la forma del límite de decisión."
  },
  {
    "objectID": "slides/lec_week8.html#ejemplos-para-un-mismo-conjunto-de-datos",
    "href": "slides/lec_week8.html#ejemplos-para-un-mismo-conjunto-de-datos",
    "title": "Métodos supervisados: continuación",
    "section": "Ejemplos para un mismo conjunto de datos",
    "text": "Ejemplos para un mismo conjunto de datos\nUtilizaremos un conjunto de datos de rendimientos porcentuales de las acciones S&P 500 a lo largo de 1250 días, desde principios de 2001 hasta finales de 2005. Para cada día, se registraron los rendimientos porcentuals para cada uno de los 5 días hábiles previos (lag1 a lag5). También se registró el volumen de acciones tranzadas en el día anterior (en billones) (variable Volume), el rendimiento porcentual del día en cuestión (variable Today) y la dirección, que representa si el mercado va hacia la alta o baja.\n\nlibrary(ISLR)\nnames(Smarket)\n\n[1] \"Year\"      \"Lag1\"      \"Lag2\"      \"Lag3\"      \"Lag4\"      \"Lag5\"     \n[7] \"Volume\"    \"Today\"     \"Direction\"\n\ndim(Smarket)\n\n[1] 1250    9\n\nhead(Smarket)\n\n  Year   Lag1   Lag2   Lag3   Lag4   Lag5 Volume  Today Direction\n1 2001  0.381 -0.192 -2.624 -1.055  5.010 1.1913  0.959        Up\n2 2001  0.959  0.381 -0.192 -2.624 -1.055 1.2965  1.032        Up\n3 2001  1.032  0.959  0.381 -0.192 -2.624 1.4112 -0.623      Down\n4 2001 -0.623  1.032  0.959  0.381 -0.192 1.2760  0.614        Up\n5 2001  0.614 -0.623  1.032  0.959  0.381 1.2057  0.213        Up\n6 2001  0.213  0.614 -0.623  1.032  0.959 1.3491  1.392        Up"
  },
  {
    "objectID": "slides/lec_week8.html#ejemplo-continuación",
    "href": "slides/lec_week8.html#ejemplo-continuación",
    "title": "Métodos supervisados: continuación",
    "section": "Ejemplo: continuación",
    "text": "Ejemplo: continuación\n\nHigh=as.factor(ifelse(Sales<=8,\"No\",\"Yes\"))\nCarseats=data.frame(Carseats,High)\nCarseats_tree=tree(High~ . -Sales, data=Carseats)\nsummary(Carseats_tree)\n\n\nClassification tree:\ntree(formula = High ~ . - Sales, data = Carseats)\nVariables actually used in tree construction:\n[1] \"ShelveLoc\"   \"Price\"       \"Income\"      \"CompPrice\"   \"Population\" \n[6] \"Advertising\" \"Age\"         \"US\"         \nNumber of terminal nodes:  27 \nResidual mean deviance:  0.4575 = 170.7 / 373 \nMisclassification error rate: 0.09 = 36 / 400"
  },
  {
    "objectID": "slides/lec_week8.html#ejemplo-continuación-1",
    "href": "slides/lec_week8.html#ejemplo-continuación-1",
    "title": "Métodos supervisados: continuación",
    "section": "Ejemplo: continuación",
    "text": "Ejemplo: continuación\n\nplot(Carseats_tree)\ntext(Carseats_tree, pretty=0)"
  },
  {
    "objectID": "slides/lec_week8.html#ejemplo-continuación-2",
    "href": "slides/lec_week8.html#ejemplo-continuación-2",
    "title": "Métodos supervisados: continuación",
    "section": "Ejemplo: continuación",
    "text": "Ejemplo: continuación\n\n#Alternativa\nlibrary(rpart)\nlibrary(rpart.plot)\nCarseats_tree2<-rpart(formula=High~ . -Sales, data=Carseats)\nsummary(Carseats_tree2)\n\nCall:\nrpart(formula = High ~ . - Sales, data = Carseats)\n  n= 400 \n\n          CP nsplit rel error    xerror       xstd\n1 0.28658537      0 1.0000000 1.0000000 0.05997967\n2 0.10975610      1 0.7134146 0.7134146 0.05547692\n3 0.04573171      2 0.6036585 0.6463415 0.05382112\n4 0.03658537      4 0.5121951 0.6402439 0.05365767\n5 0.02743902      5 0.4756098 0.6158537 0.05298128\n6 0.02439024      7 0.4207317 0.6158537 0.05298128\n7 0.01219512      8 0.3963415 0.6158537 0.05298128\n8 0.01000000     10 0.3719512 0.6219512 0.05315381\n\nVariable importance\n      Price   ShelveLoc         Age Advertising   CompPrice      Income \n         34          25          11          11           9           5 \n Population   Education \n          3           1 \n\nNode number 1: 400 observations,    complexity param=0.2865854\n  predicted class=No   expected loss=0.41  P(node) =1\n    class counts:   236   164\n   probabilities: 0.590 0.410 \n  left son=2 (315 obs) right son=3 (85 obs)\n  Primary splits:\n      ShelveLoc   splits as  LRL,       improve=28.991900, (0 missing)\n      Price       < 92.5  to the right, improve=19.463880, (0 missing)\n      Advertising < 6.5   to the left,  improve=17.277980, (0 missing)\n      Age         < 61.5  to the right, improve= 9.264442, (0 missing)\n      Income      < 60.5  to the left,  improve= 7.249032, (0 missing)\n\nNode number 2: 315 observations,    complexity param=0.1097561\n  predicted class=No   expected loss=0.3111111  P(node) =0.7875\n    class counts:   217    98\n   probabilities: 0.689 0.311 \n  left son=4 (269 obs) right son=5 (46 obs)\n  Primary splits:\n      Price       < 92.5  to the right, improve=15.930580, (0 missing)\n      Advertising < 7.5   to the left,  improve=11.432570, (0 missing)\n      ShelveLoc   splits as  L-R,       improve= 7.543912, (0 missing)\n      Age         < 50.5  to the right, improve= 6.369905, (0 missing)\n      Income      < 60.5  to the left,  improve= 5.984509, (0 missing)\n  Surrogate splits:\n      CompPrice < 95.5  to the right, agree=0.873, adj=0.13, (0 split)\n\nNode number 3: 85 observations,    complexity param=0.03658537\n  predicted class=Yes  expected loss=0.2235294  P(node) =0.2125\n    class counts:    19    66\n   probabilities: 0.224 0.776 \n  left son=6 (12 obs) right son=7 (73 obs)\n  Primary splits:\n      Price       < 142.5 to the right, improve=7.745608, (0 missing)\n      US          splits as  LR,        improve=5.112440, (0 missing)\n      Income      < 35    to the left,  improve=4.529433, (0 missing)\n      Advertising < 6     to the left,  improve=3.739996, (0 missing)\n      Education   < 15.5  to the left,  improve=2.565856, (0 missing)\n  Surrogate splits:\n      CompPrice < 154.5 to the right, agree=0.882, adj=0.167, (0 split)\n\nNode number 4: 269 observations,    complexity param=0.04573171\n  predicted class=No   expected loss=0.2453532  P(node) =0.6725\n    class counts:   203    66\n   probabilities: 0.755 0.245 \n  left son=8 (224 obs) right son=9 (45 obs)\n  Primary splits:\n      Advertising < 13.5  to the left,  improve=10.400090, (0 missing)\n      Age         < 49.5  to the right, improve= 8.083998, (0 missing)\n      ShelveLoc   splits as  L-R,       improve= 7.023150, (0 missing)\n      CompPrice   < 124.5 to the left,  improve= 6.749986, (0 missing)\n      Price       < 126.5 to the right, improve= 5.646063, (0 missing)\n\nNode number 5: 46 observations,    complexity param=0.02439024\n  predicted class=Yes  expected loss=0.3043478  P(node) =0.115\n    class counts:    14    32\n   probabilities: 0.304 0.696 \n  left son=10 (10 obs) right son=11 (36 obs)\n  Primary splits:\n      Income      < 57    to the left,  improve=4.000483, (0 missing)\n      ShelveLoc   splits as  L-R,       improve=3.189762, (0 missing)\n      Advertising < 9.5   to the left,  improve=1.388592, (0 missing)\n      Price       < 80.5  to the right, improve=1.388592, (0 missing)\n      Age         < 64.5  to the right, improve=1.172885, (0 missing)\n\nNode number 6: 12 observations\n  predicted class=No   expected loss=0.25  P(node) =0.03\n    class counts:     9     3\n   probabilities: 0.750 0.250 \n\nNode number 7: 73 observations\n  predicted class=Yes  expected loss=0.1369863  P(node) =0.1825\n    class counts:    10    63\n   probabilities: 0.137 0.863 \n\nNode number 8: 224 observations,    complexity param=0.02743902\n  predicted class=No   expected loss=0.1830357  P(node) =0.56\n    class counts:   183    41\n   probabilities: 0.817 0.183 \n  left son=16 (96 obs) right son=17 (128 obs)\n  Primary splits:\n      CompPrice   < 124.5 to the left,  improve=4.881696, (0 missing)\n      Age         < 49.5  to the right, improve=3.960418, (0 missing)\n      ShelveLoc   splits as  L-R,       improve=3.654633, (0 missing)\n      Price       < 126.5 to the right, improve=3.234428, (0 missing)\n      Advertising < 6.5   to the left,  improve=2.371276, (0 missing)\n  Surrogate splits:\n      Price      < 115.5 to the left,  agree=0.741, adj=0.396, (0 split)\n      Age        < 50.5  to the right, agree=0.634, adj=0.146, (0 split)\n      Population < 405   to the right, agree=0.629, adj=0.135, (0 split)\n      Education  < 11.5  to the left,  agree=0.585, adj=0.031, (0 split)\n      Income     < 22.5  to the left,  agree=0.580, adj=0.021, (0 split)\n\nNode number 9: 45 observations,    complexity param=0.04573171\n  predicted class=Yes  expected loss=0.4444444  P(node) =0.1125\n    class counts:    20    25\n   probabilities: 0.444 0.556 \n  left son=18 (20 obs) right son=19 (25 obs)\n  Primary splits:\n      Age       < 54.5  to the right, improve=6.722222, (0 missing)\n      CompPrice < 121.5 to the left,  improve=4.629630, (0 missing)\n      ShelveLoc splits as  L-R,       improve=3.250794, (0 missing)\n      Income    < 99.5  to the left,  improve=3.050794, (0 missing)\n      Price     < 127   to the right, improve=2.933429, (0 missing)\n  Surrogate splits:\n      Population  < 363.5 to the left,  agree=0.667, adj=0.25, (0 split)\n      Income      < 39    to the left,  agree=0.644, adj=0.20, (0 split)\n      Advertising < 17.5  to the left,  agree=0.644, adj=0.20, (0 split)\n      CompPrice   < 106.5 to the left,  agree=0.622, adj=0.15, (0 split)\n      Price       < 135.5 to the right, agree=0.622, adj=0.15, (0 split)\n\nNode number 10: 10 observations\n  predicted class=No   expected loss=0.3  P(node) =0.025\n    class counts:     7     3\n   probabilities: 0.700 0.300 \n\nNode number 11: 36 observations\n  predicted class=Yes  expected loss=0.1944444  P(node) =0.09\n    class counts:     7    29\n   probabilities: 0.194 0.806 \n\nNode number 16: 96 observations\n  predicted class=No   expected loss=0.0625  P(node) =0.24\n    class counts:    90     6\n   probabilities: 0.938 0.062 \n\nNode number 17: 128 observations,    complexity param=0.02743902\n  predicted class=No   expected loss=0.2734375  P(node) =0.32\n    class counts:    93    35\n   probabilities: 0.727 0.273 \n  left son=34 (107 obs) right son=35 (21 obs)\n  Primary splits:\n      Price     < 109.5 to the right, improve=9.764582, (0 missing)\n      ShelveLoc splits as  L-R,       improve=6.320022, (0 missing)\n      Age       < 49.5  to the right, improve=2.575061, (0 missing)\n      Income    < 108.5 to the right, improve=1.799546, (0 missing)\n      CompPrice < 143.5 to the left,  improve=1.741982, (0 missing)\n\nNode number 18: 20 observations\n  predicted class=No   expected loss=0.25  P(node) =0.05\n    class counts:    15     5\n   probabilities: 0.750 0.250 \n\nNode number 19: 25 observations\n  predicted class=Yes  expected loss=0.2  P(node) =0.0625\n    class counts:     5    20\n   probabilities: 0.200 0.800 \n\nNode number 34: 107 observations,    complexity param=0.01219512\n  predicted class=No   expected loss=0.1869159  P(node) =0.2675\n    class counts:    87    20\n   probabilities: 0.813 0.187 \n  left son=68 (65 obs) right son=69 (42 obs)\n  Primary splits:\n      Price     < 126.5 to the right, improve=2.9643900, (0 missing)\n      CompPrice < 147.5 to the left,  improve=2.2337090, (0 missing)\n      ShelveLoc splits as  L-R,       improve=2.2125310, (0 missing)\n      Age       < 49.5  to the right, improve=2.1458210, (0 missing)\n      Income    < 60.5  to the left,  improve=0.8025853, (0 missing)\n  Surrogate splits:\n      CompPrice   < 129.5 to the right, agree=0.664, adj=0.143, (0 split)\n      Advertising < 3.5   to the right, agree=0.664, adj=0.143, (0 split)\n      Population  < 53.5  to the right, agree=0.645, adj=0.095, (0 split)\n      Age         < 77.5  to the left,  agree=0.636, adj=0.071, (0 split)\n      US          splits as  RL,        agree=0.626, adj=0.048, (0 split)\n\nNode number 35: 21 observations\n  predicted class=Yes  expected loss=0.2857143  P(node) =0.0525\n    class counts:     6    15\n   probabilities: 0.286 0.714 \n\nNode number 68: 65 observations\n  predicted class=No   expected loss=0.09230769  P(node) =0.1625\n    class counts:    59     6\n   probabilities: 0.908 0.092 \n\nNode number 69: 42 observations,    complexity param=0.01219512\n  predicted class=No   expected loss=0.3333333  P(node) =0.105\n    class counts:    28    14\n   probabilities: 0.667 0.333 \n  left son=138 (22 obs) right son=139 (20 obs)\n  Primary splits:\n      Age         < 49.5  to the right, improve=5.4303030, (0 missing)\n      CompPrice   < 137.5 to the left,  improve=2.1000000, (0 missing)\n      Advertising < 5.5   to the left,  improve=1.8666670, (0 missing)\n      ShelveLoc   splits as  L-R,       improve=1.4291670, (0 missing)\n      Population  < 382   to the right, improve=0.8578431, (0 missing)\n  Surrogate splits:\n      Income      < 46.5  to the left,  agree=0.595, adj=0.15, (0 split)\n      Education   < 12.5  to the left,  agree=0.595, adj=0.15, (0 split)\n      CompPrice   < 131.5 to the right, agree=0.571, adj=0.10, (0 split)\n      Advertising < 5.5   to the left,  agree=0.571, adj=0.10, (0 split)\n      Population  < 221.5 to the left,  agree=0.571, adj=0.10, (0 split)\n\nNode number 138: 22 observations\n  predicted class=No   expected loss=0.09090909  P(node) =0.055\n    class counts:    20     2\n   probabilities: 0.909 0.091 \n\nNode number 139: 20 observations\n  predicted class=Yes  expected loss=0.4  P(node) =0.05\n    class counts:     8    12\n   probabilities: 0.400 0.600"
  },
  {
    "objectID": "slides/lec_week8.html#ejemplo-continuación-3",
    "href": "slides/lec_week8.html#ejemplo-continuación-3",
    "title": "Métodos supervisados: continuación",
    "section": "Ejemplo: continuación",
    "text": "Ejemplo: continuación\n\ntree_plot<-rpart.plot(Carseats_tree2)"
  },
  {
    "objectID": "slides/lec_week8.html#análisis-exploratorio",
    "href": "slides/lec_week8.html#análisis-exploratorio",
    "title": "Métodos supervisados: continuación",
    "section": "Análisis exploratorio",
    "text": "Análisis exploratorio\n\nlibrary(ggplot2)\ncor(Smarket[,-9])\n\n             Year         Lag1         Lag2         Lag3         Lag4\nYear   1.00000000  0.029699649  0.030596422  0.033194581  0.035688718\nLag1   0.02969965  1.000000000 -0.026294328 -0.010803402 -0.002985911\nLag2   0.03059642 -0.026294328  1.000000000 -0.025896670 -0.010853533\nLag3   0.03319458 -0.010803402 -0.025896670  1.000000000 -0.024051036\nLag4   0.03568872 -0.002985911 -0.010853533 -0.024051036  1.000000000\nLag5   0.02978799 -0.005674606 -0.003557949 -0.018808338 -0.027083641\nVolume 0.53900647  0.040909908 -0.043383215 -0.041823686 -0.048414246\nToday  0.03009523 -0.026155045 -0.010250033 -0.002447647 -0.006899527\n               Lag5      Volume        Today\nYear    0.029787995  0.53900647  0.030095229\nLag1   -0.005674606  0.04090991 -0.026155045\nLag2   -0.003557949 -0.04338321 -0.010250033\nLag3   -0.018808338 -0.04182369 -0.002447647\nLag4   -0.027083641 -0.04841425 -0.006899527\nLag5    1.000000000 -0.02200231 -0.034860083\nVolume -0.022002315  1.00000000  0.014591823\nToday  -0.034860083  0.01459182  1.000000000"
  },
  {
    "objectID": "slides/lec_week8.html#análisis-exploratorio-continuación",
    "href": "slides/lec_week8.html#análisis-exploratorio-continuación",
    "title": "Métodos supervisados: continuación",
    "section": "Análisis exploratorio: continuación",
    "text": "Análisis exploratorio: continuación\n\nlibrary(ggplot2)\ncor(Smarket[,-9])\n\n             Year         Lag1         Lag2         Lag3         Lag4\nYear   1.00000000  0.029699649  0.030596422  0.033194581  0.035688718\nLag1   0.02969965  1.000000000 -0.026294328 -0.010803402 -0.002985911\nLag2   0.03059642 -0.026294328  1.000000000 -0.025896670 -0.010853533\nLag3   0.03319458 -0.010803402 -0.025896670  1.000000000 -0.024051036\nLag4   0.03568872 -0.002985911 -0.010853533 -0.024051036  1.000000000\nLag5   0.02978799 -0.005674606 -0.003557949 -0.018808338 -0.027083641\nVolume 0.53900647  0.040909908 -0.043383215 -0.041823686 -0.048414246\nToday  0.03009523 -0.026155045 -0.010250033 -0.002447647 -0.006899527\n               Lag5      Volume        Today\nYear    0.029787995  0.53900647  0.030095229\nLag1   -0.005674606  0.04090991 -0.026155045\nLag2   -0.003557949 -0.04338321 -0.010250033\nLag3   -0.018808338 -0.04182369 -0.002447647\nLag4   -0.027083641 -0.04841425 -0.006899527\nLag5    1.000000000 -0.02200231 -0.034860083\nVolume -0.022002315  1.00000000  0.014591823\nToday  -0.034860083  0.01459182  1.000000000"
  },
  {
    "objectID": "slides/lec_week8.html#análisis-exploratorio-continuación-1",
    "href": "slides/lec_week8.html#análisis-exploratorio-continuación-1",
    "title": "Métodos supervisados: continuación",
    "section": "Análisis exploratorio: continuación",
    "text": "Análisis exploratorio: continuación\n\nlibrary(DataExplorer)\nplot_correlation(Smarket[,-9])"
  },
  {
    "objectID": "slides/lec_week8.html#regresión-logística",
    "href": "slides/lec_week8.html#regresión-logística",
    "title": "Métodos supervisados: continuación",
    "section": "Regresión logística",
    "text": "Regresión logística\n\nglm.fit=glm(Direction~Lag1+Lag2+Lag3+Lag4+Lag5+Volume,data = Smarket , family = binomial )\nsummary(glm.fit)\n\n\nCall:\nglm(formula = Direction ~ Lag1 + Lag2 + Lag3 + Lag4 + Lag5 + \n    Volume, family = binomial, data = Smarket)\n\nDeviance Residuals: \n   Min      1Q  Median      3Q     Max  \n-1.446  -1.203   1.065   1.145   1.326  \n\nCoefficients:\n             Estimate Std. Error z value Pr(>|z|)\n(Intercept) -0.126000   0.240736  -0.523    0.601\nLag1        -0.073074   0.050167  -1.457    0.145\nLag2        -0.042301   0.050086  -0.845    0.398\nLag3         0.011085   0.049939   0.222    0.824\nLag4         0.009359   0.049974   0.187    0.851\nLag5         0.010313   0.049511   0.208    0.835\nVolume       0.135441   0.158360   0.855    0.392\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1731.2  on 1249  degrees of freedom\nResidual deviance: 1727.6  on 1243  degrees of freedom\nAIC: 1741.6\n\nNumber of Fisher Scoring iterations: 3"
  },
  {
    "objectID": "slides/lec_week8.html#regresión-logística-continuación",
    "href": "slides/lec_week8.html#regresión-logística-continuación",
    "title": "Métodos supervisados: continuación",
    "section": "Regresión logística: continuación",
    "text": "Regresión logística: continuación\n\nglm.probs=predict(glm.fit,type=\"response\")\nglm.probs[1:10]\n\n        1         2         3         4         5         6         7         8 \n0.5070841 0.4814679 0.4811388 0.5152224 0.5107812 0.5069565 0.4926509 0.5092292 \n        9        10 \n0.5176135 0.4888378 \n\ncontrasts(Direction)\n\n     Up\nDown  0\nUp    1\n\nglm.pred=rep(\"Down\",1250)\nglm.pred[glm.probs>.5]=\"Up\"\ntable(glm.pred,Direction)\n\n        Direction\nglm.pred Down  Up\n    Down  145 141\n    Up    457 507\n\n(507+145)/1250\n\n[1] 0.5216\n\nmean(glm.pred==Direction)\n\n[1] 0.5216"
  },
  {
    "objectID": "slides/lec_week8.html#regresión-logística-continuación-1",
    "href": "slides/lec_week8.html#regresión-logística-continuación-1",
    "title": "Métodos supervisados: continuación",
    "section": "Regresión logística: continuación",
    "text": "Regresión logística: continuación\n\nlibrary(caret)\nconfusionMatrix(table(glm.probs >= 0.5, Smarket$Direction == \"Up\"))\n\nConfusion Matrix and Statistics\n\n       \n        FALSE TRUE\n  FALSE   145  141\n  TRUE    457  507\n                                          \n               Accuracy : 0.5216          \n                 95% CI : (0.4935, 0.5496)\n    No Information Rate : 0.5184          \n    P-Value [Acc > NIR] : 0.4216          \n                                          \n                  Kappa : 0.0237          \n                                          \n Mcnemar's Test P-Value : <2e-16          \n                                          \n            Sensitivity : 0.2409          \n            Specificity : 0.7824          \n         Pos Pred Value : 0.5070          \n         Neg Pred Value : 0.5259          \n             Prevalence : 0.4816          \n         Detection Rate : 0.1160          \n   Detection Prevalence : 0.2288          \n      Balanced Accuracy : 0.5116          \n                                          \n       'Positive' Class : FALSE"
  },
  {
    "objectID": "slides/lec_week8.html#regresión-logística-continuación-2",
    "href": "slides/lec_week8.html#regresión-logística-continuación-2",
    "title": "Métodos supervisados: continuación",
    "section": "Regresión logística: continuación",
    "text": "Regresión logística: continuación\n\ntrain=(Year <2005)\nSmarket.2005=Smarket[!train,]\ndim(Smarket.2005)\n\n[1] 252   9\n\nDirection.2005=Direction[!train]\nglm.fit=glm(Direction~Lag1+Lag2+Lag3+Lag4+Lag5+Volume,data = Smarket, family = binomial, subset = train)\nglm.probs=predict(glm.fit,Smarket.2005,type=\"response\")\nglm.pred=rep(\"Down\",252)\nglm.pred[glm.probs >.5]=\"Up\"\ntable(glm.pred, Direction.2005)\n\n        Direction.2005\nglm.pred Down Up\n    Down   77 97\n    Up     34 44\n\nmean(glm.pred==Direction.2005)\n\n[1] 0.4801587\n\nmean(glm.pred!=Direction.2005)\n\n[1] 0.5198413"
  },
  {
    "objectID": "slides/lec_week8.html#regresión-logística-continuación-3",
    "href": "slides/lec_week8.html#regresión-logística-continuación-3",
    "title": "Métodos supervisados: continuación",
    "section": "Regresión logística: continuación",
    "text": "Regresión logística: continuación\n\nconfusionMatrix(table(glm.probs >= 0.5, Smarket.2005$Direction == \"Up\"))\n\nConfusion Matrix and Statistics\n\n       \n        FALSE TRUE\n  FALSE    77   97\n  TRUE     34   44\n                                         \n               Accuracy : 0.4802         \n                 95% CI : (0.417, 0.5437)\n    No Information Rate : 0.5595         \n    P-Value [Acc > NIR] : 0.9952         \n                                         \n                  Kappa : 0.0054         \n                                         \n Mcnemar's Test P-Value : 6.062e-08      \n                                         \n            Sensitivity : 0.6937         \n            Specificity : 0.3121         \n         Pos Pred Value : 0.4425         \n         Neg Pred Value : 0.5641         \n             Prevalence : 0.4405         \n         Detection Rate : 0.3056         \n   Detection Prevalence : 0.6905         \n      Balanced Accuracy : 0.5029         \n                                         \n       'Positive' Class : FALSE"
  },
  {
    "objectID": "slides/lec_week8.html#regresión-logística-continuación-4",
    "href": "slides/lec_week8.html#regresión-logística-continuación-4",
    "title": "Métodos supervisados: continuación",
    "section": "Regresión logística: continuación",
    "text": "Regresión logística: continuación\n\nglm.fit=glm(Direction~Lag1+Lag2,data=Smarket,family=binomial,subset=train)\nglm.probs=predict(glm.fit,Smarket.2005,type=\"response\")\nglm.pred=rep(\"Down\",252)\nglm.pred[glm.probs >.5]=\"Up\"\ntable(glm.pred,Direction.2005)\n\n        Direction.2005\nglm.pred Down  Up\n    Down   35  35\n    Up     76 106\n\nmean(glm.pred==Direction.2005)\n\n[1] 0.5595238\n\n106/(106+76)\n\n[1] 0.5824176"
  },
  {
    "objectID": "slides/lec_week8.html#regresión-logística-continuación-5",
    "href": "slides/lec_week8.html#regresión-logística-continuación-5",
    "title": "Métodos supervisados: continuación",
    "section": "Regresión logística: continuación",
    "text": "Regresión logística: continuación\n\nconfusionMatrix(table(glm.probs >= 0.5, Smarket.2005$Direction == \"Up\"))\n\nConfusion Matrix and Statistics\n\n       \n        FALSE TRUE\n  FALSE    35   35\n  TRUE     76  106\n                                          \n               Accuracy : 0.5595          \n                 95% CI : (0.4959, 0.6218)\n    No Information Rate : 0.5595          \n    P-Value [Acc > NIR] : 0.5262856       \n                                          \n                  Kappa : 0.0698          \n                                          \n Mcnemar's Test P-Value : 0.0001467       \n                                          \n            Sensitivity : 0.3153          \n            Specificity : 0.7518          \n         Pos Pred Value : 0.5000          \n         Neg Pred Value : 0.5824          \n             Prevalence : 0.4405          \n         Detection Rate : 0.1389          \n   Detection Prevalence : 0.2778          \n      Balanced Accuracy : 0.5335          \n                                          \n       'Positive' Class : FALSE           \n                                          \n\npredict(glm.fit,newdata=data.frame(Lag1=c(1.2,1.5),Lag2=c(1.1,-0.8)), type=\"response\")\n\n        1         2 \n0.4791462 0.4960939"
  },
  {
    "objectID": "slides/lec_week8.html#regresión-logística-continuación-6",
    "href": "slides/lec_week8.html#regresión-logística-continuación-6",
    "title": "Métodos supervisados: continuación",
    "section": "Regresión logística: continuación",
    "text": "Regresión logística: continuación"
  },
  {
    "objectID": "slides/lec_week8.html#análisis-discriminante-lineal",
    "href": "slides/lec_week8.html#análisis-discriminante-lineal",
    "title": "Métodos supervisados: continuación",
    "section": "Análisis discriminante lineal",
    "text": "Análisis discriminante lineal\n\nlibrary(MASS)\nlda.fit=lda(Direction~Lag1+Lag2,data=Smarket,subset=train)\nlda.fit\n\nCall:\nlda(Direction ~ Lag1 + Lag2, data = Smarket, subset = train)\n\nPrior probabilities of groups:\n    Down       Up \n0.491984 0.508016 \n\nGroup means:\n            Lag1        Lag2\nDown  0.04279022  0.03389409\nUp   -0.03954635 -0.03132544\n\nCoefficients of linear discriminants:\n            LD1\nLag1 -0.6420190\nLag2 -0.5135293"
  },
  {
    "objectID": "slides/lec_week8.html#análisis-discriminante-lineal-continuación",
    "href": "slides/lec_week8.html#análisis-discriminante-lineal-continuación",
    "title": "Métodos supervisados: continuación",
    "section": "Análisis discriminante lineal: continuación",
    "text": "Análisis discriminante lineal: continuación\n\nplot(lda.fit)"
  },
  {
    "objectID": "slides/lec_week8.html#análisis-discriminante-lineal-continuación-1",
    "href": "slides/lec_week8.html#análisis-discriminante-lineal-continuación-1",
    "title": "Métodos supervisados: continuación",
    "section": "Análisis discriminante lineal: continuación",
    "text": "Análisis discriminante lineal: continuación\n\nlda.pred=predict(lda.fit,Smarket.2005)\nnames(lda.pred)\n\n[1] \"class\"     \"posterior\" \"x\"        \n\nlda.class=lda.pred$class\ntable(lda.class,Direction.2005)\n\n         Direction.2005\nlda.class Down  Up\n     Down   35  35\n     Up     76 106\n\nmean(lda.class==Direction.2005)\n\n[1] 0.5595238"
  },
  {
    "objectID": "slides/lec_week8.html#análisis-discriminante-lineal-continuación-2",
    "href": "slides/lec_week8.html#análisis-discriminante-lineal-continuación-2",
    "title": "Métodos supervisados: continuación",
    "section": "Análisis discriminante lineal: continuación",
    "text": "Análisis discriminante lineal: continuación\n\nconfusionMatrix(table(lda.class,Direction.2005))\n\nConfusion Matrix and Statistics\n\n         Direction.2005\nlda.class Down  Up\n     Down   35  35\n     Up     76 106\n                                          \n               Accuracy : 0.5595          \n                 95% CI : (0.4959, 0.6218)\n    No Information Rate : 0.5595          \n    P-Value [Acc > NIR] : 0.5262856       \n                                          \n                  Kappa : 0.0698          \n                                          \n Mcnemar's Test P-Value : 0.0001467       \n                                          \n            Sensitivity : 0.3153          \n            Specificity : 0.7518          \n         Pos Pred Value : 0.5000          \n         Neg Pred Value : 0.5824          \n             Prevalence : 0.4405          \n         Detection Rate : 0.1389          \n   Detection Prevalence : 0.2778          \n      Balanced Accuracy : 0.5335          \n                                          \n       'Positive' Class : Down"
  },
  {
    "objectID": "slides/lec_week8.html#análisis-discriminante-lineal-continuación-3",
    "href": "slides/lec_week8.html#análisis-discriminante-lineal-continuación-3",
    "title": "Métodos supervisados: continuación",
    "section": "Análisis discriminante lineal: continuación",
    "text": "Análisis discriminante lineal: continuación\n\n# Aplicando un umbral del 50%\nsum(lda.pred$posterior[,1] >=.5)\n\n[1] 70\n\nsum(lda.pred$posterior[,1] <.5)\n\n[1] 182\n\n# Primeros 20 datos\nlda.pred$posterior[1:20,1]\n\n      999      1000      1001      1002      1003      1004      1005      1006 \n0.4901792 0.4792185 0.4668185 0.4740011 0.4927877 0.4938562 0.4951016 0.4872861 \n     1007      1008      1009      1010      1011      1012      1013      1014 \n0.4907013 0.4844026 0.4906963 0.5119988 0.4895152 0.4706761 0.4744593 0.4799583 \n     1015      1016      1017      1018 \n0.4935775 0.5030894 0.4978806 0.4886331 \n\nlda.class[1:20]\n\n [1] Up   Up   Up   Up   Up   Up   Up   Up   Up   Up   Up   Down Up   Up   Up  \n[16] Up   Up   Down Up   Up  \nLevels: Down Up\n\n# Aplicando un umbral del 90%\nsum(lda.pred$posterior[,1] >.9)\n\n[1] 0"
  },
  {
    "objectID": "slides/lec_week8.html#análisis-discriminante-cuadrático",
    "href": "slides/lec_week8.html#análisis-discriminante-cuadrático",
    "title": "Métodos supervisados: continuación",
    "section": "Análisis discriminante cuadrático",
    "text": "Análisis discriminante cuadrático\n\nqda.fit=qda(Direction~Lag1+Lag2,data=Smarket,subset=train)\nqda.fit\n\nCall:\nqda(Direction ~ Lag1 + Lag2, data = Smarket, subset = train)\n\nPrior probabilities of groups:\n    Down       Up \n0.491984 0.508016 \n\nGroup means:\n            Lag1        Lag2\nDown  0.04279022  0.03389409\nUp   -0.03954635 -0.03132544\n\nqda.class=predict(qda.fit,Smarket.2005)$class\ntable(qda.class,Direction.2005)\n\n         Direction.2005\nqda.class Down  Up\n     Down   30  20\n     Up     81 121\n\nmean(qda.class==Direction.2005)\n\n[1] 0.5992063"
  },
  {
    "objectID": "slides/lec_week8.html#análisis-discriminante-cuadrático-continuación",
    "href": "slides/lec_week8.html#análisis-discriminante-cuadrático-continuación",
    "title": "Métodos supervisados: continuación",
    "section": "Análisis discriminante cuadrático: continuación",
    "text": "Análisis discriminante cuadrático: continuación\n\nconfusionMatrix(table(qda.class,Direction.2005))\n\nConfusion Matrix and Statistics\n\n         Direction.2005\nqda.class Down  Up\n     Down   30  20\n     Up     81 121\n                                          \n               Accuracy : 0.5992          \n                 95% CI : (0.5358, 0.6602)\n    No Information Rate : 0.5595          \n    P-Value [Acc > NIR] : 0.1138          \n                                          \n                  Kappa : 0.1364          \n                                          \n Mcnemar's Test P-Value : 2.369e-09       \n                                          \n            Sensitivity : 0.2703          \n            Specificity : 0.8582          \n         Pos Pred Value : 0.6000          \n         Neg Pred Value : 0.5990          \n             Prevalence : 0.4405          \n         Detection Rate : 0.1190          \n   Detection Prevalence : 0.1984          \n      Balanced Accuracy : 0.5642          \n                                          \n       'Positive' Class : Down"
  },
  {
    "objectID": "slides/lec_week8.html#k-vecinos-cercanos-1",
    "href": "slides/lec_week8.html#k-vecinos-cercanos-1",
    "title": "Métodos supervisados: continuación",
    "section": "K-vecinos cercanos",
    "text": "K-vecinos cercanos\n\nlibrary(class)\ntrain.X=cbind(Lag1,Lag2)[train,]\ntest.X=cbind(Lag1,Lag2)[!train,]\ntrain.Direction=Direction[train]\nhead(train.X)\n\n       Lag1   Lag2\n[1,]  0.381 -0.192\n[2,]  0.959  0.381\n[3,]  1.032  0.959\n[4,] -0.623  1.032\n[5,]  0.614 -0.623\n[6,]  0.213  0.614\n\nknn.pred=knn(train.X,test.X,train.Direction,k=1)\ntable(knn.pred,Direction.2005)\n\n        Direction.2005\nknn.pred Down Up\n    Down   43 58\n    Up     68 83\n\n(83+43)/252\n\n[1] 0.5"
  },
  {
    "objectID": "slides/lec_week8.html#k-vecinos-cercanos-continuación",
    "href": "slides/lec_week8.html#k-vecinos-cercanos-continuación",
    "title": "Métodos supervisados: continuación",
    "section": "K-vecinos cercanos: continuación",
    "text": "K-vecinos cercanos: continuación\nUna metodología que intenta estimar la probabilidad condicional para luego asignar la clase \\(k-\\)ésima a la observación que tenga la mayor probabilidad condicional es K-vecinos cercanos o KNN por sus siglas en inglés.\nDada un entero positivo \\(K\\), una observación de prueba \\(x_0\\), el clasificador \\(KNN\\) primero identifica los \\(K\\) puntos más cercanos a \\(x_0\\) pertenecientes al conjunto de entrenamiento, representados por \\(\\mathcal{N}_0\\). Luego estima la probabilidad condicional para la clase \\(j-\\)ésima como una fracción de puntos en \\(\\mathcal{N}_0\\) cuyas respuestas son igual a la de \\(j\\), esto es:\n\\[\n\\mathbb{P}(Y=j|X=x_0)=\\dfrac{1}{K}\\sum_{i\\in \\mathcal{N}_0}I(y_i = j)\n\\]\nFinalmente, KNN aplica la regla de Bayes y clasifica la observación de prueba/testeo \\(x_0\\) a la clase con la mayor probabilidad"
  },
  {
    "objectID": "slides/lec_week8.html#k-vecinos-cercanos-continuación-1",
    "href": "slides/lec_week8.html#k-vecinos-cercanos-continuación-1",
    "title": "Métodos supervisados: continuación",
    "section": "K-vecinos cercanos: continuación",
    "text": "K-vecinos cercanos: continuación\n\nconfusionMatrix(table(knn.pred,Direction.2005))\n\nConfusion Matrix and Statistics\n\n        Direction.2005\nknn.pred Down Up\n    Down   43 58\n    Up     68 83\n                                          \n               Accuracy : 0.5             \n                 95% CI : (0.4366, 0.5634)\n    No Information Rate : 0.5595          \n    P-Value [Acc > NIR] : 0.9751          \n                                          \n                  Kappa : -0.0242         \n                                          \n Mcnemar's Test P-Value : 0.4227          \n                                          \n            Sensitivity : 0.3874          \n            Specificity : 0.5887          \n         Pos Pred Value : 0.4257          \n         Neg Pred Value : 0.5497          \n             Prevalence : 0.4405          \n         Detection Rate : 0.1706          \n   Detection Prevalence : 0.4008          \n      Balanced Accuracy : 0.4880          \n                                          \n       'Positive' Class : Down"
  },
  {
    "objectID": "slides/lec_week8.html#k-vecinos-cercanos-continuación-2",
    "href": "slides/lec_week8.html#k-vecinos-cercanos-continuación-2",
    "title": "Métodos supervisados: continuación",
    "section": "K-vecinos cercanos: continuación",
    "text": "K-vecinos cercanos: continuación\n\nknn.pred=knn(train.X,test.X,train.Direction,k=3)\ntable(knn.pred,Direction.2005)\n\n        Direction.2005\nknn.pred Down Up\n    Down   48 55\n    Up     63 86\n\nmean(knn.pred==Direction.2005)\n\n[1] 0.531746"
  },
  {
    "objectID": "slides/lec_week8.html#k-vecinos-cercanos-continuación-3",
    "href": "slides/lec_week8.html#k-vecinos-cercanos-continuación-3",
    "title": "Métodos supervisados: continuación",
    "section": "K-vecinos cercanos: continuación",
    "text": "K-vecinos cercanos: continuación\n\nconfusionMatrix(table(knn.pred,Direction.2005))\n\nConfusion Matrix and Statistics\n\n        Direction.2005\nknn.pred Down Up\n    Down   48 55\n    Up     63 86\n                                          \n               Accuracy : 0.5317          \n                 95% CI : (0.4681, 0.5946)\n    No Information Rate : 0.5595          \n    P-Value [Acc > NIR] : 0.8294          \n                                          \n                  Kappa : 0.0427          \n                                          \n Mcnemar's Test P-Value : 0.5193          \n                                          \n            Sensitivity : 0.4324          \n            Specificity : 0.6099          \n         Pos Pred Value : 0.4660          \n         Neg Pred Value : 0.5772          \n             Prevalence : 0.4405          \n         Detection Rate : 0.1905          \n   Detection Prevalence : 0.4087          \n      Balanced Accuracy : 0.5212          \n                                          \n       'Positive' Class : Down"
  },
  {
    "objectID": "slides/lec_week8.html#ejercicio",
    "href": "slides/lec_week8.html#ejercicio",
    "title": "Métodos supervisados: continuación",
    "section": "Ejercicio",
    "text": "Ejercicio\nRealizar KNN con el conjunto Caravan del paquete ISLR. El conjunto de datos corresponde a 85 predictores que miden características demográficas para 5822 personas, en donde la variable respuesta es Purchase que indica si la persona adquirió un póliza de seguros. Realice el ejercicio con y sin estandarización de variables."
  },
  {
    "objectID": "slides/lec_week8.html#análisis-exploratiorio",
    "href": "slides/lec_week8.html#análisis-exploratiorio",
    "title": "Métodos supervisados: continuación",
    "section": "Análisis exploratiorio",
    "text": "Análisis exploratiorio\n\nlibrary(ISLR)\nnames(Smarket)\n\n[1] \"Year\"      \"Lag1\"      \"Lag2\"      \"Lag3\"      \"Lag4\"      \"Lag5\"     \n[7] \"Volume\"    \"Today\"     \"Direction\"\n\ndim(Smarket)\n\n[1] 1250    9\n\nhead(Smarket)\n\n  Year   Lag1   Lag2   Lag3   Lag4   Lag5 Volume  Today Direction\n1 2001  0.381 -0.192 -2.624 -1.055  5.010 1.1913  0.959        Up\n2 2001  0.959  0.381 -0.192 -2.624 -1.055 1.2965  1.032        Up\n3 2001  1.032  0.959  0.381 -0.192 -2.624 1.4112 -0.623      Down\n4 2001 -0.623  1.032  0.959  0.381 -0.192 1.2760  0.614        Up\n5 2001  0.614 -0.623  1.032  0.959  0.381 1.2057  0.213        Up\n6 2001  0.213  0.614 -0.623  1.032  0.959 1.3491  1.392        Up"
  },
  {
    "objectID": "slides/lec_week8.html#análisis-exploratorio-continuación-2",
    "href": "slides/lec_week8.html#análisis-exploratorio-continuación-2",
    "title": "Métodos supervisados: continuación",
    "section": "Análisis exploratorio: continuación",
    "text": "Análisis exploratorio: continuación\n\nattach(Smarket)\nggplot(Smarket) + aes(x = 1:nrow(Smarket), y = Volume) +geom_point(shape = \"circle\", size = 1.5, colour = \"#4682B4\") +\n  theme_bw()"
  },
  {
    "objectID": "slides/lec_week8.html#definición",
    "href": "slides/lec_week8.html#definición",
    "title": "Métodos supervisados: continuación",
    "section": "Definición",
    "text": "Definición\nEn un árbol de decisión para problemas de clasificación se predice que cada observación pertenece a la clase más frecuente entre las observaciones de entrenamiento en la región a la que pertenece.\nUtilizamos la tasa de error de clasificación para separar los espacios a lo largo del árbol de decisión. Debido a que se planea asignar una observación en una región particular a la clase más frecuente en el conjunto de entrenamiento, este error se define como:\n\\[\nE=1-\\max_{k}(\\hat{p}_{mk})\n\\]\nen donde \\(\\hat{p}_{mk}\\) representa la proporción de observaciones de entrenamiento en la región \\(m-\\)ésima que son de la clase \\(k-\\)ésima."
  },
  {
    "objectID": "slides/lec_week8.html#diagrama-de-ejemplo",
    "href": "slides/lec_week8.html#diagrama-de-ejemplo",
    "title": "Métodos supervisados: continuación",
    "section": "Diagrama de ejemplo",
    "text": "Diagrama de ejemplo"
  },
  {
    "objectID": "slides/lec_week8.html#definición-continuación",
    "href": "slides/lec_week8.html#definición-continuación",
    "title": "Métodos supervisados: continuación",
    "section": "Definición: continuación",
    "text": "Definición: continuación\nEn general, usar sólo la tasa de error de clasifición no es lo suficientemente sensible para esta metodología, y se opta por dos medidas alternativas: índice de Gini y entropía cruzada.\nEl índice de Gini está definido como:\n\\[\nG=\\sum_{k=1}^{K} \\hat{p}_{mk}(1-\\hat{p}_{mk})\n\\]\nque es una medida de la varianza total a lo largo de las \\(K\\) clases. Es claro ver que este índice toma valores pequeños si todos los \\(\\hat{p}_{mk}\\) son cercanos a cero."
  },
  {
    "objectID": "slides/lec_week8.html#definición-continuación-1",
    "href": "slides/lec_week8.html#definición-continuación-1",
    "title": "Métodos supervisados: continuación",
    "section": "Definición: continuación",
    "text": "Definición: continuación\nUna alternativa al índice anterior es la entropía cruzada, dada por:\n\\[\nD=-\\sum_{k=1}^{K} \\hat{p}_{mk}\\log \\hat{p}_{mk}.\n\\]\nDebido a que \\(0 \\leq \\hat{p}_{mk}\\leq 1\\), sigue que \\(0\\leq -\\hat{p}_{mk}\\log\\hat{p}_{mk}\\). Se puede mostrar que la entropía cruzada tomará valores cercanos a cero si todos los \\(\\hat{p}_{mk}\\) están cercano a cero o a uno. Por lo que ambos índices tomaran valores pequeños si la \\(m-\\)ésimo nodo es puro."
  },
  {
    "objectID": "slides/lec_week8.html#ejemplo",
    "href": "slides/lec_week8.html#ejemplo",
    "title": "Métodos supervisados: continuación",
    "section": "Ejemplo",
    "text": "Ejemplo\n\nlibrary(tree)\nattach(Carseats)\nrequire(ISLR)\nhead(Carseats)\n\n  Sales CompPrice Income Advertising Population Price ShelveLoc Age Education\n1  9.50       138     73          11        276   120       Bad  42        17\n2 11.22       111     48          16        260    83      Good  65        10\n3 10.06       113     35          10        269    80    Medium  59        12\n4  7.40       117    100           4        466    97    Medium  55        14\n5  4.15       141     64           3        340   128       Bad  38        13\n6 10.81       124    113          13        501    72       Bad  78        16\n  Urban  US\n1   Yes Yes\n2   Yes Yes\n3   Yes Yes\n4   Yes Yes\n5   Yes  No\n6    No Yes"
  },
  {
    "objectID": "slides/lec_week8.html#ejemplo-continuación-4",
    "href": "slides/lec_week8.html#ejemplo-continuación-4",
    "title": "Métodos supervisados: continuación",
    "section": "Ejemplo: continuación",
    "text": "Ejemplo: continuación\n\nset.seed(2)\ntrain=sample(1:nrow(Carseats), 200)\nCarseats_test=Carseats[-train,]\nHigh_test=High[-train]\nCarseats_tree=tree(High~ .-Sales ,Carseats ,subset = train)\ntree_pred=predict(Carseats_tree ,Carseats_test , type =\"class\")\ntable(tree_pred,High_test)\n\n         High_test\ntree_pred  No Yes\n      No  104  33\n      Yes  13  50\n\n(104+50)/200\n\n[1] 0.77"
  },
  {
    "objectID": "slides/lec_week8.html#ejemplo-continuación-5",
    "href": "slides/lec_week8.html#ejemplo-continuación-5",
    "title": "Métodos supervisados: continuación",
    "section": "Ejemplo: continuación",
    "text": "Ejemplo: continuación\n\nconfusionMatrix(table(tree_pred,High_test))\n\nConfusion Matrix and Statistics\n\n         High_test\ntree_pred  No Yes\n      No  104  33\n      Yes  13  50\n                                          \n               Accuracy : 0.77            \n                 95% CI : (0.7054, 0.8264)\n    No Information Rate : 0.585           \n    P-Value [Acc > NIR] : 2.938e-08       \n                                          \n                  Kappa : 0.5091          \n                                          \n Mcnemar's Test P-Value : 0.005088        \n                                          \n            Sensitivity : 0.8889          \n            Specificity : 0.6024          \n         Pos Pred Value : 0.7591          \n         Neg Pred Value : 0.7937          \n             Prevalence : 0.5850          \n         Detection Rate : 0.5200          \n   Detection Prevalence : 0.6850          \n      Balanced Accuracy : 0.7456          \n                                          \n       'Positive' Class : No"
  },
  {
    "objectID": "pages/week9.html",
    "href": "pages/week9.html",
    "title": "Semana 9",
    "section": "",
    "text": "Capítulo 8 y 9 , Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems. Géron, Aurélien.\nCapítulo 9, An Introduction to Statistical Learning with Applications in R."
  },
  {
    "objectID": "slides/lec_week9.html#clasificador-de-máximo-margen",
    "href": "slides/lec_week9.html#clasificador-de-máximo-margen",
    "title": "Métodos supervisados: continuación",
    "section": "Clasificador de máximo margen",
    "text": "Clasificador de máximo margen\nAntes de definidir el clasificador de máximo margen, debemos introducir dos conceptos primordiales:\n\nHiperplano\nHiperplano de separación óptimo"
  },
  {
    "objectID": "slides/lec_week9.html#hiperplano",
    "href": "slides/lec_week9.html#hiperplano",
    "title": "Métodos supervisados: continuación",
    "section": "Hiperplano",
    "text": "Hiperplano\nEn un espacio \\(p-\\)dimensional, un hiperplano es un subespacio afín plano de dimensión \\(p-1\\). Por ejemplo, en dos dimensiones, un hiperplano es una linea. En tres dimensiones, un hiperplano es un subespacio 2-dimensional plano.\nMatemáticamente, para el caso bidimensional, un hiperplano está definido por la ecuación:\n\\[\n\\beta_0+\\beta_1 X_1 + \\beta_2 X_2 = 0\n\\]\npara parámetros \\(\\beta_0,\\beta_1\\) y \\(\\beta_2\\). Naturalmente, la extensión a \\(p\\) dimensiones es:\n\\[\n\\beta_0+\\beta_1 X_1 +\\beta_2 X_2 + \\dots + \\beta_p X_p =0\n\\]\nque define un hiperplano \\(p-\\)dimensional, en el sentido de que si un punto \\(X=(X_1,X_2,\\dots,X_p)^T\\) en un espacio \\(p-\\)dimensional que satisface la ecuación anterior."
  },
  {
    "objectID": "slides/lec_week9.html#figura-hiperplano",
    "href": "slides/lec_week9.html#figura-hiperplano",
    "title": "Métodos supervisados: continuación",
    "section": "Figura hiperplano",
    "text": "Figura hiperplano"
  },
  {
    "objectID": "slides/lec_week9.html#clasificando-usando-un-hiperplano-separable",
    "href": "slides/lec_week9.html#clasificando-usando-un-hiperplano-separable",
    "title": "Métodos supervisados: continuación",
    "section": "Clasificando usando un hiperplano separable",
    "text": "Clasificando usando un hiperplano separable\nSupongamos que tenemos una matriz de datos \\(\\mathbf{X}\\) de tamaño \\(n\\times p\\) que consiste en \\(n\\) observaciones de entrenamiento en un espacio \\(p-\\)dimensional,\n\\[\nx_1=\\begin{pmatrix}x_{11} \\\\ \\vdots \\\\ x_{1p}\\end{pmatrix} , \\dots,x_n=\\begin{pmatrix} x_{n1} \\\\ \\vdots \\\\ x_{np} \\end{pmatrix}\n\\]\ny que estas observaciones caen dentro de dos clases, esto es, \\(y_1,\\dots,y_n \\in \\{-1,1\\}\\) donde \\(-1\\) representa una clase y \\(1\\) la otra clase. También tenemos una observación de prueba, un \\(p-\\)vector de features observadas \\(x^*=(x_{1}^{*}\\, \\dots \\,x_{p}^{*})^T\\)"
  },
  {
    "objectID": "slides/lec_week9.html#clasificando-usando-un-hiperplano-separable-continuación",
    "href": "slides/lec_week9.html#clasificando-usando-un-hiperplano-separable-continuación",
    "title": "Métodos supervisados: continuación",
    "section": "Clasificando usando un hiperplano separable: continuación",
    "text": "Clasificando usando un hiperplano separable: continuación\nNuestro objetivo es desarrollar un clasificador basado en este conjunto de entrenamiento que clasifique correctamente la observación de prueba usando las variables medidas, para esto nosotros ya hemos visto varias metodologías que podríamos usar: LDA, QDA, árboles de decisión y regresión logística.\nEn lo que sigue veremos una metodología que se basa en el concepto de hiperplano separable."
  },
  {
    "objectID": "slides/lec_week9.html#clasificando-usando-un-hiperplano-separable-continuación-1",
    "href": "slides/lec_week9.html#clasificando-usando-un-hiperplano-separable-continuación-1",
    "title": "Métodos supervisados: continuación",
    "section": "Clasificando usando un hiperplano separable: continuación",
    "text": "Clasificando usando un hiperplano separable: continuación\nSupongamos que es posible construir un hiperplano que separe las observaciones de entrenamiento perfectamente de acuerdo a sus clases. Por lo que si utilizamos las clase como antes (\\(\\{-1,1\\}\\)) se tendrá la propiedad que\n\\[\n\\beta_0+\\beta_1 x_{i1} +\\beta_2 x_{i2}+\\dots+\\beta_p x_{ip} > 0 \\quad \\text{si} \\quad y_i=1\n\\]\ny,\n\\[\n\\beta_0+\\beta_1 x_{i1} +\\beta_2 x_{i2}+\\dots+\\beta_p x_{ip} < 0 \\quad \\text{si} \\quad y_i=-1\n\\]\nequivalentemente, un hiperplano separable tiene la propiedad que:\n\\[\ny_i(\\beta_0 +\\beta_0+\\beta_1 x_{i1} +\\beta_2 x_{i2}+\\dots+\\beta_p x_{ip})>0\n\\]\npara todo \\(i=1,\\dots,n\\)."
  },
  {
    "objectID": "slides/lec_week9.html#clasificando-usando-un-hiperplano-separable-continuación-2",
    "href": "slides/lec_week9.html#clasificando-usando-un-hiperplano-separable-continuación-2",
    "title": "Métodos supervisados: continuación",
    "section": "Clasificando usando un hiperplano separable: continuación",
    "text": "Clasificando usando un hiperplano separable: continuación"
  },
  {
    "objectID": "slides/lec_week9.html#clasificando-usando-un-hiperplano-separable-continuación-3",
    "href": "slides/lec_week9.html#clasificando-usando-un-hiperplano-separable-continuación-3",
    "title": "Métodos supervisados: continuación",
    "section": "Clasificando usando un hiperplano separable: continuación",
    "text": "Clasificando usando un hiperplano separable: continuación\nSi un hiperplano separable existe, podemos usarlo para construir un clasificador bastante natural: una observación de prueba es asignada una clase dependiendo de que lado del hiperplano está ubicada.\nIntuitivamente, podremos estar seguro de nuestra clasificación conforme la magnitud obtenida tras clasificar la observación de prueba."
  },
  {
    "objectID": "slides/lec_week9.html#clasificador-de-margen-máximo",
    "href": "slides/lec_week9.html#clasificador-de-margen-máximo",
    "title": "Métodos supervisados: continuación",
    "section": "Clasificador de margen máximo",
    "text": "Clasificador de margen máximo\nEn general, si nuestros datos pueden ser perfectamente separados un hiperplano, entonces existiran un infinito número de aquellos hiperplanos. Para poder construir un clasificador basado en un hiperplano separable, debemos encontrar una forma razonable de decidir cual de estos infinitos hiperplanos separables usar.\nUna elección natural es el hiperplano de máximo margen (también conocido como hiperplano separable máximo), que es el hiperplano que está más lejos de las observaciones de entrenamiento. Esto es, podemos calcular la distancia (perpendicular) desde cada punto a un hiperplano separable dado; la menor de aquellas distancias es la mínima distancia entre las observaciones y el hiperplano, esta distancia es conocida como margen.\nEl hiperplano de margen máximo es el hiperplano separable en donde el margen es el más grande, esto es, es el hiperplano que tiene la distancia mínima más lejana a las observaciones de entrenamiento.\nLuego, podemos clasificar una observación de prueba basado en que lado del hiperplano de margen máximo recae."
  },
  {
    "objectID": "slides/lec_week9.html#vector-de-soportes",
    "href": "slides/lec_week9.html#vector-de-soportes",
    "title": "Métodos supervisados: continuación",
    "section": "Vector de soportes",
    "text": "Vector de soportes"
  },
  {
    "objectID": "slides/lec_week9.html#construcción-de-un-clasificador-de-margen-máximo",
    "href": "slides/lec_week9.html#construcción-de-un-clasificador-de-margen-máximo",
    "title": "Métodos supervisados: continuación",
    "section": "Construcción de un clasificador de margen máximo",
    "text": "Construcción de un clasificador de margen máximo\nAhora consideramos la tarea de construir el hiperplano de margen máximo basado en un conjunto de \\(n\\) observaciones de entrenamiento \\(x_1,\\dots, x_n \\in \\mathbb{R}^{p}\\) y clases asociadas \\(y_1,\\dots,y_n \\in \\{-1,1\\}\\). En síntesis, este hiperplano es la solución de un problema de optimización dado por:\n\\[\\begin{align*}\n&\\max_{\\beta_0,\\beta_1,\\dots,\\beta_p} \\quad M\\\\\n&\\text{ Sujeto a } \\sum_{j=1}^{p} \\beta_{j}^{2}=1 \\\\\n&y_i(\\beta_0 +\\beta_0+\\beta_1 x_{i1} +\\beta_2 x_{i2}+\\dots+\\beta_p x_{ip})\\geq M \\quad \\forall i=1,\\dots,n\n\\end{align*}\\]"
  },
  {
    "objectID": "slides/lec_week9.html#construcción-de-un-clasificador-de-margen-máximo-continuación",
    "href": "slides/lec_week9.html#construcción-de-un-clasificador-de-margen-máximo-continuación",
    "title": "Métodos supervisados: continuación",
    "section": "Construcción de un clasificador de margen máximo: continuación",
    "text": "Construcción de un clasificador de margen máximo: continuación\n\nlibrary(e1071)\nlibrary(ggplot2)\nset.seed(411)\ncoord <- matrix(rnorm(40), 20, 2)\ncolnames(coord) <- c(\"X1\",\"X2\")\ny <- c(rep(-1,10), rep(1,10))\ncoord[y == 1, ] <- coord[y == 1, ] + 1\ndata <- data.frame(coord, y)\nplot_svm<-ggplot(data = data, aes(x = X1, y = X2, color = as.factor(y))) +\n  geom_point(size = 6) +\n  theme_bw() +\n  theme(legend.position = \"none\")\n\ndata$y <- as.factor(data$y)"
  },
  {
    "objectID": "slides/lec_week9.html#construcción-de-un-clasificador-de-margen-máximo-continuación-1",
    "href": "slides/lec_week9.html#construcción-de-un-clasificador-de-margen-máximo-continuación-1",
    "title": "Métodos supervisados: continuación",
    "section": "Construcción de un clasificador de margen máximo: continuación",
    "text": "Construcción de un clasificador de margen máximo: continuación\n\nmod_svm <- svm(formula = y ~ X1 + X2, data = data, kernel = \"linear\",\n                  cost = 10, scale = FALSE)\nsummary(mod_svm)\n\n\nCall:\nsvm(formula = y ~ X1 + X2, data = data, kernel = \"linear\", cost = 10, \n    scale = FALSE)\n\n\nParameters:\n   SVM-Type:  C-classification \n SVM-Kernel:  linear \n       cost:  10 \n\nNumber of Support Vectors:  8\n\n ( 4 4 )\n\n\nNumber of Classes:  2 \n\nLevels: \n -1 1\n\nmod_svm$index\n\n[1]  1  5  6  8 12 13 15 18"
  },
  {
    "objectID": "slides/lec_week9.html#construcción-de-un-clasificador-de-margen-máximo-continuación-2",
    "href": "slides/lec_week9.html#construcción-de-un-clasificador-de-margen-máximo-continuación-2",
    "title": "Métodos supervisados: continuación",
    "section": "Construcción de un clasificador de margen máximo: continuación",
    "text": "Construcción de un clasificador de margen máximo: continuación\n\nplot(mod_svm, data)"
  },
  {
    "objectID": "slides/lec_week9.html#clasificador-de-vectores-de-soporte",
    "href": "slides/lec_week9.html#clasificador-de-vectores-de-soporte",
    "title": "Métodos supervisados: continuación",
    "section": "Clasificador de vectores de soporte",
    "text": "Clasificador de vectores de soporte"
  },
  {
    "objectID": "slides/lec_week9.html#clasificador-de-vectores-de-soporte-continuación",
    "href": "slides/lec_week9.html#clasificador-de-vectores-de-soporte-continuación",
    "title": "Métodos supervisados: continuación",
    "section": "Clasificador de vectores de soporte: continuación",
    "text": "Clasificador de vectores de soporte: continuación\nEn el caso anterior, un hiperplano separable no existe. En la figura siguiente, la adición de un solo dato provoca un cambio drástico en el margen máximo del hiperplano."
  },
  {
    "objectID": "slides/lec_week9.html#clasificador-de-vectores-de-soporte-continuación-1",
    "href": "slides/lec_week9.html#clasificador-de-vectores-de-soporte-continuación-1",
    "title": "Métodos supervisados: continuación",
    "section": "Clasificador de vectores de soporte: continuación",
    "text": "Clasificador de vectores de soporte: continuación\nEste cambio, reduce la confianza de la asignación de clases. Así, podemos concluir que nuestra metodología es extremadamente sensible a cambio, incluso de sólo una observación.\nEn estos casos, quizás deberíamos considerar un clasificador basado en un hiperplano que no separe perfectamente las dos clases, con el fin de:\n\nTener mayor robustez a las observaciones individuales\nTener mayor clasificación para la mayoría de las observaciones de entrenamiento"
  },
  {
    "objectID": "slides/lec_week9.html#clasificador-de-vectores-de-soporte-continuación-2",
    "href": "slides/lec_week9.html#clasificador-de-vectores-de-soporte-continuación-2",
    "title": "Métodos supervisados: continuación",
    "section": "Clasificador de vectores de soporte: continuación",
    "text": "Clasificador de vectores de soporte: continuación\nAsí, podría ser beneficioso clasificar erróneamente un par de observaciones de entrenamiento para realizar un mejor trabajo clasificando el resto de las observaciones.\nEl clasificador de vectores de soporte (support vector classifier) o aveces llamado soft margin classifier, hace exactamente lo anterior; en vez de buscar el marger más grande tal que cada observación que clasifique perfectamente, permite que ciertas observaciones estén en la lado incorrecto del margen, o del lado incorrecto del hiperplano."
  },
  {
    "objectID": "slides/lec_week9.html#clasificador-de-vectores-de-soporte-continuación-3",
    "href": "slides/lec_week9.html#clasificador-de-vectores-de-soporte-continuación-3",
    "title": "Métodos supervisados: continuación",
    "section": "Clasificador de vectores de soporte: continuación",
    "text": "Clasificador de vectores de soporte: continuación\nMatemáticamente, corresponde a la solución del siguiente problema de optimización:\n\\[\\begin{align*}\n&\\max_{\\beta_0,\\beta_1,\\dots,\\beta_p; \\epsilon_1,\\dots,\\epsilon_n} \\quad M\\\\\n&\\text{ Sujeto a } \\sum_{j=1}^{p} \\beta_{j}^{2}=1 \\\\\n&y_i(\\beta_0 +\\beta_0+\\beta_1 x_{i1} +\\beta_2 x_{i2}+\\dots+\\beta_p x_{ip})\\geq M (1-\\epsilon_i) \\quad \\forall i=1,\\dots,n \\\\\n&\\epsilon_i \\geq 0, \\sum_{i=1}^{n} \\epsilon_i \\leq C\n\\end{align*}\\]\ndonde \\(C\\) es un parámetro de tunning no negativo. Cuando este parámetro es grande, habrá una gran tolerancia a que las observaciones están al lado incorrecto del margen (y por ende el margen será grande)"
  },
  {
    "objectID": "slides/lec_week9.html#svm",
    "href": "slides/lec_week9.html#svm",
    "title": "Métodos supervisados: continuación",
    "section": "SVM",
    "text": "SVM\nSupport Vector Machine (SVM) o Maquina de vectores de soporte es una extensión del clasificador de vectores de soporte que se obtiene tras aumentar el espacio de variables de una manera específica: usando kernels.\nEn el caso del problema de optimización del clasificador de vectores de soporte, la solución involucra sólo productos internos de las observaciones (en contraste con las observaciones mismas)."
  },
  {
    "objectID": "slides/lec_week9.html#svm-continuación",
    "href": "slides/lec_week9.html#svm-continuación",
    "title": "Métodos supervisados: continuación",
    "section": "SVM: continuación",
    "text": "SVM: continuación\nEl producto interno de dos \\(r-\\)vectores \\(a\\) y \\(b\\) se define como \\(\\langle a,b\\rangle=\\sum_{i=1}^{r} a_i b_i\\). Por lo que el producto interno de dos observaciones \\(x_i,x_{i'}\\) está dado por:\n\\[\n\\langle x_i, x_{i'}\\rangle=\\sum_{j=1}^{p}x_{ij}x_{i'j}\n\\]\nMás precisamente, se puede mostrar que:\n\nEl clasificador de vectores de soportes lineal se puede representar como\n\\[\nf(x)=\\beta_0+\\sum_{i=1}^{n}\\alpha_i\\langle x,x_i\\rangle\n\\]\n\n\ndonde hay \\(n\\) parámetros \\(\\alpha_i, i=1,\\dots,n\\), uno para cada observación de entrenamiento."
  },
  {
    "objectID": "slides/lec_week9.html#svm-continuación-1",
    "href": "slides/lec_week9.html#svm-continuación-1",
    "title": "Métodos supervisados: continuación",
    "section": "SVM: continuación",
    "text": "SVM: continuación\n\nPara estimar los parámetros \\(\\alpha_1,\\dots,\\alpha_n\\) y \\(\\beta_0\\), sólo necesitamos los \\(\\begin{pmatrix} n \\\\ 2 \\end{pmatrix}\\) productos internos \\(\\langle x_i,x_{i'}\\rangle\\) entre todos los pares de observaciones de entrenamiento. (esto es \\(n(n-1)/2\\) pares).\n\n\nSupongamos que cada producto interno que hemos definido aparece en la representación del clasificador de vectores de soporte lineal, o en el cálculo del problema de optimización. Reemplazaremos este producto interno con una generalización de este, de la forma:\n\\[\nK(x_i,x_{i'})\n\\]\ndonde \\(K\\) es una función que le llamaremos kernel."
  },
  {
    "objectID": "slides/lec_week9.html#svm-continuación-2",
    "href": "slides/lec_week9.html#svm-continuación-2",
    "title": "Métodos supervisados: continuación",
    "section": "SVM: continuación",
    "text": "SVM: continuación\nUn kernel es una función que cuantifica la similitud entre dos observaciones. Por ejemplo, podemos tomar:\n\\[\nK(x_i,x_{i'})=\\sum_{j=1}^{p} x_{ij}x_{i'j}\n\\]\nque nos entregaría el clasificar de vectores de soporte. Lo anterior se dice que es un kernel lineal porque el lineal para las features. El kernel lineal esencialmente cuantifica la similitud de un par de observaciones usando la correlación de Pearson."
  },
  {
    "objectID": "slides/lec_week9.html#svm-continuación-3",
    "href": "slides/lec_week9.html#svm-continuación-3",
    "title": "Métodos supervisados: continuación",
    "section": "SVM: continuación",
    "text": "SVM: continuación\nAlternativamente, podemos considerar otra forma de kernel, por ejemplo:\n\\[\nK(x_i,x_{i'})=(1+\\sum_{j=1}^{p} x_{ij}x_{i'j})^{d}\n\\]\nEste kernel es conocido como el kernel polinomial de grado \\(d\\), donde \\(d\\) es un entero positivo. Cuando este parámetro es mayor a 1, el clasificador de vectores de soportes tiende a tener un límite de decisión bastante más flexible."
  },
  {
    "objectID": "slides/lec_week9.html#svm-continuación-4",
    "href": "slides/lec_week9.html#svm-continuación-4",
    "title": "Métodos supervisados: continuación",
    "section": "SVM: continuación",
    "text": "SVM: continuación\nCuando el clasificador de vectores de soporte es combinado con un kernel no lineal (como el anterior), el clasificador resultante se conoce como support vector machine.\nOtra opción popular de kernel es el kernel radial, que tiene la forma:\n\\[\nK(x_i,x_{i'})=\\exp(-\\gamma \\sum_{j=1}^{p}(x_{ij}-x_{i'j})^2)\n\\]\ndonde \\(\\gamma\\) es una constante positiva."
  },
  {
    "objectID": "slides/lec_week9.html#figura-svm",
    "href": "slides/lec_week9.html#figura-svm",
    "title": "Métodos supervisados: continuación",
    "section": "Figura SVM",
    "text": "Figura SVM"
  },
  {
    "objectID": "slides/lec_week9.html#ejemplo",
    "href": "slides/lec_week9.html#ejemplo",
    "title": "Métodos supervisados: continuación",
    "section": "Ejemplo",
    "text": "Ejemplo\n\nset.seed (411)\nx=matrix(rnorm(200*2), ncol=2)\nx[1:100,]=x[1:100,]+2\nx[101:150,]=x[101:150,]-2\ny=c(rep(1,150),rep(2,50))\ndat=data.frame(x=x,y=as.factor(y))\nplot_radial<-ggplot(dat) +\n  aes(x = x.1, y = x.2, colour = y) +\n  geom_point(shape = \"circle\", size = 1.5) +\n  scale_color_hue(direction = 1) +\n  theme_bw()"
  },
  {
    "objectID": "slides/lec_week9.html#ejemplo-continuación",
    "href": "slides/lec_week9.html#ejemplo-continuación",
    "title": "Métodos supervisados: continuación",
    "section": "Ejemplo: continuación",
    "text": "Ejemplo: continuación\n\nplot_radial"
  },
  {
    "objectID": "slides/lec_week9.html#ejemplo-continuación-1",
    "href": "slides/lec_week9.html#ejemplo-continuación-1",
    "title": "Métodos supervisados: continuación",
    "section": "Ejemplo: continuación",
    "text": "Ejemplo: continuación\n\ntrain=sample(200,100)\nsvmfit=svm(y~., data=dat[train,], kernel=\"radial\", gamma=1,cost =1)\nplot(svmfit , dat[train ,])"
  },
  {
    "objectID": "slides/lec_week9.html#ejemplo-continuación-2",
    "href": "slides/lec_week9.html#ejemplo-continuación-2",
    "title": "Métodos supervisados: continuación",
    "section": "Ejemplo: continuación",
    "text": "Ejemplo: continuación\n\nsummary(svmfit)\n\n\nCall:\nsvm(formula = y ~ ., data = dat[train, ], kernel = \"radial\", gamma = 1, \n    cost = 1)\n\n\nParameters:\n   SVM-Type:  C-classification \n SVM-Kernel:  radial \n       cost:  1 \n\nNumber of Support Vectors:  35\n\n ( 16 19 )\n\n\nNumber of Classes:  2 \n\nLevels: \n 1 2"
  },
  {
    "objectID": "slides/lec_week9.html#ejemplo-continuación-3",
    "href": "slides/lec_week9.html#ejemplo-continuación-3",
    "title": "Métodos supervisados: continuación",
    "section": "Ejemplo: continuación",
    "text": "Ejemplo: continuación\n\nlibrary(caret)\nconfusionMatrix(table(true=dat[-train,\"y\"],pred=predict(svmfit, newdata=dat[-train,])))\n\nConfusion Matrix and Statistics\n\n    pred\ntrue  1  2\n   1 68  7\n   2  9 16\n                                          \n               Accuracy : 0.84            \n                 95% CI : (0.7532, 0.9057)\n    No Information Rate : 0.77            \n    P-Value [Acc > NIR] : 0.05701         \n                                          \n                  Kappa : 0.5616          \n                                          \n Mcnemar's Test P-Value : 0.80259         \n                                          \n            Sensitivity : 0.8831          \n            Specificity : 0.6957          \n         Pos Pred Value : 0.9067          \n         Neg Pred Value : 0.6400          \n             Prevalence : 0.7700          \n         Detection Rate : 0.6800          \n   Detection Prevalence : 0.7500          \n      Balanced Accuracy : 0.7894          \n                                          \n       'Positive' Class : 1"
  },
  {
    "objectID": "slides/lec_week9.html#introducción",
    "href": "slides/lec_week9.html#introducción",
    "title": "Métodos supervisados: continuación",
    "section": "Introducción",
    "text": "Introducción\nEn general, realizar técnicas no supervisadas tiende a ser más difícil que realizar un método supervisado, pues no se tiene un objetivo claro para el análisis (como lo es predecir en el caso supervisado).\nUsualmente, las metodologías no supervisadas se realizar como parte del análisis exploratorio de dato. Además, no existe un consenso en la mejor forma de evaluar las técnicas implementadas en datos de prueba. En el caso supervisados, podemos probar nuestro modelo creado con un conjunto de prueba, pero en el caso no supervisado no es posible debido a que no sabemos el respuesta verdadera.\nEjemplos de aplicación de estas metodologías son vastas:\n\nIdentificación de cáncer\nHistoriales de compras\nEtc."
  },
  {
    "objectID": "slides/lec_week9.html#introducción-continuación",
    "href": "slides/lec_week9.html#introducción-continuación",
    "title": "Métodos supervisados: continuación",
    "section": "Introducción: continuación",
    "text": "Introducción: continuación\nEjemplos de aplicación de estas metodologías son vastas:\n\nIdentificación de cáncer\nHistoriales de compras\nEtc."
  },
  {
    "objectID": "slides/lec_week9.html#análisis-de-componentes-principales",
    "href": "slides/lec_week9.html#análisis-de-componentes-principales",
    "title": "Métodos supervisados: continuación",
    "section": "Análisis de componentes principales",
    "text": "Análisis de componentes principales\nEl análisis de componentes principales nos permite resumir, ante un conjunto grande de variables correlacionadas, un subconjunto con menor número de variables representativas que colectivamente explican la mayoría de la variabilidad del conjunto original.\nAdemás de producir variables que pueden ser usadas para métodos supervisados, PCA (por sus siglas en inglés, principal component analysis) sirve como herramienta para visualizar datos."
  },
  {
    "objectID": "slides/lec_week9.html#qué-son-las-componentes-principales",
    "href": "slides/lec_week9.html#qué-son-las-componentes-principales",
    "title": "Métodos supervisados: continuación",
    "section": "¿Qué son las componentes principales?",
    "text": "¿Qué son las componentes principales?\nSupongamos que deseamos visualizar \\(n\\) observaciones con mediciones en un conjunto de \\(a\\) variables/características/features, \\(X_1,X_2,\\dots,X_p\\), como parte de un análisis exploratorio de datos. Podemos examinar los gráficos bidimensionales de dispersión de los datos, que cada una contiene \\(n\\) mediciones de observaciones de 2 variables. Sin embargo, hay \\(\\begin{pmatrix} p \\\\ 2 \\end{pmatrix}=p(p-1)/2\\) de tales gráficos.\nPor ejemplo, para \\(p=10\\) habrán 45 gráficos. Por lo que si, \\(p\\) es grande no nos será posible mostrarlos todos, y además ninguno de ellos será informativo debido a que sólo tienen un pequeña fracción del total de información disponible en los datos.\nAsí, necesitamos una mejor metodología para poder visualizar las \\(n\\) observaciones cuando \\(p\\) es grande."
  },
  {
    "objectID": "slides/lec_week9.html#qué-son-las-componentes-principales-continuación",
    "href": "slides/lec_week9.html#qué-son-las-componentes-principales-continuación",
    "title": "Métodos supervisados: continuación",
    "section": "¿Qué son las componentes principales?: continuación",
    "text": "¿Qué son las componentes principales?: continuación\nEn particular, quisieramos encontrar una presentación de baja dimensionalidad de los datos que capture la mayor cantidad de información posible. Por ejemplo, si podemos obtener un diagrama bidimensional de los datos que capture la mayoría de la información, entonces podemos graficar las observaciones en aquel espacio.\nPCA nos entrega una herramienta para hacer justamento esto. Encuentra una representación de baja dimensionalidad del conjunto de datos que contiene la mayor variabilidad posible. La idea es que cada una de las \\(n\\) observaciones vive en un espacio \\(p-\\)dimensional, pero no todas estas dimensiones son igualmente interesantes."
  },
  {
    "objectID": "slides/lec_week9.html#qué-son-las-componentes-principales-continuación-1",
    "href": "slides/lec_week9.html#qué-son-las-componentes-principales-continuación-1",
    "title": "Métodos supervisados: continuación",
    "section": "¿Qué son las componentes principales?: continuación",
    "text": "¿Qué son las componentes principales?: continuación\nPCA busca un pequeño número de dimensiones que sean lo más interesantes posibles, donde el concepto de interesante es medido por la cantidad que varían las observaciones en cada uno de las dimensiones.\nCada una de las dimensiones encontradas por PCA es una combinación lineal de \\(p\\) variables.\nAhora nos enfocamos en la manera en que PCA encuentra estas dimensiones o componentes principales."
  },
  {
    "objectID": "slides/lec_week9.html#qué-son-las-componentes-principales-continuación-2",
    "href": "slides/lec_week9.html#qué-son-las-componentes-principales-continuación-2",
    "title": "Métodos supervisados: continuación",
    "section": "¿Qué son las componentes principales?: continuación",
    "text": "¿Qué son las componentes principales?: continuación\nEl primer componente principal de un conjunto de variables \\(X_1,X_2,\\dots,X_p\\) es la combinación lineal normalizada de las variables\n\\[\nZ_1=\\phi_{11}X_1+\\phi_{21}X_2+\\dots+\\phi_{p1}X_p\n\\]\nque tenga la mayor varianza. Por normalizada, se refiere a que\n\\[\n\\sum_{j=1}^{p} \\phi_{j1}^{2}=1.\n\\]\nLlamamos a los elementos \\(\\phi_{11},\\phi_{2 1},\\dots,\\phi_{p1}\\)reciben en el nombre de loadings y son los que definen a la componente. Así, estos elementos conforman el vector de loadings de los componentes principales \\(\\phi_1=(\\phi_{11}\\,\\phi_{21}\\dots\\phi_{p1})'\\)"
  },
  {
    "objectID": "slides/lec_week9.html#métodos-de-agrupamiento",
    "href": "slides/lec_week9.html#métodos-de-agrupamiento",
    "title": "Métodos supervisados: continuación",
    "section": "Métodos de agrupamiento",
    "text": "Métodos de agrupamiento\nLos métodos de agrupamiento o clustering hacen referencia a un conjunto de técnicas que tienen por finalidad encontrar subgrupos o clusters en un conjuntos de datos dado. Al separar en grupos las observaciones que componen un conjunto de datos, interpretamos que los elementos en un mismo grupo son más similares entre sí que con los de otros grupos.\nLo anterior, naturalmente provoca la interrogante ¿Qué se considera que dos datos sean similares o distintos?\nGeneralmente, responder a esta pregunta frecuentemente requiere tener consideraciones sobre el dominio o naturaleza de los datos en estudio."
  },
  {
    "objectID": "slides/lec_week9.html#agrupamiento-jerárquico",
    "href": "slides/lec_week9.html#agrupamiento-jerárquico",
    "title": "Métodos supervisados: continuación",
    "section": "Agrupamiento jerárquico",
    "text": "Agrupamiento jerárquico\nAgrupamiento jerárquico o Hierarchical clustering es una alternativa no requiere que se pre-especifique el número de clusters. Los métodos que engloba el hierarchical clustering se subdividen en dos tipos dependiendo de la estrategia seguida para crear los grupos:\n\nAgglomerative clustering (bottom-up): el agrupamiento se inicia en la base del árbol, donde cada observación forma un cluster individual. Los clusters se van combinado a medida que la estructura crece hasta converger en una única “rama” central.\nDivisive clustering (top-down): es la estrategia opuesta al agglomerative clustering, se inicia con todas las observaciones contenidas en un mismo cluster y se suceden divisiones hasta que cada observación forma un cluster individual.\n\n\nEn ambos casos, los resultados pueden representarse de forma muy intuitiva en una estructura de árbol llamada dendrograma."
  },
  {
    "objectID": "slides/lec_week9.html#qué-son-las-componentes-principales-continuación-3",
    "href": "slides/lec_week9.html#qué-son-las-componentes-principales-continuación-3",
    "title": "Métodos supervisados: continuación",
    "section": "¿Qué son las componentes principales?: continuación",
    "text": "¿Qué son las componentes principales?: continuación\nDado un conjunto de datos \\(\\mathbf{X}\\) de tamaño \\(n\\times p\\). ¿Cómo calculamos la primera componente principal?\nDebido a que sólo estamos interesado en la varianza, asumiremos que cada variable de \\(\\mathbf{X}\\) ha sido centrada en cero ( esto es, que las medias de las columnas sean cero). Luego, buscamos la combinación lineal de las variables medidas con forma:\n\\[\nz_{i1}=\\phi_{11}x_{i1}+\\phi_{21}x_{i2}+\\dots+\\phi_{p1}x_{ip}\n\\]\nque tenga la mayor varianza muestral, sujeto a la restricción que \\(\\sum_{j=1}^{p} \\phi_{j1}^{2}=1\\). En otras palabras, el vector de loadings de la primera componente principal resuelve el siguiente problema de optimización:\n\\[\n\\max_{\\phi_{11},\\dots,\\phi_{p1}}\\Bigg\\{ \\dfrac{1}{n}\\sum_{i=1}^{n} \\left( \\sum_{j=1}^{p} \\phi_{j1}x_{ij}\\right)\\Bigg\\} \\text{ sujeto a }\\sum_{j=1}^{p}\\phi_{j1}^2=1\n\\]"
  },
  {
    "objectID": "slides/lec_week9.html#reproducibilidad-de-las-componentes",
    "href": "slides/lec_week9.html#reproducibilidad-de-las-componentes",
    "title": "Métodos supervisados: continuación",
    "section": "Reproducibilidad de las componentes",
    "text": "Reproducibilidad de las componentes\nEl proceso de PCA genera siempre las mismas componentes principales independientemente del software utilizado, es decir, el valor de los loadings resultantes es el mismo.\nLa única discrepancia que podría suceder es que los signos estén invertidos, pues los loadings determinan la dirección de la componente.\nInfluencia de outliers\nAl trabajar con varianzas, el método PCA es altamente sensible a outliers, por lo que es altamente recomendable estudiar si los hay. La detección de valores atípicos con respecto a una determinada dimensión es algo relativamente sencillo de hacer mediante comprobaciones gráficas.\nLas técnicas diagnóstico de datos anómalos escapa de los objetivos del curso, pero son estudiados en análisis multivariado o modelos lineales (dentro del contexto de regresión)"
  },
  {
    "objectID": "slides/lec_week9.html#proporción-de-varianza-explicada",
    "href": "slides/lec_week9.html#proporción-de-varianza-explicada",
    "title": "Métodos supervisados: continuación",
    "section": "Proporción de varianza explicada",
    "text": "Proporción de varianza explicada\nUna de las preguntas más frecuentes que surge tras realizar un PCA es: ¿Cuánta información presente en el set de datos original se pierde al proyectar las observaciones en un espacio de menor dimensión? o lo que es lo mismo ¿Cuanta información es capaz de capturar cada una de las componentes principales obtenidas? Para contestar a estas preguntas se recurre a la proporción de varianza explicada por cada componente principal.\nAsumiendo que las variables se han estandarizado para tener media cero, la varianza total presente en el set de datos se define como:\n\\[\n\\sum_{j=1}^p Var(X_j) = \\sum_{j=1}^p \\dfrac{1}{n} \\sum_{i=1}^n x^{2}_{ij}\n\\]"
  },
  {
    "objectID": "slides/lec_week9.html#proporción-de-varianza-explicada-continuación",
    "href": "slides/lec_week9.html#proporción-de-varianza-explicada-continuación",
    "title": "Métodos supervisados: continuación",
    "section": "Proporción de varianza explicada: continuación",
    "text": "Proporción de varianza explicada: continuación\ny la varianza explicada por la componente \\(m\\) es:\n\\[\n\\dfrac{1}{n} \\sum_{i=1}^n z^{2}_{im} = \\dfrac{1}{n} \\sum_{i=1}^n  \\left( \\sum_{j=1}^p \\phi_{jm}x_{ij} \\right)^2\n\\]\nAsí, la proporción de varianza explicada por la componente \\(m\\) viene dada por\n\\[\n\\dfrac{\\sum_{i=1}^n  \\left( \\sum_{j=1}^p \\phi_{jm}x_{ij} \\right)^2} {\\sum_{j=1}^p \\sum_{i=1}^n x^{2}_{ij}}\n\\]\nEsta proporción y su forma acumulada (a lo largo de las componentes) nos entrega información crucial a la hora de elegir cuantas componentes principales utilizar en nuestro análisis."
  },
  {
    "objectID": "slides/lec_week9.html#número-óptimo-de-componentes-principales",
    "href": "slides/lec_week9.html#número-óptimo-de-componentes-principales",
    "title": "Métodos supervisados: continuación",
    "section": "Número óptimo de componentes principales",
    "text": "Número óptimo de componentes principales\nPor lo general, dada una matriz de datos de dimensiones \\(n \\times p\\), el número de componentes principales que se pueden calcular es como máximo de \\(\\min\\{n-1,p\\}\\). Sin embargo, siendo el objetivo del PCA reducir la dimensionalidad, suelen ser de interés utilizar el número mínimo de componentes que resultan suficientes para explicar los datos.\nNo existe una respuesta o método único que permita identificar cual es el número óptimo de componentes principales a utilizar. Una forma de proceder muy extendida consiste en evaluar la proporción de varianza explicada acumulada y seleccionar el número de componentes mínimo a partir del cual el incremento deja de ser sustancial."
  },
  {
    "objectID": "slides/lec_week9.html#número-óptimo-de-componentes-principales-continuación",
    "href": "slides/lec_week9.html#número-óptimo-de-componentes-principales-continuación",
    "title": "Métodos supervisados: continuación",
    "section": "Número óptimo de componentes principales: continuación",
    "text": "Número óptimo de componentes principales: continuación"
  },
  {
    "objectID": "slides/lec_week9.html#ejemplo-1",
    "href": "slides/lec_week9.html#ejemplo-1",
    "title": "Métodos supervisados: continuación",
    "section": "Ejemplo",
    "text": "Ejemplo\nDatos del porcentaje de asaltos, asesinatos y secuestros por cada 100 mil habitantes para cada uno de los estos de US, en el año 1973. Adicionalmente, se incluye el porcentaje de la población de cada estado que vive en zonas rurales.\n\ndata(\"USArrests\")\nhead(USArrests)\n\n           Murder Assault UrbanPop Rape\nAlabama      13.2     236       58 21.2\nAlaska       10.0     263       48 44.5\nArizona       8.1     294       80 31.0\nArkansas      8.8     190       50 19.5\nCalifornia    9.0     276       91 40.6\nColorado      7.9     204       78 38.7\n\napply(X = USArrests, MARGIN = 2, FUN = mean)\n\n  Murder  Assault UrbanPop     Rape \n   7.788  170.760   65.540   21.232 \n\napply(X = USArrests, MARGIN = 2, FUN = var)\n\n    Murder    Assault   UrbanPop       Rape \n  18.97047 6945.16571  209.51878   87.72916 \n\n\nSi no estandarizamos, la variable Assault será la que dominará nuestro PCA."
  },
  {
    "objectID": "slides/lec_week9.html#ejemplo-continuación-4",
    "href": "slides/lec_week9.html#ejemplo-continuación-4",
    "title": "Métodos supervisados: continuación",
    "section": "Ejemplo: continuación",
    "text": "Ejemplo: continuación\n\npca <- prcomp(USArrests, scale = TRUE)\nnames(pca)\n\n[1] \"sdev\"     \"rotation\" \"center\"   \"scale\"    \"x\"       \n\npca$center\n\n  Murder  Assault UrbanPop     Rape \n   7.788  170.760   65.540   21.232 \n\npca$scale\n\n   Murder   Assault  UrbanPop      Rape \n 4.355510 83.337661 14.474763  9.366385 \n\npca$rotation\n\n                PC1        PC2        PC3         PC4\nMurder   -0.5358995  0.4181809 -0.3412327  0.64922780\nAssault  -0.5831836  0.1879856 -0.2681484 -0.74340748\nUrbanPop -0.2781909 -0.8728062 -0.3780158  0.13387773\nRape     -0.5434321 -0.1673186  0.8177779  0.08902432\n\n\n\nElementos center y scale contienen la media y desviación en escala original.\nElemento rotation contiene el valor de los loadings para cada componente"
  },
  {
    "objectID": "slides/lec_week9.html#ejemplo-continuación-5",
    "href": "slides/lec_week9.html#ejemplo-continuación-5",
    "title": "Métodos supervisados: continuación",
    "section": "Ejemplo: continuación",
    "text": "Ejemplo: continuación\nValor de las componentes principales para cada observación (principal component scores)\n\nhead(pca$x)\n\n                  PC1        PC2         PC3          PC4\nAlabama    -0.9756604  1.1220012 -0.43980366  0.154696581\nAlaska     -1.9305379  1.0624269  2.01950027 -0.434175454\nArizona    -1.7454429 -0.7384595  0.05423025 -0.826264240\nArkansas    0.1399989  1.1085423  0.11342217 -0.180973554\nCalifornia -2.4986128 -1.5274267  0.59254100 -0.338559240\nColorado   -1.4993407 -0.9776297  1.08400162  0.001450164\n\ndim(pca$x)\n\n[1] 50  4"
  },
  {
    "objectID": "slides/lec_week9.html#ejemplo-continuación-6",
    "href": "slides/lec_week9.html#ejemplo-continuación-6",
    "title": "Métodos supervisados: continuación",
    "section": "Ejemplo: continuación",
    "text": "Ejemplo: continuación\n\nbiplot(x = pca, scale = 0, cex = 0.6, col = c(\"blue4\", \"brown3\"))"
  },
  {
    "objectID": "slides/lec_week9.html#ejemplo-continuación-7",
    "href": "slides/lec_week9.html#ejemplo-continuación-7",
    "title": "Métodos supervisados: continuación",
    "section": "Ejemplo: continuación",
    "text": "Ejemplo: continuación\n\npca$rotation <- -pca$rotation\npca$x        <- -pca$x\nbiplot(x = pca, scale = 0, cex = 0.6, col = c(\"blue4\", \"brown3\"))"
  },
  {
    "objectID": "slides/lec_week9.html#ejemplo-continuación-8",
    "href": "slides/lec_week9.html#ejemplo-continuación-8",
    "title": "Métodos supervisados: continuación",
    "section": "Ejemplo: continuación",
    "text": "Ejemplo: continuación\n\npca$sdev^2\n\n[1] 2.4802416 0.9897652 0.3565632 0.1734301\n\nprop_varianza <- pca$sdev^2 / sum(pca$sdev^2)\nprop_varianza\n\n[1] 0.62006039 0.24744129 0.08914080 0.04335752\n\nej_pca<-ggplot(data = data.frame(prop_varianza, pc = 1:4),\n       aes(x = pc, y = prop_varianza)) +\n  geom_col(width = 0.3) +\n  scale_y_continuous(limits = c(0,1)) +\n  theme_bw() +\n  labs(x = \"Componente principal\",\n       y = \"Prop. de varianza explicada\")"
  },
  {
    "objectID": "slides/lec_week9.html#ejemplo-continuación-9",
    "href": "slides/lec_week9.html#ejemplo-continuación-9",
    "title": "Métodos supervisados: continuación",
    "section": "Ejemplo: continuación",
    "text": "Ejemplo: continuación\n\nej_pca"
  },
  {
    "objectID": "slides/lec_week9.html#ejemplo-continuación-10",
    "href": "slides/lec_week9.html#ejemplo-continuación-10",
    "title": "Métodos supervisados: continuación",
    "section": "Ejemplo: continuación",
    "text": "Ejemplo: continuación\n\nprop_varianza_acum <- cumsum(prop_varianza)\nprop_varianza_acum\n\n[1] 0.6200604 0.8675017 0.9566425 1.0000000\n\nej_pca2<-ggplot(data = data.frame(prop_varianza_acum, pc = 1:4),\n       aes(x = pc, y = prop_varianza_acum, group = 1)) +\n  geom_point() +\n  geom_line() +\n  theme_bw() +\n  labs(x = \"Componente principal\",\n       y = \"Prop. varianza explicada acumulada\")"
  },
  {
    "objectID": "slides/lec_week9.html#ejemplo-continuación-11",
    "href": "slides/lec_week9.html#ejemplo-continuación-11",
    "title": "Métodos supervisados: continuación",
    "section": "Ejemplo: continuación",
    "text": "Ejemplo: continuación\n\nej_pca2"
  },
  {
    "objectID": "slides/lec_week9.html#métodos-de-agrupamiento-continuación",
    "href": "slides/lec_week9.html#métodos-de-agrupamiento-continuación",
    "title": "Métodos supervisados: continuación",
    "section": "Métodos de agrupamiento: continuación",
    "text": "Métodos de agrupamiento: continuación\nPor ejemplo, supongamos que tenemos un conjunto de \\(n\\) observaciones, cada una con \\(p\\) features. Las \\(n\\) observaciones podrían corresponder a muestras de tejido de pacientes con cáncer de mamas, y las \\(p\\) características podrían corresponder a las mediciones recogidas desde cada tejido; mediciones clínicas, mediciones sobre la expresión de genes, etc.\nPodríamos tener alguna razón para creer que existe alguna tipo de heterogeneidad entre las \\(n\\) muestras de tejidos; por ejemplo, quizás existen algunos sub-tipos diferentes de cáncer de mama. En este caso, las técnicas de agrupamiento podrían ser utilizadas para encontrar estos subgrupos."
  },
  {
    "objectID": "slides/lec_week9.html#métodos-de-agrupamiento-continuación-1",
    "href": "slides/lec_week9.html#métodos-de-agrupamiento-continuación-1",
    "title": "Métodos supervisados: continuación",
    "section": "Métodos de agrupamiento: continuación",
    "text": "Métodos de agrupamiento: continuación\nEste es un problema no-supervisado debido a que estamos tratando de descubrir la estructure en base a un conjunto de datos. Las técnicas de PCA y clustering buscan simplificar los datos a través de un pequeño número de abstracciones, pero sus mecanismos son diferentes:\n\nPCA busca encontrar una representación de dimensión baja de las observaciones que expliquen una gran parte de la varianza.\nLos métodos de agrupamiento buscan encontrar subgrupos homogéneos entre las observaciones.\n\n\nDebido a que la popularidad y uso de agrupamientos, existen un gran número metodologías de clustering. Nos concentraremos un particularmente dos, K-medias y agrupamiento jerárquico"
  },
  {
    "objectID": "slides/lec_week9.html#medidas-de-distancia",
    "href": "slides/lec_week9.html#medidas-de-distancia",
    "title": "Métodos supervisados: continuación",
    "section": "Medidas de distancia",
    "text": "Medidas de distancia\nTodos los métodos de clustering tienen una cosa en común, para poder llevar a cabo las agrupaciones necesitan definir y cuantificar la similitud entre las observaciones. Dentro de este contexto, cuantificaremos aquella similitud usando distintos tipos de distancia entre las observaciones, debido a que en principio podemos escoger cualquier tipo de distancia, hace a esta metodología bastante flexible."
  },
  {
    "objectID": "slides/lec_week9.html#distancia-euclidiana",
    "href": "slides/lec_week9.html#distancia-euclidiana",
    "title": "Métodos supervisados: continuación",
    "section": "Distancia euclidiana",
    "text": "Distancia euclidiana\nPara un espacio euclidiano \\(n-\\)dimensional definimos la distancia euclidiana entre dos puntos \\(p=(p_1,p_2,\\dots,p_n)\\) y \\(q=(q_1,q_2,\\dots,q_n)\\) como la cantidad:\n\\[d_{euc}(p,q)\\sqrt{(p_1-q_1)^2+(p_2-q_2)^2+\\dots(p_n-q_n)^2}=\\sqrt{\\sum_{i=1}^n (p_i-q_i)^2}\\]\nElevar esta distancia al cuadrado permite dar más peso a aquellas observaciones que están más alejadas."
  },
  {
    "objectID": "slides/lec_week9.html#distancia-de-manhattan",
    "href": "slides/lec_week9.html#distancia-de-manhattan",
    "title": "Métodos supervisados: continuación",
    "section": "Distancia de Manhattan",
    "text": "Distancia de Manhattan\nLa distancia de Manhattan, también conocida como taxicab metric o distancia \\(L^1\\), define la distancia entre dos puntos \\(p\\) y \\(q\\) como la sumatoria de las diferencias absolutas entre cada dimensión. Esta medida es menos sensible a datos anómalos que la distancia euclidiana.\nEn este tipo de distancia existen múltiples caminos para unir dos puntos con el mismo valor de distancia de Manhattan, ya que su valor es igual al desplazamiento total en cada una de las dimensiones. Esta distancia está definida como:\n\\[d_{man}(p,q)=\\sum_{i=1}^{n}|(p_i-q_i)|\\]"
  },
  {
    "objectID": "slides/lec_week9.html#distancia-de-manhattan-continuación",
    "href": "slides/lec_week9.html#distancia-de-manhattan-continuación",
    "title": "Métodos supervisados: continuación",
    "section": "Distancia de Manhattan: continuación",
    "text": "Distancia de Manhattan: continuación"
  },
  {
    "objectID": "slides/lec_week9.html#correlación",
    "href": "slides/lec_week9.html#correlación",
    "title": "Métodos supervisados: continuación",
    "section": "Correlación",
    "text": "Correlación\nLa correlación es una medida de distancia muy útil cuando la definición de simulitud se hace en términos de patrón o forma y no de desplazamiento o magnitud ¿Qué quiere decir esto?"
  },
  {
    "objectID": "slides/lec_week9.html#correlación-continuación",
    "href": "slides/lec_week9.html#correlación-continuación",
    "title": "Métodos supervisados: continuación",
    "section": "Correlación: continuación",
    "text": "Correlación: continuación\nLa correlación la definimos como:\n\\[d_{cor}(p,q)=1-\\text{correlación}(p,q)\\]\nSegún esta definición, tendremos que a una correlación de magnitud 1, la similitud o distancia será cero, y por tanto las consideraremos iguales.\nExisten más distancias que podemos ocupar, entre ellas Jackknife correlation,Simple matching coefficient (para datos binarios), índice Jacard, distancia coseno, entre otras."
  },
  {
    "objectID": "slides/lec_week9.html#k-medias",
    "href": "slides/lec_week9.html#k-medias",
    "title": "Métodos supervisados: continuación",
    "section": "K-medias",
    "text": "K-medias\nEl método de K-medias o \\(K-means\\) agrupa las observaciones en \\(K\\) grupos distintos donde \\(K\\) se determina antes de realizar el análisis. Una vez definido el valor de \\(k\\), esta metodología encuentra los \\(k\\) mejores clusters, entendiendo como mejor cluster aquel cuya varianza interna (varianza intra-cluster) sea lo más pequeña posible.\nAsí, este método es un problema de optimización, en el que se reparten las observaciones en \\(K\\) clusters de forma que la suma de las varianzas internas de todos ellos sea la menor posible. Esto requiere definir un modo de cuantificar la varianza interna."
  },
  {
    "objectID": "slides/lec_week9.html#k-medias-continuación",
    "href": "slides/lec_week9.html#k-medias-continuación",
    "title": "Métodos supervisados: continuación",
    "section": "K-medias: continuación",
    "text": "K-medias: continuación\nConsideremos \\(C_1,\\dots,C_k\\) como los conjuntos formados por los índices de las observaciones de cada uno de los clusters. Esto es, \\(C_1\\) contiene los índices de las observaciones agrupadas en el cluster 1. Para indicar la pertenencia de una observación a un cluster particular es \\(i\\in C_k\\). Todos estos conjuntos satisfacen las siguientes dos propiedades:\n\n\\(C_1 \\cup C_2 \\dots \\cup C_k=\\{1,\\dots,n\\}\\)\n\\(C_k \\cap C_{k'}=\\emptyset\\)\n\n\nDos medidas frecuentemente utilizadas para definir la varianza interna de cada cluster \\(W(C_k)\\) son:\n\n\\(W(C_k)=\\sum_{x_i\\in C_k} (x_i-\\mu_k)^2\\)\n\\(W(C_k)=\\dfrac{1}{|C_k|}\\sum_{i,i'\\in C_k}\\sum_{j=1}^{p}(x_{ij}-x_{i'j})^2\\)\n\n\n\nMinimizar la suma total de la varianza interna \\(\\sum_{k=1}^{K}W(C_k)\\) de forma exacta (encontrar un mínimo global) es un proceso complejo debido a la inmensa cantidad de formas en las que \\(n\\) observaciones se pueden dividir en \\(K\\) grupos. Sin embargo, es posible obtener una solución que si bien no es la óptima, nos entrega un óptimo local."
  },
  {
    "objectID": "slides/lec_week9.html#k-medias-continuación-1",
    "href": "slides/lec_week9.html#k-medias-continuación-1",
    "title": "Métodos supervisados: continuación",
    "section": "K-medias: continuación",
    "text": "K-medias: continuación\nEl algoritmo empleado en este caso es:\n\nAsignar aleatoriamente un número entre 1 y \\(K\\) a cada observación. Esto sirve como asignación inicial aleatoria de las observaciones a los clusters.\nIterar los siguientes pasos hasta que la asignación de las observaciones de los clusters no cambie o se alcance un número máximo de iteraciones preestablecido.\n\nPara cada uno de los clusters calcular su centroide (centro de gravedad)\nAsignar cada observación al cluster cuyo centroide está más próximo.\n\n\n\nEste algoritmo garantiza que, en cada paso, se reduzca la intra-varianza total de los clusters hasta alcanzar un óptimo local."
  },
  {
    "objectID": "slides/lec_week9.html#figura-k-medias",
    "href": "slides/lec_week9.html#figura-k-medias",
    "title": "Métodos supervisados: continuación",
    "section": "Figura: K-medias",
    "text": "Figura: K-medias"
  },
  {
    "objectID": "slides/lec_week9.html#k-medias-continuación-2",
    "href": "slides/lec_week9.html#k-medias-continuación-2",
    "title": "Métodos supervisados: continuación",
    "section": "K-medias: continuación",
    "text": "K-medias: continuación\nOtra forma de implementar el algoritmo de K-means clustering es la siguiente:\n\nEspecificar el número K de clusters que se quieren crear.\nSeleccionar de forma aleatoria k observaciones del set de datos como centroides iniciales.\nAsignar cada una de las observaciones al centroide más cercano.\nPara cada uno de los K clusters recalcular su centroide.\nRepetir los pasos 3 y 4 hasta que las asignaciones no cambien o se alcance el número máximo de iteraciones establecido.\n\n\nDebido a que el algoritmo de K-means no evalúa todas las posibles distribuciones de las observaciones sino solo parte de ellas, los resultados obtenidos dependen de la asignación aleatoria inicial (paso 1). Por esta razón, es importante ejecutar el algoritmo varias veces (25-50), cada una con una asignación aleatoria inicial distinta, y seleccionar aquella que haya conseguido un menor valor de varianza total."
  },
  {
    "objectID": "slides/lec_week9.html#k-means-ventajas-y-desventajas",
    "href": "slides/lec_week9.html#k-means-ventajas-y-desventajas",
    "title": "Métodos supervisados: continuación",
    "section": "K-means: Ventajas y desventajas",
    "text": "K-means: Ventajas y desventajas\nK-means es uno de los métodos de clustering más utilizados. Destaca por la sencillez y velocidad de su algoritmo, sin embargo, presenta una serie de limitaciones que se deben tener en cuenta.\n\nRequiere que se indique de antemano el número de clusters que se van a crear. Esto puede ser complicado si no se dispone de información adicional sobre los datos con los que se trabaja. Se han desarrollado varias estrategias para ayudar a identificar potenciales valores óptimos de K, aunque todas ellas son orientativas.\nLas agrupaciones resultantes pueden variar dependiendo de la asignación aleatoria inicial de los centroides. Para minimizar este problema se recomienda repetir el proceso de clustering entre 25-50 veces y seleccionar como resultado definitivo el que tenga menor suma total de varianza interna. Aun así, solo se puede garantizar la reproducibilidad de los resultados si se emplean semillas.\nPresenta problemas de robustez frente a outliers. La única solución es excluirlos o recurrir a otros métodos de clustering más robustos como K-medoids (partitioning around medoids; PAM)."
  },
  {
    "objectID": "slides/lec_week9.html#ejemplo-2",
    "href": "slides/lec_week9.html#ejemplo-2",
    "title": "Métodos supervisados: continuación",
    "section": "Ejemplo",
    "text": "Ejemplo\n\nlibrary(tidyverse)\nlibrary(ggpubr)\nset.seed(411)\ndatos <- matrix(rnorm(n = 100*2), nrow = 100, ncol = 2,\n                dimnames = list(NULL,c(\"x\", \"y\")))\ndatos <- as.data.frame(datos)\nmedia_grupos <- matrix(rnorm(n = 8, mean = 0, sd = 4), nrow = 4, ncol = 2,\n                       dimnames = list(NULL, c(\"media_x\", \"media_y\")))\nmedia_grupos <- as.data.frame(media_grupos)\nmedia_grupos <- media_grupos %>% mutate(grupo = c(\"a\",\"b\",\"c\",\"d\"))\ndatos <- datos %>% mutate(grupo = sample(x = c(\"a\",\"b\",\"c\",\"d\"),\n                                         size = 100,\n                                         replace = TRUE))\ndatos <- left_join(datos, media_grupos, by = \"grupo\")\ndatos <- datos %>% mutate(x = x + media_x,\n                          y = y + media_y)\n\nkm1<-ggplot(data = datos, aes(x = x, y = y, color = grupo)) +\n  geom_point(size = 2.5) +\n  theme_bw()"
  },
  {
    "objectID": "slides/lec_week9.html#ejemplo-3",
    "href": "slides/lec_week9.html#ejemplo-3",
    "title": "Métodos supervisados: continuación",
    "section": "Ejemplo",
    "text": "Ejemplo\n\ndata(USArrests)\ndatos <- scale(USArrests)\nmat_dist <- dist(x = datos, method = \"euclidean\")\nhc_euclidiana_complete <- hclust(d = mat_dist, method = \"complete\")\nhc_euclidiana_average  <- hclust(d = mat_dist, method = \"average\")\ncor(x = mat_dist, cophenetic(hc_euclidiana_complete))\n\n[1] 0.6979437\n\ncor(x = mat_dist, cophenetic(hc_euclidiana_average))\n\n[1] 0.7180382\n\n\nPara estos datos, el método de linkage average consigue representar un poco mejor la similitud entre observaciones."
  },
  {
    "objectID": "slides/lec_week9.html#ejemplo-continuación-12",
    "href": "slides/lec_week9.html#ejemplo-continuación-12",
    "title": "Métodos supervisados: continuación",
    "section": "Ejemplo: continuación",
    "text": "Ejemplo: continuación"
  },
  {
    "objectID": "slides/lec_week9.html#ejemplo-continuación-13",
    "href": "slides/lec_week9.html#ejemplo-continuación-13",
    "title": "Métodos supervisados: continuación",
    "section": "Ejemplo: continuación",
    "text": "Ejemplo: continuación\n\nset.seed(411)\nkm_clusters <- kmeans(x = datos[, c(\"x\", \"y\")], centers = 4, nstart = 50)\nkm_clusters\n\nK-means clustering with 4 clusters of sizes 24, 25, 33, 18\n\nCluster means:\n          x          y\n1 -4.840884 -5.5399183\n2  2.970914  0.3436634\n3  3.119718 -3.9643128\n4 -5.188403 -0.9255762\n\nClustering vector:\n  [1] 4 1 3 2 4 3 1 2 2 3 2 3 3 3 3 4 3 2 3 4 1 3 2 3 2 1 1 2 1 3 3 2 1 1 1 3 3\n [38] 3 2 3 1 3 1 2 2 4 4 2 2 1 1 3 2 2 4 1 1 2 4 1 4 4 3 2 2 4 1 3 1 4 4 2 3 4\n [75] 3 3 3 3 2 4 1 4 2 3 3 3 2 1 4 4 1 3 1 3 2 1 3 3 1 2\n\nWithin cluster sum of squares by cluster:\n[1] 39.08613 55.16049 61.76208 42.71183\n (between_SS / total_SS =  91.4 %)\n\nAvailable components:\n\n[1] \"cluster\"      \"centers\"      \"totss\"        \"withinss\"     \"tot.withinss\"\n[6] \"betweenss\"    \"size\"         \"iter\"         \"ifault\""
  },
  {
    "objectID": "slides/lec_week9.html#ejemplo-continuación-14",
    "href": "slides/lec_week9.html#ejemplo-continuación-14",
    "title": "Métodos supervisados: continuación",
    "section": "Ejemplo: continuación",
    "text": "Ejemplo: continuación\n\ndatos <- datos %>% mutate(cluster = km_clusters$cluster)\ndatos <- datos %>% mutate(cluster = as.factor(cluster),grupo=as.factor(grupo))\n\nkm2<-ggplot(data = datos, aes(x = x, y = y, color = grupo)) +  geom_text(aes(label = cluster), size = 5) + theme_bw() + theme(legend.position = \"none\")"
  },
  {
    "objectID": "slides/lec_week9.html#ejemplo-continuación-15",
    "href": "slides/lec_week9.html#ejemplo-continuación-15",
    "title": "Métodos supervisados: continuación",
    "section": "Ejemplo: continuación",
    "text": "Ejemplo: continuación"
  },
  {
    "objectID": "slides/lec_week9.html#ejemplo-continuación-16",
    "href": "slides/lec_week9.html#ejemplo-continuación-16",
    "title": "Métodos supervisados: continuación",
    "section": "Ejemplo: continuación",
    "text": "Ejemplo: continuación\n\n\n       grupo real\ncluster  a  b  c  d\n      1  0  0 24  0\n      2  0 25  0  0\n      3 33  0  0  0\n      4  0  0  1 17"
  },
  {
    "objectID": "slides/lec_week9.html#ejemplo-continuación-17",
    "href": "slides/lec_week9.html#ejemplo-continuación-17",
    "title": "Métodos supervisados: continuación",
    "section": "Ejemplo: continuación",
    "text": "Ejemplo: continuación\n\ndatos <- datos %>% dplyr::select(x,y)\nset.seed(411)\nkm_clusters_2 <- kmeans(x = datos, centers = 2, nstart = 50)\ndatos <- datos %>% mutate(cluster = km_clusters_2$cluster)\np1 <- ggplot(data = datos, aes(x = x, y = y, color = as.factor(cluster))) +\n      geom_point(size = 3) +\n      labs(title = \"Kmeans con k=2\") +\n      theme_bw() +\n      theme(legend.position = \"none\")\n\ndatos <- datos %>% dplyr::select(x, y)\n\nkm_clusters_6 <- kmeans(x = datos, centers = 6, nstart = 50)\ndatos <- datos %>% mutate(cluster = km_clusters_6$cluster)\np2 <- ggplot(data = datos, aes(x = x, y = y, color = as.factor(cluster))) +\n      geom_point(size = 3) +\n      labs(title = \"Kmeans con k=6\") +\n      theme_bw() +\n      theme(legend.position = \"none\")"
  },
  {
    "objectID": "slides/lec_week9.html#ejemplo-continuación-18",
    "href": "slides/lec_week9.html#ejemplo-continuación-18",
    "title": "Métodos supervisados: continuación",
    "section": "Ejemplo: continuación",
    "text": "Ejemplo: continuación\n\nlibrary(gridExtra)\nggarrange(p1, p2)"
  },
  {
    "objectID": "slides/lec_week9.html#agglomerative",
    "href": "slides/lec_week9.html#agglomerative",
    "title": "Métodos supervisados: continuación",
    "section": "Agglomerative",
    "text": "Agglomerative\nLa estructura resultante de un agglomerative hierarchical clustering se obtiene mediante un algoritmo sencillo.\n\nEl proceso se inicia considerando cada una de las observaciones como un cluster individual, formando así la base del dendrograma (hojas).\nSe inicia un proceso iterativo hasta que todas las observaciones pertenecen a un único cluster:\n\nSe calcula la distancia entre cada posible par de los \\(n\\) clusters. El investigador debe determinar el tipo de medida emplea para cuantificar la similitud entre observaciones o grupos (distancia y linkage).\nLos dos clusters más similares se fusionan, de forma que quedan \\(n-1\\) clusters.\n\nDeterminar dónde cortar la estructura de árbol generada (dendrograma)."
  },
  {
    "objectID": "slides/lec_week9.html#figura-h.c.-agglomerative",
    "href": "slides/lec_week9.html#figura-h.c.-agglomerative",
    "title": "Métodos supervisados: continuación",
    "section": "Figura H.C. agglomerative",
    "text": "Figura H.C. agglomerative"
  },
  {
    "objectID": "slides/lec_week9.html#agglomerative-continuación",
    "href": "slides/lec_week9.html#agglomerative-continuación",
    "title": "Métodos supervisados: continuación",
    "section": "Agglomerative: continuación",
    "text": "Agglomerative: continuación\nPara que el proceso de agrupamiento pueda llevarse a cabo tal como indica el algoritmo anterior, es necesario definir cómo se cuantifica la similitud entre dos clusters. Es decir, se tiene que extender el concepto de distancia entre pares de observaciones para que sea aplicable a pares de grupos, cada uno formado por varias observaciones. A este proceso se le conoce como linkage. A continuación, se describen los tipos de linkage más empleados y sus definiciones.\n\nComplete or Maximum: Se calcula la distancia entre todos los posibles pares formados por una observación del cluster A y una del cluster B. La mayor de todas ellas se selecciona como la distancia entre los dos clusters. Se trata de la medida más conservadora (maximal intercluster dissimilarity).\nSingle or Minimum: Se calcula la distancia entre todos los posibles pares formados por una observación del cluster A y una del cluster B. La menor de todas ellas se selecciona como la distancia entre los dos clusters. Se trata de la medida menos conservadora (minimal intercluster dissimilarity).\nAverage: Se calcula la distancia entre todos los posibles pares formados por una observación del cluster A y una del cluster B. El valor promedio de todas ellas se selecciona como la distancia entre los dos clusters (mean intercluster dissimilarity)."
  },
  {
    "objectID": "slides/lec_week9.html#agglomerative-continuación-1",
    "href": "slides/lec_week9.html#agglomerative-continuación-1",
    "title": "Métodos supervisados: continuación",
    "section": "Agglomerative: continuación",
    "text": "Agglomerative: continuación\n\nCentroid: Se calcula el centroide de cada uno de los clusters y se selecciona la distancia entre ellos como la distancia entre los dos clusters.\nWard: Se trata de un método general. La selección del par de clusters que se combinan en cada paso del agglomerative hierarchical clustering se basa en el valor óptimo de una función objetivo, pudiendo ser esta última cualquier función definida por el analista. El conocido método Ward’s minimum variance es un caso particular en el que el objetivo es minimizar la suma total de varianza intra-cluster.\n\n\nLos métodos de linkage complete, average y Ward’s minimum variance suelen ser los preferidos por los analistas debido a que generan dendrogramas más compensados. Sin embargo, no se puede determinar que uno sea mejor que otro, ya que depende del caso de estudio en cuestión."
  },
  {
    "objectID": "slides/lec_week9.html#divisive",
    "href": "slides/lec_week9.html#divisive",
    "title": "Métodos supervisados: continuación",
    "section": "Divisive",
    "text": "Divisive\nEl algoritmo más conocido de divisive hierarchical clustering es DIANA (DIvisive ANAlysis Clustering). Este algoritmo se inicia con un único cluster que contiene todas las observaciones, a continuación, se van sucediendo divisiones hasta que cada observación forma un cluster independiente. En cada iteración, se selecciona el cluster con mayor diámetro, entendiendo por diámetro de un cluster la mayor de las diferencias entre dos de sus observaciones.\nUna vez seleccionado el cluster, se identifica la observación más dispar, que es aquella con mayor distancia promedio respecto al resto de observaciones que forman el cluster, esta observación inicia el nuevo cluster. Se reasignan las observaciones en función de si están más próximas al nuevo cluster o al resto de la partición, dividiendo así el cluster seleccionado en dos nuevos clusters."
  },
  {
    "objectID": "slides/lec_week9.html#divisive-continuación",
    "href": "slides/lec_week9.html#divisive-continuación",
    "title": "Métodos supervisados: continuación",
    "section": "Divisive: continuación",
    "text": "Divisive: continuación\n\nTodas las n observaciones forman un único cluster.\nRepetir hasta que hayan n clusters:\n\nCalcular para cada cluster la mayor de las distancias entre pares de observaciones (diámetro del cluster).\nSeleccionar el cluster con mayor diámetro.\nCalcular la distancia media de cada observación respecto a las demás.\nLa observación más distante inicia un nuevo cluster.\nSe reasignan las observaciones restantes al nuevo cluster o al viejo dependiendo de cual está más próximo.\n\n\n\nA diferencia del clustering aglomerativo, en el que hay que elegir un tipo de distancia y un método de linkage, en el clustering divisivo sólo hay que elegir la distancia."
  },
  {
    "objectID": "slides/lec_week9.html#dendograma",
    "href": "slides/lec_week9.html#dendograma",
    "title": "Métodos supervisados: continuación",
    "section": "Dendograma",
    "text": "Dendograma\nPara ilustrar cómo se interpreta un dendograma, se simula un set de datos y se somete a un proceso de hierarchical clustering.\nSupongamos que se dispone de 45 observaciones en un espacio de dos dimensiones, que pertenecen a 3 grupos. Aunque se ha coloreado de forma distinta cada uno de los grupos, se va a suponer que se desconoce esta información y que se desea aplicar el método de hierarchical clustering para intentar reconocer los grupos."
  },
  {
    "objectID": "slides/lec_week9.html#dendograma-continuación",
    "href": "slides/lec_week9.html#dendograma-continuación",
    "title": "Métodos supervisados: continuación",
    "section": "Dendograma: continuación",
    "text": "Dendograma: continuación"
  },
  {
    "objectID": "slides/lec_week9.html#dendograma-continuación-1",
    "href": "slides/lec_week9.html#dendograma-continuación-1",
    "title": "Métodos supervisados: continuación",
    "section": "Dendograma: continuación",
    "text": "Dendograma: continuación\nAl aplicar hierarchical clustering, empleando como medida de similitud la distancia euclídea y linkage complete, se obtiene el siguiente dendrograma. Como los datos se han simulado en aproximamdamente la misma escala, no es necesario estandarizarlos, de no ser así, sí se tendrían que estandarizar."
  },
  {
    "objectID": "slides/lec_week9.html#verificación-del-árbol-resultante",
    "href": "slides/lec_week9.html#verificación-del-árbol-resultante",
    "title": "Métodos supervisados: continuación",
    "section": "Verificación del árbol resultante",
    "text": "Verificación del árbol resultante\nUna vez creado el dendrograma, hay que evaluar hasta qué punto su estructura refleja las distancias originales entre observaciones. Una forma de hacerlo es empleando el coeficiente de correlación entre las distancias cophenetic del dendrograma (altura de los nodos) y la matriz de distancias original.\nCuanto más cercano es el valor a 1, mejor refleja el dendrograma la verdadera similitud entre las observaciones. Valores superiores a 0.75 suelen considerarse como buenos."
  },
  {
    "objectID": "slides/lec_week9.html#corte-del-árbol",
    "href": "slides/lec_week9.html#corte-del-árbol",
    "title": "Métodos supervisados: continuación",
    "section": "Corte del árbol",
    "text": "Corte del árbol\nAdemás de representar en un dendrograma la similitud entre observaciones, se tiene que poder identificar el número de clusters creados y qué observaciones forman parte de cada uno. Si se realiza un corte horizontal a una determinada altura del dendrograma, el número de ramas que sobrepasan (en sentido ascendente) dicho corte se corresponde con el número de clusters.\n\nlibrary(factoextra)\ndatos <- USArrests\ndatos <- scale(datos)\nset.seed(411)\n\nhc_euclidiana_completo <- hclust(d = dist(x = datos, method = \"euclidean\"),\n                               method = \"complete\")\n\ndendograma1<-fviz_dend(x = hc_euclidiana_completo, k = 2, cex = 0.6) +\n  geom_hline(yintercept = 5.5, linetype = \"dashed\") +\n  labs(title = \"Herarchical clustering\",\n       subtitle = \"Distancia euclídea, Linkage complete, K=2\")"
  },
  {
    "objectID": "slides/lec_week9.html#corte-del-árbol-continuación",
    "href": "slides/lec_week9.html#corte-del-árbol-continuación",
    "title": "Métodos supervisados: continuación",
    "section": "Corte del árbol: continuación",
    "text": "Corte del árbol: continuación"
  },
  {
    "objectID": "slides/lec_week9.html#corte-del-árbol-continuación-1",
    "href": "slides/lec_week9.html#corte-del-árbol-continuación-1",
    "title": "Métodos supervisados: continuación",
    "section": "Corte del árbol: continuación",
    "text": "Corte del árbol: continuación\n\ndendograma2<-fviz_dend(x = hc_euclidiana_completo, k = 4, cex = 0.6) +\n  geom_hline(yintercept = 3.5, linetype = \"dashed\") +\n  labs(title = \"Herarchical clustering\",\n       subtitle = \"Distancia euclídea, Linkage complete, K=4\")"
  },
  {
    "objectID": "slides/lec_week9.html#corte-del-árbol-continuación-2",
    "href": "slides/lec_week9.html#corte-del-árbol-continuación-2",
    "title": "Métodos supervisados: continuación",
    "section": "Corte del árbol: continuación",
    "text": "Corte del árbol: continuación"
  },
  {
    "objectID": "slides/lec_week9.html#corte-del-árbol-continuación-3",
    "href": "slides/lec_week9.html#corte-del-árbol-continuación-3",
    "title": "Métodos supervisados: continuación",
    "section": "Corte del árbol: continuación",
    "text": "Corte del árbol: continuación\nDos propiedades adicionales se derivan de la forma en que se generan los clusters en el método de hierarchical clustering:\n\nDada la longitud variable de las ramas, siempre existe un intervalo de altura para el que cualquier corte da lugar al mismo número de clusters.\nCon un solo dendrograma se dispone de la flexibilidad para generar cualquier número de clusters desde 1 a \\(n\\). La selección del número óptimo puede valorarse de forma visual, tratando de identificar las ramas principales en base a la altura a la que ocurren las uniones."
  },
  {
    "objectID": "slides/lec_week11.html#neurona",
    "href": "slides/lec_week11.html#neurona",
    "title": "Redes neuronales artificiales",
    "section": "Neurona",
    "text": "Neurona\nLa neurona es la unidad funcional de los modelos de redes. Dentro de cada neurona ocurren simplemente dos operaciones: la suma ponderada de sus entradas y la aplicación de una función de activación.\nEn la primera parte, se multiplica cada valor de entrada \\(x_i\\) por su peso asociado \\(w_i\\) y se suman junto con el sesgo. Este es el valor neto de entrada a la neurona. A continuación, este valor se pasa por una función, conocida como función de activación, que transforma el valor neto de entrada en un valor de salida.\nSi bien el valor que llega a la neurona, siempre es una combinación lineal, gracias a la función de activación, se pueden generar salidas muy diversas. Es en la función de activación donde reside el potencial de los modelos de redes para aprender relaciones no lineales."
  },
  {
    "objectID": "slides/lec_week11.html#función-de-activación",
    "href": "slides/lec_week11.html#función-de-activación",
    "title": "Redes neuronales artificiales",
    "section": "Función de activación",
    "text": "Función de activación\nLas funciones de activación controlan en gran medida qué información se propaga desde una capa a la siguiente (forward propagation). Estas funciones convierten el valor neto de entrada a la neurona (combinación de los input, pesos y sesgo) en un nuevo valor.\nGracias a combinación de funciones de activación no lineales con múltiples capas, los modelos de redes son capaces de aprender relaciones no lineales.\nLa gran mayoría de funciones de activación convierten el valor de entrada neto de la neurona en un valor dentro del rango \\((0, 1)\\) o \\((-1, 1)\\). Cuando el valor de activación de una neurona (salida de su función de activación) es cero, se dice que la neurona está inactiva, ya que no pasa ningún tipo de información a las siguientes neuronas."
  },
  {
    "objectID": "slides/lec_week11.html#función-de-coste-loss-function",
    "href": "slides/lec_week11.html#función-de-coste-loss-function",
    "title": "Métodos supervisados: continuación",
    "section": "Función de coste (loss function)",
    "text": "Función de coste (loss function)\nLa función de coste (\\(l\\)), también llamada función de pérdida, loss function o cost function, es la encargada de cuantificar la distancia entre el valor real y el valor predicho por la red, en otras palabras, mide cuánto se equivoca la red al realizar predicciones.\nEn la mayoría de casos, la función de coste devuelve valores positivos. Cuanto más próximo a cero es el valor de coste, mejor son las predicciones de la red (menor error), siendo cero cuando las predicciones se corresponden exactamente con el valor real.\nLa función de coste puede calcularse para una única observación o para un conjunto de datos (normalmente promediando el valor de todas las observaciones). Es el segundo caso el que se utiliza para dirigir el entrenamiento de los modelos."
  },
  {
    "objectID": "slides/lec_week11.html#múltiples-capas",
    "href": "slides/lec_week11.html#múltiples-capas",
    "title": "Redes neuronales artificiales",
    "section": "Múltiples capas",
    "text": "Múltiples capas\nEl modelo de red neuronal con una única capa (single-layer perceptron), aunque supuso un gran avance en el campo del machine learning, solo es capaz de aprender patrones sencillos. Para superar esta limitación, los investigadores descubrieron que, combinando múltiples capas ocultas, la red puede aprender relaciones mucho más complejas entre los predictores y la variable respuesta. A esta estructura se le conoce como perceptrón multicapa o multilayer perceptron (MLP), y puede considerarse como el primer modelo de deep learning.\nLa estructura de un perceptrón multicapa consta de varias capas ocultas. Cada neurona está conectada a todas las neuronas de la capa anterior y a las de la capa posterior. Aunque no es estrictamente necesario, todas las neuronas que forman parte de una misma capa suelen emplear la misma función de activación."
  },
  {
    "objectID": "slides/lec_week11.html#entrenamiento",
    "href": "slides/lec_week11.html#entrenamiento",
    "title": "Redes neuronales artificiales",
    "section": "Entrenamiento",
    "text": "Entrenamiento\nEl proceso de entrenamiento de una red neuronal consiste en ajustar el valor de los pesos y sesgo de tal forma que, las predicciones que se generen, tengan el menor error posible. Gracias a esto, el modelo es capaz de identificar qué predictores tienen mayor influencia y de qué forma están relacionados entre ellos y con la variable respuesta.\nLa idea intuitiva de cómo entrenar una red neuronal es la siguiente:\n\nIniciar la red con valores aleatorios de los pesos y sesgo.\nPara cada observación de entrenamiento, calcular el error que comete la red al hacer su predicción. Promediar los errores de todas las observaciones.\nIdentificar la responsabilidad que ha tenido cada peso y sesgo en el error de las predicciones.\nModificar ligeramente los pesos y sesgos de la red (de forma proporcional a su responsabilidad en el error) en la dirección correcta para que se reduzca el error.\nRepetir los pasos 2, 3, 4 y 5 hasta que la red sea suficientemente buena.\n\n\nSi bien la idea parece sencilla, alcanzar una forma de implementarla ha requerido la combinación de múltiples métodos matemáticos, en particular, backward y forward propagation."
  },
  {
    "objectID": "slides/lec_week11.html#hiperparámetros",
    "href": "slides/lec_week11.html#hiperparámetros",
    "title": "Métodos supervisados: continuación",
    "section": "Hiperparámetros",
    "text": "Hiperparámetros\nLa gran “flexibilidad” que tienen las redes neuronales es un arma de doble filo. Por un lado, son capaces de generar modelos que aprenden relaciones muy complejas, sin embargo, sufren fácilmente el problema de sobreajuste (overfitting) lo que los incapacita al tratar de predecir nuevas observaciones.\nLa forma de minimizar este problema y conseguir modelos útiles pasa por configurar de forma adecuada sus hiperparámetros. Son muchos los hiperparámetros de un modelo basado en redes y su nomenclatura varía de unas implementaciones a otras, sin embargo, los de mayor impacto siempre están presentes:\n\nNúmero y tamaño de capas\nLearning rate\nAlgoritmo de optimización\nRegularización\n\nNúmero y tamaño de capas\nLa arquitectura de una red, el número de capas y el número de neuronas que forman parte de cada capa, determinan en gran medida la complejidad del modelo y con ello su potencial capacidad de aprendizaje.\nLa capa de entrada y salida son sencillas de establecer. La capa de entrada tiene tantas neuronas como predictores y la capa de salida tiene una neurona en problemas de regresión y tantas como clases en problemas de clasificación. En la mayoría de implementaciones, estos valores se establecen automáticamente en función del conjunto de entrenamiento. El usuario suele especificar únicamente el número de capas intermedias (ocultas) y el tamaño de las mismas.\nCuantas más neuronas y capas, mayor la complejidad de las relaciones que puede aprender el modelo. Sin embargo, dado que cada neurona está conectada por pesos al resto de neuronas de las capas adyacentes, el número de parámetros a aprender aumenta y con ello el tiempo de entrenamiento.\nLearning rate\nEl learning rate o tasa de aprendizaje establece cuan rápido pueden cambiar los parámetros de un modelo a medida que se optimiza (aprende). Este hiperparámetro es uno de los más complicados de establecer, ya que depende mucho de los datos e interacciona con el resto de hiperparámetros. Si el learning rate es muy grande, el proceso de optimización puede ir saltando de una región a otra sin que el modelo sea capaz de aprender. Si por el contrario, el learning rate es muy pequeño, el proceso de entrenamiento puede tardar demasiado y no llegar a completarse. Algunas de las recomendaciones heurísticas basadas en prueba y error son:\n\nUtilizar un learning rate lo más pequeño posible siempre y cuando el tiempo de entrenamiento no supere las limitaciones temporales disponibles.\nNo utilizar un valor constante de learning rate durante todo el proceso de entrenamiento. Por lo general, utilizar valores mayores al inicio y pequeños al final.\n\nAlgoritmo de optimización\nEl descenso de gradiente y el descenso de gradiente estocástico fueron de los primeros métodos de optimización utilizados para entrenar modelos de redes neuronales. Ambos utilizan directamente el gradiente para dirigir la optimización. Pronto se vio que esto genera problemas a medida que las redes aumentan de tamaño (neuronas y capas). En muchas regiones del espacio de búsqueda, el gradiente es muy próximo a cero, lo que hace que la optimización quede estancada. Para evitar este problema, se han desarrollado modificaciones del descenso de gradiente capaces de adaptar el learning rate en función del gradiente y subgradiente. De esta forma, el proceso de aprendizaje se ralentiza o acelera dependiendo de las características de la región del espacio de búsqueda en el que se encuentren. Aunque existen multitud de adaptaciones, suele recomendarse:\n\nPara conjuntos de datos pequeños: l-bfgs (limited memory bfgs)\nPara conjuntos de datos grandes: adam o rmsprop (root mean square propagation)\n\nLa elección del algoritmo de optimización puede tener un impacto notable en el aprendizaje de los modelos, sobre todo en deep learning.\nRegularización\nLos métodos de regularización tienen el objetivo de reducir el sobreajuste (overfitting) de los modelos. Un modelo con sobreajuste memoriza los datos de entrenamiento pero es incapaz de predecir correctamente nuevas observaciones.\nLos modelos de redes neuronales pueden considerarse como modelos sobre parametrizados, por lo tanto, las estrategias de regularización son fundamentales. De entre las muchas que existen, destacan la regularización L1 y L2 (weight decay) y el dropout."
  },
  {
    "objectID": "slides/lec_week11.html#ejemplo",
    "href": "slides/lec_week11.html#ejemplo",
    "title": "Métodos supervisados: continuación",
    "section": "Ejemplo",
    "text": "Ejemplo\nUtilizaremos datos del repositorio del Center for Machine Learning and Intelligent Systems de la Universidad de California, en particular, el conjunto de datos Concrete Compressive Strength Data Sets."
  },
  {
    "objectID": "slides/lec_week11.html#representación-de-red-neuronal",
    "href": "slides/lec_week11.html#representación-de-red-neuronal",
    "title": "Redes neuronales artificiales",
    "section": "Representación de red neuronal",
    "text": "Representación de red neuronal"
  },
  {
    "objectID": "slides/lec_week11.html#redes-neuronales-continuación",
    "href": "slides/lec_week11.html#redes-neuronales-continuación",
    "title": "Redes neuronales artificiales",
    "section": "Redes neuronales: continuación",
    "text": "Redes neuronales: continuación\nLa forma más común de representar la estructura de una red neuronal es mediante el uso de capas (layers), formadas a su vez por neuronas. Cada neurona, realiza una operación sencilla y está conectada a las neuronas de la capa anterior y de la capa siguiente mediante pesos, cuya función es regular la información que se propaga de una neurona a otra."
  },
  {
    "objectID": "slides/lec_week11.html#red-neuronal-artificial",
    "href": "slides/lec_week11.html#red-neuronal-artificial",
    "title": "Redes neuronales artificiales",
    "section": "Red neuronal artificial",
    "text": "Red neuronal artificial"
  },
  {
    "objectID": "slides/lec_week11.html#red-neuronal-artificial-continuación",
    "href": "slides/lec_week11.html#red-neuronal-artificial-continuación",
    "title": "Redes neuronales artificiales",
    "section": "Red neuronal artificial: continuación",
    "text": "Red neuronal artificial: continuación\nPara facilitar la comprensión de la estructura de las redes, es útil representar una red equivalente a un modelo de regresión lineal:\n\\[y=w_1 x_1 +\\dots+w_d x_d + b\\]\nCada neurona de la capa de entrada representa el valor de uno de los predictores. Las flechas representan los coeficientes de regresión, que en términos de redes se llaman pesos, y la neurona de salida representa el valor predicho. Para que esta representación sea equivalente a la ecuación de un modelo lineal, faltan dos cosas:\n\nEl sesgo del modelo\nLas operaciones de multiplicación y suma que combinan el valor de los predictores con los pesos del modelo\n\n\nCada neurona de la capa intermedia tiene un valor de sesgo, pero suele omitirse en las representaciones gráficas. En cuanto a las operaciones matemáticas, es el elemento clave que ocurre dentro de las neuronas y conviene verlo con detalle."
  },
  {
    "objectID": "slides/lec_week11.html#representación-de-una-neurona",
    "href": "slides/lec_week11.html#representación-de-una-neurona",
    "title": "Redes neuronales artificiales",
    "section": "Representación de una neurona",
    "text": "Representación de una neurona"
  },
  {
    "objectID": "slides/lec_week11.html#neurona-continuación",
    "href": "slides/lec_week11.html#neurona-continuación",
    "title": "Redes neuronales artificiales",
    "section": "Neurona: continuación",
    "text": "Neurona: continuación\nLo anterior es la noción intuitiva de las redes neuronales artificiales, en términos matemáticos:\nEl valor neto de entrada a una neurona es la suma de los valores que le llegan, ponderados por el peso de las conexiones, más el sesgo:\n\\[Input = \\sum_{i=1}^{n} x_i w_i + b\\]\nEn lugar de utilizar la sumatoria, este operación usualmente se presenta como un producto matricial, donde \\(X\\) representa el vector de los valores de entrada y \\(W\\) el vector de pesos:\n\\[Input = XW + b\\]"
  },
  {
    "objectID": "slides/lec_week11.html#neurona-continuación-1",
    "href": "slides/lec_week11.html#neurona-continuación-1",
    "title": "Redes neuronales artificiales",
    "section": "Neurona: continuación",
    "text": "Neurona: continuación\nA este valor se le aplica una función de activación \\(g\\) que lo transforma en lo que se conoce como el valor de activación \\(a\\), que es lo que finalmente sale de la neurona.\n\\[a=g(Input)=g(XW+b)\\]\nPara la capa de entrada, donde únicamente se quiere incorporar el valor de los predictores, la función de activación es la unidad, es decir, sale lo mismo que entra. En la capa de salida, la función de activación utilizada suele ser la identidad para problemas de regresión."
  },
  {
    "objectID": "slides/lec_week11.html#tipos-de-funciones-de-activación",
    "href": "slides/lec_week11.html#tipos-de-funciones-de-activación",
    "title": "Redes neuronales artificiales",
    "section": "Tipos de funciones de activación",
    "text": "Tipos de funciones de activación\nExisten muchas funciones de activación utilizadas en la práctica, en lo que sigue mencionamos un par de ellas:\n\nRectified linear unit (ReLU)\nSigmoide\nTangente hiperbólica\n\n\nTambién hay otras como: función lineal, gaussiana, linear saturada, etc."
  },
  {
    "objectID": "slides/lec_week11.html#rectified-linear-unit-relu",
    "href": "slides/lec_week11.html#rectified-linear-unit-relu",
    "title": "Redes neuronales artificiales",
    "section": "Rectified linear unit (ReLU)",
    "text": "Rectified linear unit (ReLU)\nLa función de activación ReLu aplica una transformación no lineal muy simple, activa la neurona solo si el input está por encima de cero. Mientras el valor de entrada está por debajo de cero, el valor de salida es cero, pero cuando es superior, el valor de salida aumenta de forma lineal con el de entrada.\n\\[ReLU(x)=\\max (x,0)\\]\nDe esta forma, la función de activación retiene únicamente los valores positivos y descarta los negativos dándoles una activación de cero."
  },
  {
    "objectID": "slides/lec_week11.html#gráfico-relu",
    "href": "slides/lec_week11.html#gráfico-relu",
    "title": "Redes neuronales artificiales",
    "section": "Gráfico ReLU",
    "text": "Gráfico ReLU"
  },
  {
    "objectID": "slides/lec_week11.html#rectified-linear-unit-relu-continuación",
    "href": "slides/lec_week11.html#rectified-linear-unit-relu-continuación",
    "title": "Redes neuronales artificiales",
    "section": "Rectified linear unit (ReLU): continuación",
    "text": "Rectified linear unit (ReLU): continuación\nLa función de activación ReLU es con diferencia la función de activación más empleada por sus buenos resultados en aplicaciones diversas. La razón de esto reside en el comportamiento de su derivada (gradiente), que es cero o constante."
  },
  {
    "objectID": "slides/lec_week11.html#sigmoide",
    "href": "slides/lec_week11.html#sigmoide",
    "title": "Redes neuronales artificiales",
    "section": "Sigmoide",
    "text": "Sigmoide\nLa función sigmoide transforma valores en la recta real a valores en el rango \\([0, 1]\\):\n\\[sigmoid(x)=\\dfrac{1}{1+\\exp(-x)}\\]"
  },
  {
    "objectID": "slides/lec_week11.html#gráfico-sigmoide",
    "href": "slides/lec_week11.html#gráfico-sigmoide",
    "title": "Redes neuronales artificiales",
    "section": "Gráfico Sigmoide",
    "text": "Gráfico Sigmoide"
  },
  {
    "objectID": "slides/lec_week11.html#tangente-hiperbólica",
    "href": "slides/lec_week11.html#tangente-hiperbólica",
    "title": "Redes neuronales artificiales",
    "section": "Tangente hiperbólica",
    "text": "Tangente hiperbólica\nLa función de activación tangente hiperbólica, se comporta de forma similar a la función sigmoide, pero su salida está acotada en el rango \\((-1, 1)\\):\n\\[\\tanh(x)=\\dfrac{1-\\exp(-2x)}{1+\\exp(-2x)}\\]"
  },
  {
    "objectID": "slides/lec_week11.html#gráfico-tangente-hiperbólica",
    "href": "slides/lec_week11.html#gráfico-tangente-hiperbólica",
    "title": "Redes neuronales artificiales",
    "section": "Gráfico tangente hiperbólica",
    "text": "Gráfico tangente hiperbólica"
  },
  {
    "objectID": "slides/lec_week11.html#sigmoide-continuación",
    "href": "slides/lec_week11.html#sigmoide-continuación",
    "title": "Redes neuronales artificiales",
    "section": "Sigmoide: continuación",
    "text": "Sigmoide: continuación\nAunque la función de activación sigmoide se utilizó mucho en los inicios de los modelos de redes neuronales artificiales, en la actualidad, suele preferirse la función ReLU.\nUn caso en el que la función de activación sigmoide sigue siendo la función utilizada por defecto es en las neuronas de la capa de salida de los modelos de clasificación binaria, ya que su salida puede interpretarse como probabilidad."
  },
  {
    "objectID": "slides/lec_week11.html#error-cuadrático-medio",
    "href": "slides/lec_week11.html#error-cuadrático-medio",
    "title": "Redes neuronales artificiales",
    "section": "Error cuadrático medio",
    "text": "Error cuadrático medio\nEl error cuadrático medio (mean squared error, MSE) es la función de coste más utilizada en problemas de regresión. Para una determinada observación \\(i\\), el error cuadrático se calcula como la diferencia al cuadrado entre el valor predicho \\(\\hat{y}\\) y el valor real \\(y\\).\n\\[l^{(i)}(w,b)=\\left( \\widehat{y}^{(i)}-y^{(i)}\\right)^2\\]\nLas funciones de coste suelen escribirse con la notación \\(l(w,b)\\) para hacer referencia a que su valor depende de los pesos y el sesgo del modelo, ya que son estos los que determinan el valor de las predicciones \\(\\widehat{y}^{(i)}\\)."
  },
  {
    "objectID": "slides/lec_week11.html#error-cuadrático-medio-continuación",
    "href": "slides/lec_week11.html#error-cuadrático-medio-continuación",
    "title": "Redes neuronales artificiales",
    "section": "Error cuadrático medio: continuación",
    "text": "Error cuadrático medio: continuación\nCon frecuencia, esta función de coste se encuentra multiplicada por \\(\\dfrac{1}{2}\\), esto es simplemente por conveniencia matemática para simplificar el cálculo de su derivada.\n\\[l^{(i)}(w,b)=\\dfrac{1}{2}\\left( \\widehat{y}^{(i)}-y^{(i)}\\right)^2\\]\nPara cuantificar el error que comete el modelo todo un conjunto de datos, por ejemplo los de entrenamiento, se promedia el error de todas las \\(N\\) observaciones.\n\\[L(w,b)=\\dfrac{1}{n}\\sum_{i=1}^{n}l^{(i)}(w,b)=\\dfrac{1}{n}\\sum_{i=1}^{n}\\left( \\widehat{y}^{(i)}-y^{(i)}\\right)^{2}\\]\nCuando un modelo se entrena utilizando el error cuadrático medio como función de coste, está aprendiendo a predecir la media de la variable respuesta."
  },
  {
    "objectID": "slides/lec_week11.html#error-medio-absoluto",
    "href": "slides/lec_week11.html#error-medio-absoluto",
    "title": "Redes neuronales artificiales",
    "section": "Error medio absoluto",
    "text": "Error medio absoluto\nEl error medio absoluto (mean absolute error, MAE) consiste en promediar el error absoluto de las predicciones.\n\\[L(w,b)=\\dfrac{1}{n}\\sum_{i=1}^{n}|\\widehat{y}^{(i)}-y^{(i)}|\\]\nEl error medio absoluto es más robusto frente a outliers que el error cuadrático medio. Esto significa que el entrenamiento del modelo se ve menos influenciado por datos anómalos que pueda haber en el conjunto de entrenamiento. Cuando un modelo se entrena utilizando el error absoluto medio como función de coste, está aprendiendo a predecir la mediana de la variable respuesta."
  },
  {
    "objectID": "slides/lec_week11.html#múltiples-capas-continuación",
    "href": "slides/lec_week11.html#múltiples-capas-continuación",
    "title": "Redes neuronales artificiales",
    "section": "Múltiples capas: continuación",
    "text": "Múltiples capas: continuación\nCombinando múltiples capas ocultas y funciones de activación no lineales, los modelos de redes pueden aprender prácticamente cualquier patrón. De hecho, está demostrado que, con suficientes neuronas, un MLP es un aproximador universal para cualquier función."
  },
  {
    "objectID": "slides/lec_week11.html#representación-mlp",
    "href": "slides/lec_week11.html#representación-mlp",
    "title": "Redes neuronales artificiales",
    "section": "Representación MLP",
    "text": "Representación MLP"
  },
  {
    "objectID": "slides/lec_week11.html#backpropagation",
    "href": "slides/lec_week11.html#backpropagation",
    "title": "Redes neuronales artificiales",
    "section": "Backpropagation",
    "text": "Backpropagation\nBackpropagation es el algoritmo que permite cuantificar la influencia que tiene cada peso y sesgo en las predicciones de la red. Para conseguirlo, hace uso de la regla de la cadena para calcular el gradiente, que no es más que el vector formado por las derivadas parciales de una función.\nEn el caso de las redes, la derivada parcial del error respecto a un parámetro (peso o sesgo) mide cuánta responsabilidad ha tenido ese parámetro en el error cometido. Gracias a esto, se puede identificar qué pesos de la red hay que modificar para mejorarla. El siguiente paso necesario, es determinar cuánto y cómo modificarlos (optimización)."
  },
  {
    "objectID": "slides/lec_week11.html#prepocesamiento-de-variables",
    "href": "slides/lec_week11.html#prepocesamiento-de-variables",
    "title": "Redes neuronales artificiales",
    "section": "Prepocesamiento de variables",
    "text": "Prepocesamiento de variables\nA la hora de entrenar modelos basados en redes neuronales, es necesario aplicar a los datos, al menos, dos tipos de transformaciones.\n\nBinarización (one hot encoding) de las variables categóricas: La binarización consiste en crear nuevas variables dummy con cada uno de los niveles de las variables cualitativas. Este proceso es el mismo realizado en modelos lineales.\nEstandarización y escalado de variables numéricas: Cuando los predictores son numéricos, la escala en la que se miden, así como la magnitud de su varianza pueden influir en gran medida en el modelo. Si no se igualan de alguna forma los predictores, aquellos que se midan en una escala mayor o que tengan más varianza dominarán el modelo aunque no sean los que más relación tienen con la variable respuesta. Para ello, en general centramos los datos, y estandarizamos o reescalamos entre 0 y 1."
  },
  {
    "objectID": "slides/lec_week11.html#número-y-tamaño-de-capas",
    "href": "slides/lec_week11.html#número-y-tamaño-de-capas",
    "title": "Redes neuronales artificiales",
    "section": "Número y tamaño de capas",
    "text": "Número y tamaño de capas\nLa arquitectura de una red, el número de capas y el número de neuronas que forman parte de cada capa, determinan en gran medida la complejidad del modelo y con ello su potencial capacidad de aprendizaje.\nLa capa de entrada y salida son sencillas de establecer. La capa de entrada tiene tantas neuronas como predictores y la capa de salida tiene una neurona en problemas de regresión y tantas como clases en problemas de clasificación. En la mayoría de implementaciones, estos valores se establecen automáticamente en función del conjunto de entrenamiento. El usuario suele especificar únicamente el número de capas intermedias (ocultas) y el tamaño de las mismas.\nCuantas más neuronas y capas, mayor la complejidad de las relaciones que puede aprender el modelo. Sin embargo, dado que cada neurona está conectada por pesos al resto de neuronas de las capas adyacentes, el número de parámetros a aprender aumenta y con ello el tiempo de entrenamiento."
  },
  {
    "objectID": "slides/lec_week11.html#learning-rate",
    "href": "slides/lec_week11.html#learning-rate",
    "title": "Redes neuronales artificiales",
    "section": "Learning rate",
    "text": "Learning rate\nEl learning rate o tasa de aprendizaje establece cuan rápido pueden cambiar los parámetros de un modelo a medida que se optimiza (aprende). Este hiperparámetro es uno de los más complicados de establecer, ya que depende mucho de los datos e interactúa con el resto de hiperparámetros. Si el learning rate es muy grande, el proceso de optimización puede ir saltando de una región a otra sin que el modelo sea capaz de aprender. Si por el contrario, el learning rate es muy pequeño, el proceso de entrenamiento puede tardar demasiado y no llegar a completarse. Algunas de las recomendaciones heurísticas basadas en prueba y error son:\n\nUtilizar un learning rate lo más pequeño posible siempre y cuando el tiempo de entrenamiento no supere las limitaciones temporales disponibles.\nNo utilizar un valor constante de learning rate durante todo el proceso de entrenamiento. Por lo general, utilizar valores mayores al inicio y pequeños al final."
  },
  {
    "objectID": "slides/lec_week11.html#algoritmo-de-optimización",
    "href": "slides/lec_week11.html#algoritmo-de-optimización",
    "title": "Redes neuronales artificiales",
    "section": "Algoritmo de optimización",
    "text": "Algoritmo de optimización\nEl descenso de gradiente y el descenso de gradiente estocástico fueron de los primeros métodos de optimización utilizados para entrenar modelos de redes neuronales. Ambos utilizan directamente el gradiente para dirigir la optimización. Pronto se vio que esto genera problemas a medida que las redes aumentan de tamaño (neuronas y capas).\nEn muchas regiones del espacio de búsqueda, el gradiente es muy próximo a cero, lo que hace que la optimización quede estancada. Para evitar este problema, se han desarrollado modificaciones del descenso de gradiente capaces de adaptar el learning rate en función del gradiente y subgradiente. De esta forma, el proceso de aprendizaje se ralentiza o acelera dependiendo de las características de la región del espacio de búsqueda en el que se encuentren. Aunque existen multitud de adaptaciones, suele recomendarse:\n\nPara conjuntos de datos pequeños: l-bfgs (limited memory bfgs)\nPara conjuntos de datos grandes: adam o rmsprop (root mean square propagation)\n\n\nLa elección del algoritmo de optimización puede tener un impacto notable en el aprendizaje de los modelos, sobre todo en deep learning."
  },
  {
    "objectID": "slides/lec_week11.html#regularización",
    "href": "slides/lec_week11.html#regularización",
    "title": "Redes neuronales artificiales",
    "section": "Regularización",
    "text": "Regularización\nLos métodos de regularización tienen el objetivo de reducir el sobreajuste (overfitting) de los modelos. Un modelo con sobreajuste memoriza los datos de entrenamiento pero es incapaz de predecir correctamente nuevas observaciones.\nLos modelos de redes neuronales pueden considerarse como modelos sobre-parametrizados, por lo tanto, las estrategias de regularización son fundamentales.\nDe entre las muchas que existen, destacan la regularización L1 y L2 (weight decay) y el dropout."
  },
  {
    "objectID": "slides/lec_week11.html#ejemplo-continuación",
    "href": "slides/lec_week11.html#ejemplo-continuación",
    "title": "Redes neuronales artificiales",
    "section": "Ejemplo: continuación",
    "text": "Ejemplo: continuación\n\nlibrary(readxl)\nconcrete_data<- read_excel(\"db/Concrete_Data.xls\")\nnames(concrete_data)<-c(\"cement\",\"slag\",\"ash\",\"water\",\"superplastic\",\n                        \"coarseagg\",\"fineagg\",\"age\",\"strength\")\nnormalize <- function(x) {\nreturn((x - min(x)) / (max(x) - min(x)))\n}\nhead(concrete_data)\n\n# A tibble: 6 × 9\n  cement  slag   ash water superplastic coarseagg fineagg   age strength\n   <dbl> <dbl> <dbl> <dbl>        <dbl>     <dbl>   <dbl> <dbl>    <dbl>\n1   540     0      0   162          2.5     1040     676     28     80.0\n2   540     0      0   162          2.5     1055     676     28     61.9\n3   332.  142.     0   228          0        932     594    270     40.3\n4   332.  142.     0   228          0        932     594    365     41.1\n5   199.  132.     0   192          0        978.    826.   360     44.3\n6   266   114      0   228          0        932     670     90     47.0"
  },
  {
    "objectID": "slides/lec_week11.html#ejemplo-continuación-1",
    "href": "slides/lec_week11.html#ejemplo-continuación-1",
    "title": "Redes neuronales artificiales",
    "section": "Ejemplo: continuación",
    "text": "Ejemplo: continuación\n\nconcrete_data_norm <- as.data.frame(lapply(concrete_data, normalize))\nsummary(concrete_data_norm$strength)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.0000  0.2663  0.4000  0.4172  0.5457  1.0000 \n\nsummary(concrete_data$strength)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  2.332  23.707  34.443  35.818  46.136  82.599 \n\n\nDebido a que los datos ya están ordenamos aleatoriamente, simplemente dividimos en dos partes de 75 y 25 porciento, respectivamente.\n\nconcrete_train <- concrete_data_norm[1:773, ]\nconcrete_test <- concrete_data_norm[774:1030, ]"
  },
  {
    "objectID": "slides/lec_week11.html#ejemplo-continuación-2",
    "href": "slides/lec_week11.html#ejemplo-continuación-2",
    "title": "Redes neuronales artificiales",
    "section": "Ejemplo: continuación",
    "text": "Ejemplo: continuación\nEl siguiente modelo sería un simple multilayer feedfoward network\n\nlibrary(neuralnet)\nset.seed(411)\nconcrete_model <- neuralnet(strength ~ cement + slag + \n                            ash + water + superplastic \n                            + coarseagg + fineagg + age,\n                            data = concrete_train)"
  },
  {
    "objectID": "slides/lec_week11.html#ejemplo-continuación-3",
    "href": "slides/lec_week11.html#ejemplo-continuación-3",
    "title": "Redes neuronales artificiales",
    "section": "Ejemplo: continuación",
    "text": "Ejemplo: continuación\n\nplot(concrete_model, rep=\"best\")"
  },
  {
    "objectID": "slides/lec_week11.html#ejemplo-continuación-4",
    "href": "slides/lec_week11.html#ejemplo-continuación-4",
    "title": "Redes neuronales artificiales",
    "section": "Ejemplo: continuación",
    "text": "Ejemplo: continuación\n\nmodel_results <- compute(concrete_model, concrete_test[1:8])\npredicted_strength <- model_results$net.result\ncor(predicted_strength, concrete_test$strength)\n\n          [,1]\n[1,] 0.7209429\n\n\nDebido a que es un problema de predicción, no podemos realizar una matriz de confusión para determinar el nivel de precisión"
  },
  {
    "objectID": "slides/lec_week11.html#ejemplo-continuación-5",
    "href": "slides/lec_week11.html#ejemplo-continuación-5",
    "title": "Redes neuronales artificiales",
    "section": "Ejemplo: continuación",
    "text": "Ejemplo: continuación\nEn el siguiente modelo, ampliaremos la cantidad de neuronas.\n\nconcrete_model2 <- neuralnet(strength ~ cement + slag +\n                               ash + water + superplastic +\n                               coarseagg + fineagg + age,\n                             data = concrete_train, hidden = 5)"
  },
  {
    "objectID": "slides/lec_week11.html#ejemplo-continuación-6",
    "href": "slides/lec_week11.html#ejemplo-continuación-6",
    "title": "Redes neuronales artificiales",
    "section": "Ejemplo: continuación",
    "text": "Ejemplo: continuación\n\nplot(concrete_model2, rep=\"best\")"
  },
  {
    "objectID": "slides/lec_week11.html#ejemplo-continuación-7",
    "href": "slides/lec_week11.html#ejemplo-continuación-7",
    "title": "Redes neuronales artificiales",
    "section": "Ejemplo: continuación",
    "text": "Ejemplo: continuación\n\nmodel_results2 <- compute(concrete_model2, concrete_test[1:8])\npredicted_strength2 <- model_results2$net.result\ncor(predicted_strength2, concrete_test$strength)\n\n          [,1]\n[1,] 0.8138362"
  },
  {
    "objectID": "slides/lec_week11.html#ejemplo-continuación-8",
    "href": "slides/lec_week11.html#ejemplo-continuación-8",
    "title": "Redes neuronales artificiales",
    "section": "Ejemplo: continuación",
    "text": "Ejemplo: continuación\nEn este problema no podemos utilizar una función de activación Rectified linear unit (ReLU) debido a que no tiene derivada en \\(x=0\\). Alternativamente, utilizamos una función de activación llamada softplus o Smooth ReLI\n\nsoftplus <- function(x) { log(1 + exp(x)) }\nconcrete_model3 <- neuralnet(strength ~ cement + slag +\n                               ash + water + superplastic +\n                               coarseagg + fineagg + age,\n                             data = concrete_train,\n                             hidden = c(5, 5), act.fct = softplus)"
  },
  {
    "objectID": "slides/lec_week11.html#ejemplo-continuación-9",
    "href": "slides/lec_week11.html#ejemplo-continuación-9",
    "title": "Redes neuronales artificiales",
    "section": "Ejemplo: continuación",
    "text": "Ejemplo: continuación\n\nplot(concrete_model3, rep=\"best\")"
  },
  {
    "objectID": "slides/lec_week11.html#ejemplo-continuación-10",
    "href": "slides/lec_week11.html#ejemplo-continuación-10",
    "title": "Redes neuronales artificiales",
    "section": "Ejemplo: continuación",
    "text": "Ejemplo: continuación\n\nmodel_results3 <- compute(concrete_model3, concrete_test[1:8])\npredicted_strength3 <- model_results3$net.result\ncor(predicted_strength3, concrete_test$strength)\n\n          [,1]\n[1,] 0.6761314\n\nstrengths <- data.frame(actual = concrete_data$strength[774:1030],pred = predicted_strength3)\nhead(strengths, n = 3)\n\n      actual      pred\n774 37.42476 0.4099593\n775 11.46599 0.2406689\n776 22.43555 0.2818004\n\ncor(strengths$pred, strengths$actual)\n\n[1] 0.6761314"
  },
  {
    "objectID": "slides/lec_week11.html#ejemplo-continuación-11",
    "href": "slides/lec_week11.html#ejemplo-continuación-11",
    "title": "Redes neuronales artificiales",
    "section": "Ejemplo: continuación",
    "text": "Ejemplo: continuación\n\nunnormalize <- function(x) {\nreturn((x * (max(concrete_data$strength)) -\nmin(concrete_data$strength)) + min(concrete_data$strength))\n}\nstrengths$pred_new <- unnormalize(strengths$pred)\nstrengths$error <- strengths$pred_new - strengths$actual\nhead(strengths, n = 3)\n\n      actual      pred pred_new      error\n774 37.42476 0.4099593 33.86232 -3.5624375\n775 11.46599 0.2406689 19.87906  8.4130769\n776 22.43555 0.2818004 23.27650  0.8409468\n\ncor(strengths$pred_new, strengths$actual)\n\n[1] 0.6761314"
  },
  {
    "objectID": "slides/lec_week12.html#convolución",
    "href": "slides/lec_week12.html#convolución",
    "title": "Redes neuronales convolucionales",
    "section": "Convolución",
    "text": "Convolución\nEn su forma general, la convolución es una operación sobre dos funciones con argumentos reales.\nSupongamos que estamos rastreando la ubicación de una nave espacial con un sensor láser. Nuestro sensor láser nos entrega una sola salida \\(x(t)\\), la posición de la nave espacial en el tiempo \\(t\\), en donde \\(x\\) y \\(t\\) son valores reales.\nAhora supongamos que nuestro sensor láser es algo ruidoso. Para obtener una estimación menos ruidosa de la posición de la nave, podríamos promediar muchas mediciones, siendo las mediciones más recientes más relevantes, por lo que sería un promedio ponderado que otorga más peso a las observaciones más recientes."
  },
  {
    "objectID": "slides/lec_week12.html#convolución-continuación",
    "href": "slides/lec_week12.html#convolución-continuación",
    "title": "Redes neuronales convolucionales",
    "section": "Convolución: continuación",
    "text": "Convolución: continuación\nPodemos hacer esto con una función \\(w(a)\\), donde \\(a\\) es la edad de la medición. Si deseamos aplicar la operación de ponderación en cada momento, debemos obtener una nueva función \\(s\\) que entregue una estimación suavizada de la posición de la nave:\n\\[s(t)=\\int x(a)w(t-a)da\\]\nEsta operación es llamada convolución. La operación de convolución se denota típicamente como:\n\\[s(t)=(x * w)(t)\\]"
  },
  {
    "objectID": "slides/lec_week12.html#convolución-continuación-1",
    "href": "slides/lec_week12.html#convolución-continuación-1",
    "title": "Redes neuronales convolucionales",
    "section": "Convolución: continuación",
    "text": "Convolución: continuación\nEn nuestro caso, \\(w\\) necesita ser una función de densidad de probabilidad válida, sino la salida no sería una ponderación. Además, \\(w\\) necesita ser 0 para todos los argumentos negativos, o esta función “mirará en el futuro’’. Estas limitaciones son particulares de nuestro ejemplo.\nEn general, la convolución está definida para cualquier función para la que la integral anterior está bien definida, y puede ser ocupada con otros fines.\nEn este contexto, el primer argumento (\\(x\\)) se le llama input y el segundo argumento (\\(w\\)) se le llama kernel, y a la salida se le llama feature map."
  },
  {
    "objectID": "slides/lec_week12.html#convolución-continuación-2",
    "href": "slides/lec_week12.html#convolución-continuación-2",
    "title": "Redes neuronales convolucionales",
    "section": "Convolución: continuación",
    "text": "Convolución: continuación\nEn nuestro ejemplo, la idea de que el sensor láser entregue medidas en cada instante de tiempo no es realista, pues trabajamos con una discretización del tiempo, usualmente a tiempos regulares. Así, tendremos:\n\\[s(t)=(x*w)(t)=\\sum_{a=-\\infty}^{\\infty}x(a)w(t-a)\\]\nFrecuentemente usamos convoluciones sobre más de un eje en un tiempo especifico. Por ejemplo, si usamos una imagen 2-dimensional \\(I\\) como input, probablemente desearemos usar un kernel \\(K\\) 2-dimensional:\n\\[S(i,j)=(I*K)(i,j)=\\sum_m \\sum_n I(m,n)K(i-m,j-n)\\]\nLa convolución es conmutativa, esto significa que equivalentemente podemos escribir:\n\\[S(i,j)=(K*I)(i,j)=\\sum_m \\sum_n I(i-m,j-n)K(m,n)\\]"
  },
  {
    "objectID": "slides/lec_week12.html#motivación",
    "href": "slides/lec_week12.html#motivación",
    "title": "Redes neuronales convolucionales",
    "section": "Motivación",
    "text": "Motivación\nLa convolución aprovecha tres ideas importantes que pueden ayudar a mejorar el aprendizaje de una máquina:\n\nsparse interactions\nparameter sharing\nequivariant representation\n\n\nAdemás de permitir trabajar con entradas de tamaño variable."
  },
  {
    "objectID": "slides/lec_week12.html#sparse-interaction",
    "href": "slides/lec_week12.html#sparse-interaction",
    "title": "Redes neuronales convolucionales",
    "section": "Sparse interaction",
    "text": "Sparse interaction\nInteracciones escasas o sparse interactions (que también se le refiere como sparse connectivity o sparse weights), viene desde la idea: Las capas de una red neuronal tradicional usan multiplicación de matrices por una matriz de parámetros con un parámetro separado que describe la interacción entre cada unidad de entrada y cada unidad de salida.\nEste implica que cada unidad de salida interactúa con cada unidad de entrada. Las redes convolucionales, en cambio, no necesariamente. Este es logrado utilizando kernels más pequeños que la entrada.\nPor ejemplo, cuando se procesa una imagen, la entrada podría tener millones de pixeles, pero podemos detectar unas pequeñas pero relevantes características, que al interactuar con el kernel ocupan sólo cientos de pixeles. Esto implica que tendremos que guardar menos parámetros, que reduce la memoria requerida del modelo y mejora su eficiencia estadística."
  },
  {
    "objectID": "slides/lec_week12.html#sparse-interaction-continuación",
    "href": "slides/lec_week12.html#sparse-interaction-continuación",
    "title": "Redes neuronales convolucionales",
    "section": "Sparse interaction: continuación",
    "text": "Sparse interaction: continuación\nEn términos más formales, en una red neuronal con \\(y\\in \\mathbb{R}^{n}, x\\in \\mathbb{R}^m\\). Necesitamos realizar la multiplicación matricial \\(y=Wx\\) para calcular las activaciones para cada capa, en donde cada salida interactúa con cada entrada.\nDebido a que las redes convolucionales tienen interacciones más escasas al usar kernels más pequeños, el calculo de la red pasada de necesitar \\(O(m\\times n)\\) a \\(O(k\\times x)\\) operaciones."
  },
  {
    "objectID": "slides/lec_week12.html#sparse-interaction-continuación-1",
    "href": "slides/lec_week12.html#sparse-interaction-continuación-1",
    "title": "Redes neuronales convolucionales",
    "section": "Sparse interaction: continuación",
    "text": "Sparse interaction: continuación"
  },
  {
    "objectID": "slides/lec_week12.html#sparse-interaction-continuación-2",
    "href": "slides/lec_week12.html#sparse-interaction-continuación-2",
    "title": "Redes neuronales convolucionales",
    "section": "Sparse interaction: continuación",
    "text": "Sparse interaction: continuación"
  },
  {
    "objectID": "slides/lec_week12.html#parameter-sharing-y-equivariance-representation",
    "href": "slides/lec_week12.html#parameter-sharing-y-equivariance-representation",
    "title": "Redes neuronales convolucionales",
    "section": "Parameter sharing y equivariance representation",
    "text": "Parameter sharing y equivariance representation\nEsta característica hace referencia a usar los mismos parámetros para más de una función de activación, reduciendo así, el número de parámetros a optimizar y mejorando la eficiencia estadística.\nConfigurando particularmente los parámetros, podemos obtener la propiedad de representación de equivalencia, que refiere a que si las entradas cambian, las salidas cambian en la misma manera."
  },
  {
    "objectID": "slides/lec_week12.html#ejemplo",
    "href": "slides/lec_week12.html#ejemplo",
    "title": "Redes neuronales convolucionales",
    "section": "Ejemplo",
    "text": "Ejemplo\nCargamos las librerías de keras y tensorflow\n\nlibrary(keras)\nlibrary(tensorflow)\n#tensorflow::install_tensorflow()\n#tensorflow::tf_config()"
  },
  {
    "objectID": "slides/lec_week12.html#ejemplo-continuación",
    "href": "slides/lec_week12.html#ejemplo-continuación",
    "title": "Redes neuronales convolucionales",
    "section": "Ejemplo: continuación",
    "text": "Ejemplo: continuación\n60000 imágenes de entrenamiento y 10000 de prueba de números escritos a mano.\n\nmnist <- dataset_mnist()\nx_train <- mnist$train$x\ny_train <- mnist$train$y\nx_test <- mnist$test$x\ny_test <- mnist$test$y\ndim(x_train)\n\n[1] 60000    28    28"
  },
  {
    "objectID": "slides/lec_week12.html#ejemplo-continuación-1",
    "href": "slides/lec_week12.html#ejemplo-continuación-1",
    "title": "Redes neuronales convolucionales",
    "section": "Ejemplo: continuación",
    "text": "Ejemplo: continuación"
  },
  {
    "objectID": "slides/lec_week12.html#ejemplo-continuación-2",
    "href": "slides/lec_week12.html#ejemplo-continuación-2",
    "title": "Redes neuronales convolucionales",
    "section": "Ejemplo: continuación",
    "text": "Ejemplo: continuación\nArreglamos la forma y reescalamos.\n\n# reshape\nx_train <- array_reshape(x_train, c(nrow(x_train), 784))\nx_test <- array_reshape(x_test, c(nrow(x_test), 784))\n\n# rescale\nx_train <- x_train / 255\nx_test <- x_test / 255\n\n# categorización de la variable respuesta\n\ny_train <- to_categorical(y_train, 10)\ny_test <- to_categorical(y_test, 10)"
  },
  {
    "objectID": "slides/lec_week12.html#ejemplo-continuación-3",
    "href": "slides/lec_week12.html#ejemplo-continuación-3",
    "title": "Redes neuronales convolucionales",
    "section": "Ejemplo: continuación",
    "text": "Ejemplo: continuación\nDefinimos el modelo\n\nmodel <- keras_model_sequential() \nmodel %>% \n  layer_dense(units = 256, activation = 'relu', input_shape = c(784)) %>% \n  layer_dropout(rate = 0.4) %>% \n  layer_dense(units = 128, activation = 'relu') %>%\n  layer_dropout(rate = 0.3) %>%\n  layer_dense(units = 10, activation = 'softmax')\nsummary(model)\n\nModel: \"sequential\"\n________________________________________________________________________________\n Layer (type)                       Output Shape                    Param #     \n================================================================================\n dense_2 (Dense)                    (None, 256)                     200960      \n dropout_1 (Dropout)                (None, 256)                     0           \n dense_1 (Dense)                    (None, 128)                     32896       \n dropout (Dropout)                  (None, 128)                     0           \n dense (Dense)                      (None, 10)                      1290        \n================================================================================\nTotal params: 235,146\nTrainable params: 235,146\nNon-trainable params: 0\n________________________________________________________________________________"
  },
  {
    "objectID": "slides/lec_week12.html#ejemplo-continuación-4",
    "href": "slides/lec_week12.html#ejemplo-continuación-4",
    "title": "Redes neuronales convolucionales",
    "section": "Ejemplo: continuación",
    "text": "Ejemplo: continuación\nCompilamos y entrenamos el modelo:\n\nmodel %>% compile(\n  loss = 'categorical_crossentropy',\n  optimizer = optimizer_rmsprop(),\n  metrics = c('accuracy')\n)\n\nhistory <- model %>% fit(\n  x_train, y_train, \n  epochs = 30, batch_size = 128, \n  validation_split = 0.2\n)\nhistory\n\n\nFinal epoch (plot to see history):\n        loss: 0.05107\n    accuracy: 0.9859\n    val_loss: 0.1283\nval_accuracy: 0.978"
  },
  {
    "objectID": "slides/lec_week12.html#ejemplo-continuación-5",
    "href": "slides/lec_week12.html#ejemplo-continuación-5",
    "title": "Redes neuronales convolucionales",
    "section": "Ejemplo: continuación",
    "text": "Ejemplo: continuación\n\nplot(history)"
  },
  {
    "objectID": "slides/lec_week12.html#ejemplo-continuación-6",
    "href": "slides/lec_week12.html#ejemplo-continuación-6",
    "title": "Redes neuronales convolucionales",
    "section": "Ejemplo: continuación",
    "text": "Ejemplo: continuación\nEvaluamos el modelo en el conjunto de prueba:\n\nmodel %>% evaluate(x_test, y_test)\n\n    loss accuracy \n0.101623 0.981200 \n\n\nGeneramos predicciones:\n\npred <- model %>% predict(x_test) %>% k_argmax()"
  },
  {
    "objectID": "slides/lec_week12.html#ejemplo-continuación-7",
    "href": "slides/lec_week12.html#ejemplo-continuación-7",
    "title": "Redes neuronales convolucionales",
    "section": "Ejemplo: continuación",
    "text": "Ejemplo: continuación"
  },
  {
    "objectID": "slides/lec_week12.html#ejemplo-continuación-8",
    "href": "slides/lec_week12.html#ejemplo-continuación-8",
    "title": "Redes neuronales convolucionales",
    "section": "Ejemplo: continuación",
    "text": "Ejemplo: continuación"
  },
  {
    "objectID": "slides/lec_week12.html#ejemplo-2",
    "href": "slides/lec_week12.html#ejemplo-2",
    "title": "Redes neuronales convolucionales",
    "section": "Ejemplo 2",
    "text": "Ejemplo 2\n50000 imágenes de 32x32 pixeles a color clasificado en 10 categorías.\n\ncifar <- dataset_cifar10()\nclass_names <- c('airplane', 'automobile', 'bird', 'cat', 'deer',\n               'dog', 'frog', 'horse', 'ship', 'truck')\n\nindex <- 1:30"
  },
  {
    "objectID": "slides/lec_week12.html#ejemplo-2-continuación",
    "href": "slides/lec_week12.html#ejemplo-2-continuación",
    "title": "Redes neuronales convolucionales",
    "section": "Ejemplo 2: continuación",
    "text": "Ejemplo 2: continuación"
  },
  {
    "objectID": "slides/lec_week12.html#ejemplo-2-continuación-1",
    "href": "slides/lec_week12.html#ejemplo-2-continuación-1",
    "title": "Redes neuronales convolucionales",
    "section": "Ejemplo 2: continuación",
    "text": "Ejemplo 2: continuación\nDefinimos el modelo\n\nmodel <- keras_model_sequential() %>% \n  layer_conv_2d(filters = 32, kernel_size = c(3,3), activation = \"relu\", \n                input_shape = c(32,32,3)) %>% \n  layer_max_pooling_2d(pool_size = c(2,2)) %>% \n  layer_conv_2d(filters = 64, kernel_size = c(3,3), activation = \"relu\") %>% \n  layer_max_pooling_2d(pool_size = c(2,2)) %>% \n  layer_conv_2d(filters = 64, kernel_size = c(3,3), activation = \"relu\")\n\nsummary(model)\n\nModel: \"sequential_1\"\n________________________________________________________________________________\n Layer (type)                       Output Shape                    Param #     \n================================================================================\n conv2d_2 (Conv2D)                  (None, 30, 30, 32)              896         \n max_pooling2d_1 (MaxPooling2D)     (None, 15, 15, 32)              0           \n conv2d_1 (Conv2D)                  (None, 13, 13, 64)              18496       \n max_pooling2d (MaxPooling2D)       (None, 6, 6, 64)                0           \n conv2d (Conv2D)                    (None, 4, 4, 64)                36928       \n================================================================================\nTotal params: 56,320\nTrainable params: 56,320\nNon-trainable params: 0\n________________________________________________________________________________"
  },
  {
    "objectID": "slides/lec_week12.html#ejemplo-2-continuación-2",
    "href": "slides/lec_week12.html#ejemplo-2-continuación-2",
    "title": "Redes neuronales convolucionales",
    "section": "Ejemplo 2: continuación",
    "text": "Ejemplo 2: continuación\n\nmodel %>% \n  layer_flatten() %>% \n  layer_dense(units = 64, activation = \"relu\") %>% \n  layer_dense(units = 10, activation = \"softmax\")\nsummary(model)\n\nModel: \"sequential_1\"\n________________________________________________________________________________\n Layer (type)                       Output Shape                    Param #     \n================================================================================\n conv2d_2 (Conv2D)                  (None, 30, 30, 32)              896         \n max_pooling2d_1 (MaxPooling2D)     (None, 15, 15, 32)              0           \n conv2d_1 (Conv2D)                  (None, 13, 13, 64)              18496       \n max_pooling2d (MaxPooling2D)       (None, 6, 6, 64)                0           \n conv2d (Conv2D)                    (None, 4, 4, 64)                36928       \n flatten (Flatten)                  (None, 1024)                    0           \n dense_4 (Dense)                    (None, 64)                      65600       \n dense_3 (Dense)                    (None, 10)                      650         \n================================================================================\nTotal params: 122,570\nTrainable params: 122,570\nNon-trainable params: 0\n________________________________________________________________________________"
  },
  {
    "objectID": "slides/lec_week12.html#ejemplo-2-continuación-3",
    "href": "slides/lec_week12.html#ejemplo-2-continuación-3",
    "title": "Redes neuronales convolucionales",
    "section": "Ejemplo 2: continuación",
    "text": "Ejemplo 2: continuación\nCompilamos y entrenamos el modelo:\n\nmodel %>% compile(\n  optimizer = \"adam\",\n  loss = \"sparse_categorical_crossentropy\",\n  metrics = \"accuracy\"\n)\n\nhistory <- model %>% \n  fit(\n    x = cifar$train$x, y = cifar$train$y,\n    epochs = 10,\n    validation_data = unname(cifar$test),\n    verbose = 2\n  )\nhistory\n\n\nFinal epoch (plot to see history):\n        loss: 0.741\n    accuracy: 0.743\n    val_loss: 1.117\nval_accuracy: 0.6435"
  },
  {
    "objectID": "slides/lec_week12.html#ejemplo-2-continuación-4",
    "href": "slides/lec_week12.html#ejemplo-2-continuación-4",
    "title": "Redes neuronales convolucionales",
    "section": "Ejemplo 2: continuación",
    "text": "Ejemplo 2: continuación\n\nplot(history)"
  },
  {
    "objectID": "slides/lec_week12.html#ejemplo-2-continuación-5",
    "href": "slides/lec_week12.html#ejemplo-2-continuación-5",
    "title": "Redes neuronales convolucionales",
    "section": "Ejemplo 2: continuación",
    "text": "Ejemplo 2: continuación\n\nevaluate(model, cifar$test$x, cifar$test$y, verbose = 0)\n\n    loss accuracy \n1.116902 0.643500"
  }
]
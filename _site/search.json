[
  {
    "objectID": "pages/week2.html",
    "href": "pages/week2.html",
    "title": "Semana 2",
    "section": "",
    "text": "Instalar R y Python.\nSe recomienda también instalar Rstudio y Spyder\nRepasar materia MAT042"
  },
  {
    "objectID": "pages/week2.html#presentación",
    "href": "pages/week2.html#presentación",
    "title": "Semana 2",
    "section": "Presentación",
    "text": "Presentación\nVer presentación en pantalla completa"
  },
  {
    "objectID": "pages/week2.html#material-adicional",
    "href": "pages/week2.html#material-adicional",
    "title": "Semana 2",
    "section": "Material adicional",
    "text": "Material adicional"
  },
  {
    "objectID": "slides/lec_week2.html#escuelas-de-probabilidad",
    "href": "slides/lec_week2.html#escuelas-de-probabilidad",
    "title": "Conceptos Básicos",
    "section": "Escuelas de Probabilidad",
    "text": "Escuelas de Probabilidad\n\nEnfoque clásico\nEnfoque frecuentista\nEnfoque bayesiano"
  },
  {
    "objectID": "slides/lec_week2.html#enfoque-clásico",
    "href": "slides/lec_week2.html#enfoque-clásico",
    "title": "Conceptos Básicos",
    "section": "Enfoque clásico",
    "text": "Enfoque clásico\nEste enfoque también llamado enfoque apriori tiene por característica principal la asignación igualitaria de una medida de ocurrencia para un resultado de un experimento aleatorio (experimento equiprobable).\n\nEsta asignación de probabilidad se determina antes de observar los resultados experimentales.\n\n\n\n¿Algún ejemplo?"
  },
  {
    "objectID": "slides/lec_week2.html#enfoque-frecuentista",
    "href": "slides/lec_week2.html#enfoque-frecuentista",
    "title": "Conceptos Básicos",
    "section": "Enfoque frecuentista",
    "text": "Enfoque frecuentista\nEste enfoque también llamado enfoque empírico, determina la medida de ocurrencia con base en la proporción de veces que ocurre un resultado favorable en un determinado número de observaciones o experimentos. Este enfoque no asigna probabilidades a priori a los posibles resultados de un experimento aleatorio.\n\n\n¿Algún ejemplo?"
  },
  {
    "objectID": "slides/lec_week2.html#enfoque-bayesiano",
    "href": "slides/lec_week2.html#enfoque-bayesiano",
    "title": "Conceptos Básicos",
    "section": "Enfoque bayesiano",
    "text": "Enfoque bayesiano\nEste enfoque también llamado enfoque subjetivo, determina la medida de ocurrencia en base a una expectativa razonable basado en el conocimiento del investigador.\nEl enfoque bayesiano es particularmente útil cuando se tiene poca información del experimento, y este puede ser realizado para actualizador mis probabilidades, esto debido a que cada realización del experimento aleatorio me otorgará información adicional para determinar correctamente mis probabilidades."
  },
  {
    "objectID": "slides/lec_week2.html#conceptos-fundamentales",
    "href": "slides/lec_week2.html#conceptos-fundamentales",
    "title": "Conceptos Básicos",
    "section": "Conceptos fundamentales",
    "text": "Conceptos fundamentales\n\nEspacio muestral: Se define como el conjunto de todos los posibles resultados del experimento, lo anotamos por \\(\\Omega\\).\nSuceso o evento: Es cualquier subconjunto de \\(\\Omega\\), usualmente lo anotamos con letras mayúsculas. \\((A,B,C,\\dots)\\).\nEspacio de sucesos: Es el conjunto de todos los subconjuntos de \\(\\Omega\\). Lo anotamos por \\(2^{\\Omega}\\).\n\\(\\sigma\\)-álgebra: Es una familia de subconjuntos del espacio de sucesos, \\(\\Sigma \\subset 2^{\\Omega}\\), y que cumplen con ciertas propiedades."
  },
  {
    "objectID": "slides/lec_week2.html#clasificación-del-espacio-muestral",
    "href": "slides/lec_week2.html#clasificación-del-espacio-muestral",
    "title": "Conceptos Básicos",
    "section": "Clasificación del espacio muestral",
    "text": "Clasificación del espacio muestral\n\nDiscreto\n\nNumerable: Finito o Infinito.\n\nContinuo\n\nNo numerable: Acotado o No acotado."
  },
  {
    "objectID": "slides/lec_week2.html#definición-formal-de-probabilidad",
    "href": "slides/lec_week2.html#definición-formal-de-probabilidad",
    "title": "Conceptos Básicos",
    "section": "Definición formal de probabilidad",
    "text": "Definición formal de probabilidad\nEl par \\((\\Omega,\\Sigma)\\) se dice espacio medible, y la función \\(\\mathbb{P}:\\Sigma \\rightarrow \\mathbb{R}^{+}\\), es una medida de probabilidad si satisface:\n\n\\(0\\leq \\mathbb{P}[A] \\leq 1, \\forall A \\in \\Sigma\\)\n\\(\\mathbb{P}[\\Omega]=1\\)\nDados \\(\\displaystyle A_1,A_2,\\dots \\in \\Sigma \\Rightarrow \\mathbb{P}\\left[ \\bigcup_{i=1}^{n} A_n \\right] = \\sum_{i=1}^{n} \\mathbb{P}[A_i], \\hspace{5pt} \\forall i\\)"
  },
  {
    "objectID": "slides/lec_week2.html#algunas-propiedades",
    "href": "slides/lec_week2.html#algunas-propiedades",
    "title": "Conceptos Básicos",
    "section": "Algunas propiedades",
    "text": "Algunas propiedades\n\n\\(\\mathbb{P}[A]+\\mathbb{P}[A^c]=\\mathbb{P}[\\Omega]\\)\n\\(\\mathbb{P}[\\phi]=1-\\mathbb{P}[\\phi^c]=1-\\mathbb{P}[\\Omega]=0\\)\n\\(\\mathbb{P}[A \\cup B]=\\mathbb{P}[A]+\\mathbb{P}[B] - \\mathbb{P}[A\\cap B]\\) . Si este último término \\((\\mathbb{P}[A\\cap B])\\) es cero, se dice que \\(A\\) y \\(B\\) son eventos mutuamente excluyentes.\n\\(\\mathbb{P}[A-B]=\\mathbb{P}[A\\cap B^c]\\)\n\\(\\mathbb{P}[A \\cap B]=\\mathbb{P}[A]\\mathbb{P}[B]\\). Si \\(A\\) y \\(B\\) son independientes."
  },
  {
    "objectID": "slides/lec_week2.html#definición-básica",
    "href": "slides/lec_week2.html#definición-básica",
    "title": "Conceptos Básicos",
    "section": "Definición Básica",
    "text": "Definición Básica\nUna Variable aleatoria, es una función que permite trabajar cualquier espacio muestral de manera cuantitativa. Se dice que \\(X\\) es una variable aleatoria si es una función que toma los elementos de \\(\\Omega\\) y los transforma en puntos sobre la recta de los reales. Esto es:\n\\[\\begin{align*}\n  X: \\quad &\\Omega \\longrightarrow \\mathbb{R}\\\\\n           &\\omega \\longrightarrow X(\\omega)\n\\end{align*}\\]\n\nEl conjunto de todas las posibles realizaciones es llamado el soporte y lo denotamos por \\(R_X\\)."
  },
  {
    "objectID": "slides/lec_week2.html#tipos-de-variables-aleatorias",
    "href": "slides/lec_week2.html#tipos-de-variables-aleatorias",
    "title": "Conceptos Básicos",
    "section": "Tipos de variables aleatorias",
    "text": "Tipos de variables aleatorias\nSe dice que \\(X\\) es una Variable Aleatoria si es una función que toma valores en probabilidad, es decir, no se puede predecir con certeza sus resultados.\nUna variable aleatoria es siempre cuantitativa y se puede clasificar en los siguientes grupos:\n\\[X(\\omega) \\begin{cases}\n\\text{Discreto}\n\\begin{cases}\n\\text{Finito}\\\\\n\\text{Infinito}\n\\end{cases}\\\\\n\\text{Continuo}\n\\begin{cases}\n\\text{Acotados}\\\\\n\\text{No Acotados}\n\\end{cases}\n\\end{cases}\\]"
  },
  {
    "objectID": "slides/lec_week2.html#variables-aleatorias-discretas",
    "href": "slides/lec_week2.html#variables-aleatorias-discretas",
    "title": "Conceptos Básicos",
    "section": "Variables aleatorias discretas",
    "text": "Variables aleatorias discretas\nUna variable aleatoria \\(X\\) es llamada discreta si:\n\nSu soporte \\(R_X\\) es un conjunto numerable.\nExiste una función \\(p_X:\\mathbb{R}\\rightarrow [0,1]\\), llamada la función de masa de probabilidad de \\(X\\), tal que, para cualquier \\(x\\in \\mathbb{R}\\):\n\n\n\\[p_X(x)\\begin{cases} \\mathbb{P}(X=x) \\quad &\\text{si } x\\in R_X\\\\ 0 \\quad &\\text{si } x\\notin R_X\\end{cases}\\]\n\n\nEsta función tiene dos características principales:\n\nno-negatividad: \\(p_X(x)\\geq 0\\) para cualquier \\(x\\in \\mathbb{R}\\).\nSuma sobre su soporte es 1: \\(\\sum_{x\\in R_X}p_X(x)=1\\)"
  },
  {
    "objectID": "slides/lec_week2.html#variables-aleatorias-continuas",
    "href": "slides/lec_week2.html#variables-aleatorias-continuas",
    "title": "Conceptos Básicos",
    "section": "Variables aleatorias continuas",
    "text": "Variables aleatorias continuas\nUna variable aleatoria \\(X\\) es llamada continua si:\n\nSu soporte \\(R_X\\) es un conjunto no-numerable.\nExiste una función \\(f_X:\\mathbb{R}\\rightarrow [0,1]\\), llamada función de densidad de probabilidad de \\(X\\), tal que, para cualquier intervalo \\([a,b]\\subseteq \\mathbb{R}\\):\n\n\n\\[\\mathbb{P}(X\\in [a,b])=\\int_{a}^{b}f_X(x)dx\\]\n\n\nEsta función tiene dos características principales:\n\nno-negatividad: \\(f_X(x)\\geq 0\\) para cualquier \\(x\\in \\mathbb{R}\\).\nIntegral sobre \\(\\mathbb{R}\\) es 1: \\(\\int_{-\\infty}^{\\infty} f_X(x)dx=1\\)."
  },
  {
    "objectID": "slides/lec_week2.html#función-de-distribución",
    "href": "slides/lec_week2.html#función-de-distribución",
    "title": "Conceptos Básicos",
    "section": "Función de distribución",
    "text": "Función de distribución\nLas variables aleatorias son usualmente caracterizadas en términos de sus funciones de distribución.\n\nSea \\(X\\) una variable aleatoria. La función de distribución de \\(X\\) es una función \\(F_X:\\mathbb{R}\\rightarrow [0,1]\\) tal que:\n\\[F_X(x)=\\mathbb{P}(X\\leq x), \\forall x\\in \\mathbb{R}\\]\n\n\nSi conocemos la función de distribución de una variable aleatoria \\(X\\), entonces podemos fácilmente calcular la probabilidad que \\(X\\) pertenezca a un intervalo \\((a,b] \\subseteq \\mathbb{R}\\) como:\n\\[\\mathbb{P}(a<X<b)=F_X(b)-F_X(a)\\]"
  },
  {
    "objectID": "slides/lec_week2.html#valores-esperados",
    "href": "slides/lec_week2.html#valores-esperados",
    "title": "Conceptos Básicos",
    "section": "Valores esperados",
    "text": "Valores esperados\nSea \\(X\\) una variable aleatoria, entonces se define el valor esperado de una función real \\(g(X)\\), como:\n\\[\\mathbb{E}[g(X)]= \\begin{cases} \\sum_{x\\in \\mathbb{R}} g(X)P(X=x)\\\\ \\int_{x\\in \\mathbb{R}} g(X)f(x)dx \\end{cases}\\]\nSi \\(g(X)=X\\), diremos que el valor esperado o esperanza matemática de \\(X\\) es:\n\\[\\mathbb{E}(X)=\\begin{cases}\\sum_{x\\in \\mathbb{R}} x P(X=x)\\\\ \\int_{x\\in \\mathbb{R}} x f(x)dx \\end{cases}\\]\nPara variables de tipo discreta y continua, respectivamente."
  },
  {
    "objectID": "slides/lec_week2.html#propiedades-de-los-valores-esperados",
    "href": "slides/lec_week2.html#propiedades-de-los-valores-esperados",
    "title": "Conceptos Básicos",
    "section": "Propiedades de los valores esperados",
    "text": "Propiedades de los valores esperados\nSean \\(a\\) y \\(b\\) constantes, \\(X\\) una variable aleatoria entonces se cumple que:\n\n\\(\\mathbb{E}(a)=a\\)\n\\(\\mathbb{E}(X)=\\mu=\\) constante\n\\(\\mathbb{E}(aX)=a\\mathbb{E}(X)\\)\n\\(\\mathbb{E}(aX+b)=\\mathbb{E}(aX)+\\mathbb{E}(b)=a\\mathbb{E}(X)+b\\)"
  },
  {
    "objectID": "slides/lec_week2.html#varianza",
    "href": "slides/lec_week2.html#varianza",
    "title": "Conceptos Básicos",
    "section": "Varianza",
    "text": "Varianza\nSea \\(X\\) una variable aleatoria, se define el la varianza de \\(X\\) como:\n\\[\\mathbb{E}[(X-\\mathbb{E}(X))^2]=V(X)=\\begin{cases}\\sum_{x\\in\\mathbb{R}} (X-\\mathbb{E}(X))^2P(X=x)\\\\ \\int_{x\\in\\mathbb{R}}(X-\\mathbb{E}(X))^2f_{X}(x)dx\\end{cases}\\]\nPara variables de tipo discreta y continua, respectivamente."
  },
  {
    "objectID": "slides/lec_week2.html#propiedades-de-la-varianza",
    "href": "slides/lec_week2.html#propiedades-de-la-varianza",
    "title": "Conceptos Básicos",
    "section": "Propiedades de la varianza",
    "text": "Propiedades de la varianza\nSea \\(a\\) y \\(b\\) constantes, \\(X\\) una variable aleatoria, entonces se cumple:\n\n\\(\\mathbb{V}(a)=0\\)\n\\(\\mathbb{V}(X)=\\sigma^2=\\) constante\n\\(\\mathbb{V}(aX)=a^2 \\mathbb{V}(X)\\)\n\\(\\mathbb{V}(aX+b)=\\mathbb{V}(aX)+\\mathbb{V}(b)=a^2\\mathbb{V}(X)+0=a^2\\mathbb{V}(X)\\)\n\\(\\mathbb{V}(X)=\\mathbb{E}(X^2)-(\\mathbb{E}(X))^2\\)"
  },
  {
    "objectID": "slides/lec_week2.html#distribución-binomial",
    "href": "slides/lec_week2.html#distribución-binomial",
    "title": "Conceptos Básicos",
    "section": "Distribución binomial",
    "text": "Distribución binomial\nSea \\(X\\) una variable aleatoria que representa el número de éxitos en \\(n\\) ensayos y \\(p\\) la probabilidad de éxito con cualquiera de éstos. Se dice entonces que \\(X\\) tiene una distribución binomial con función de probabilidad:\n\\[\\mathbb{P}(X=k)= {{n}\\choose{k}}p^k(1-p)^{n-k} \\hspace{20pt} k=1,2,\\cdots,n\\]\nEn donde \\({{n}\\choose{k}}\\) es el coeficiente binomial, esto es:\n\\[{{n}\\choose{k}}=\\dfrac{n!}{k!(n-k)!}\\]\nSi \\(n=1\\) diremos que \\(X\\) sigue una distribución Bernoulli."
  },
  {
    "objectID": "slides/lec_week2.html#propiedades-de-la-distribución-binomial",
    "href": "slides/lec_week2.html#propiedades-de-la-distribución-binomial",
    "title": "Conceptos Básicos",
    "section": "Propiedades de la distribución binomial",
    "text": "Propiedades de la distribución binomial\nSi \\(X\\) tiene una distribución binomial, entonces se cumple que:\n\n\\(\\mathbb{E}[X]=np\\)\n\\(\\mathbb{V}[X]=np(1-p)\\)\n\n\nEs claro ver que si \\(X\\) tiene una distribución bernoulli, entonces:\n\n\\(\\mathbb{E}[X]=p\\)\n\\(\\mathbb{V}[X]=p(1-p)\\)"
  },
  {
    "objectID": "slides/lec_week2.html#distribución-binomial-en-r-y-python",
    "href": "slides/lec_week2.html#distribución-binomial-en-r-y-python",
    "title": "Conceptos Básicos",
    "section": "Distribución binomial en R y Python",
    "text": "Distribución binomial en R y Python\n\n\n\nIND 163 - Semana 2"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "IND163C - Análisis de Negocios (Business Analytics)",
    "section": "",
    "text": "En este curso se estudian los fundamentos del análisis de información a través del desarrollo de aplicaciones Cloud (nube) mediante lenguajes de programación, vinculando áreas técnicas especializadas en Analytics con otras áreas de la organización, agregando valor al proceso de diagnóstico y toma de decisiones en tiempo real.\nA lo largo del curso se evalúan el uso de Analytics midiendo el impacto de esta herramienta a nivel individual y social, decidiendo de forma ética y socialmente responsable respecto del uso de la información"
  },
  {
    "objectID": "index.html#softwares",
    "href": "index.html#softwares",
    "title": "IND163C - Análisis de Negocios (Business Analytics)",
    "section": "Softwares",
    "text": "Softwares\nPara la mayoría de las aplicaciones utilizaremos R y Python, por lo que se sugiere utilizar un IDE como RStudio o Spyder.\nPara la entrega de informes y talleres que requieran uso de programación, se recomienda el uso de Rmarkdown, Jupyter Notebook o \\(\\LaTeX\\) para la confección de documentos a entregar."
  },
  {
    "objectID": "index.html#bibliografía-principal",
    "href": "index.html#bibliografía-principal",
    "title": "IND163C - Análisis de Negocios (Business Analytics)",
    "section": "Bibliografía principal",
    "text": "Bibliografía principal\nLa bibliografía principal del curso es:\n\n\n\n\n\n\nData Science For Business: What You Need to Know About Data Mining & Data-Analytic Thinking. Provost F., Fawcett, T.\n\n\n\n\n\n\n\nThink like a Data Scientist: Tackle the data science process step-by-step. Godsey B.\n\n\n\n\n\n\n\nNumsense! Data Science for the Layman: No Math Added. Ng, A, Soo K."
  },
  {
    "objectID": "index.html#bibliografía-secundaria-y-de-profundización",
    "href": "index.html#bibliografía-secundaria-y-de-profundización",
    "title": "IND163C - Análisis de Negocios (Business Analytics)",
    "section": "Bibliografía secundaria y de profundización",
    "text": "Bibliografía secundaria y de profundización\nLa bibliografía secundaria y de profundización de las distintas temáticas a estudiar del curso es:\n\n\n\n\n\n\nMachine Learning with R Expert techniques for predictive modeling. Lantz, Brett.\n\n\n\n\n\n\n\nAn Introduction to Statistical Learning with Applications in R. James, Gareth, Witten, Daniela, Hastie, Trevor, Tibshirani Robert.\n\n\n\n\n\n\n\nHands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems. Géron, Aurélien."
  },
  {
    "objectID": "slides/lec_week2.html#distribución-binomial-en-r",
    "href": "slides/lec_week2.html#distribución-binomial-en-r",
    "title": "Conceptos Básicos",
    "section": "Distribución binomial en R",
    "text": "Distribución binomial en R\n\n\n\n\nCódigoSalidas\n\n\n\nset.seed(163)\ndbinom(x = 2, size = 10, prob = 0.3)\nmean(rbinom(n = 10000, size = 10, prob = 0.3) == 2)\npbinom(q = 5, size = 10, p = 0.3, lower.tail = TRUE)\nmean(rbinom(n = 10000, size = 10, prob = 0.3) <= 5)\npbinom(q = 4, size = 10, p = 0.3, lower.tail  = FALSE)\nmean(rbinom(n = 10000, size = 10, prob = 0.3) >= 5)\n\n\n\n\nset.seed(163)\ndbinom(x = 2, size = 10, prob = 0.3)\n\n[1] 0.2334744\n\nmean(rbinom(n = 10000, size = 10, prob = 0.3) == 2)\n\n[1] 0.2417\n\npbinom(q = 5, size = 10, p = 0.3, lower.tail = TRUE)\n\n[1] 0.952651\n\nmean(rbinom(n = 10000, size = 10, prob = 0.3) <= 5)\n\n[1] 0.9529\n\npbinom(q = 4, size = 10, p = 0.3, lower.tail  = FALSE)\n\n[1] 0.1502683\n\nmean(rbinom(n = 10000, size = 10, prob = 0.3) >= 5)\n\n[1] 0.1497"
  },
  {
    "objectID": "slides/lec_week2.html#distribución-binomial-en-python",
    "href": "slides/lec_week2.html#distribución-binomial-en-python",
    "title": "Conceptos Básicos",
    "section": "Distribución binomial en Python",
    "text": "Distribución binomial en Python\n\nCódigoSalidas\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import binom\n\nnp.random.seed(163)\nbinom.pmf(2, n=10, p=0.3)\nsum(np.random.binomial(10, 0.3, 10000) == 2)/10000\nbinom.cdf(5, n=10, p=0.3)\nsum(np.random.binomial(10, 0.3, 10000) <= 5)/10000\n1-binom.cdf(4, n=10, p=0.3)\nsum(np.random.binomial(10, 0.3, 10000) >= 5)/10000\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import binom\n\nnp.random.seed(163)\nbinom.pmf(2, n=10, p=0.3)\n\n0.2334744405000001\n\nsum(np.random.binomial(10, 0.3, 10000) == 2)/10000\n\n0.2332\n\nbinom.cdf(5, n=10, p=0.3)\n\n0.9526510126000001\n\nsum(np.random.binomial(10, 0.3, 10000) <= 5)/10000\n\n0.9517\n\n1-binom.cdf(4, n=10, p=0.3)\n\n0.15026833259999994\n\nsum(np.random.binomial(10, 0.3, 10000) >= 5)/10000\n\n0.1478"
  },
  {
    "objectID": "slides/lec_week2.html#distribución-de-poisson",
    "href": "slides/lec_week2.html#distribución-de-poisson",
    "title": "Conceptos Básicos",
    "section": "Distribución de Poisson",
    "text": "Distribución de Poisson\nSea \\(X\\) una variable aleatoria que representa el número de eventos aleatorios independientes que ocurren a una rapidez constante sobre el tiempo o el espacio. Se dice entonces que la variable aleatoria \\(X\\) tiene una distribución de Poisson con función de probabilidad:\n\\[\\mathbb{P}(X=k)=\\dfrac{e^{-\\lambda}\\lambda^k}{k!} \\hspace{20pt} k=0,1,\\cdots,n,\\cdots\\]\nEn donde \\(\\lambda>0\\) representa el número promedio de ocurrencias del evento aleatorio por unidad de tiempo. Además, si \\(X\\) sigue una distribución de Poisson se cumple que:\n\n\\(\\mathbb{E}[X]=\\lambda\\)\n\\(\\mathbb{V}[X]=\\lambda\\)"
  },
  {
    "objectID": "slides/lec_week2.html#distribución-de-poisson-en-r",
    "href": "slides/lec_week2.html#distribución-de-poisson-en-r",
    "title": "Conceptos Básicos",
    "section": "Distribución de Poisson en R",
    "text": "Distribución de Poisson en R\n\nCódigoSalidas\n\n\n\nset.seed(163)\ndpois(x = 7, 5)\nmean(rpois(n = 10000, 5) == 7)\nppois(q = 5, 5, lower.tail = TRUE)\nmean(rpois(n = 10000, 5) <= 5)\nppois(q = 4, 5, lower.tail  = FALSE)\nmean(rpois(n = 10000,5) >= 5)\n\n\n\n\nset.seed(163)\ndpois(x = 7, 5)\n\n[1] 0.1044449\n\nmean(rpois(n = 10000, 5) == 7)\n\n[1] 0.1107\n\nppois(q = 5, 5, lower.tail = TRUE)\n\n[1] 0.6159607\n\nmean(rpois(n = 10000, 5) <= 5)\n\n[1] 0.6109\n\nppois(q = 4, 5, lower.tail  = FALSE)\n\n[1] 0.5595067\n\nmean(rpois(n = 10000,5) >= 5)\n\n[1] 0.5542"
  },
  {
    "objectID": "slides/lec_week2.html#distribución-de-poisson-en-python",
    "href": "slides/lec_week2.html#distribución-de-poisson-en-python",
    "title": "Conceptos Básicos",
    "section": "Distribución de Poisson en Python",
    "text": "Distribución de Poisson en Python\n\nCódigoSalidas\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import poisson\n\nnp.random.seed(163)\npoisson.pmf(2, n=10, p=0.3)\nsum(np.random.binomial(10, 0.3, 10000) == 2)/10000\nbinom.cdf(5, n=10, p=0.3)\nsum(np.random.binomial(10, 0.3, 10000) <= 5)/10000\n1-binom.cdf(4, n=10, p=0.3)\nsum(np.random.binomial(10, 0.3, 10000) >= 5)/10000\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import poisson\n\nnp.random.seed(163)\npoisson.pmf(7, 5)\n\n0.10444486295705395\n\nsum(np.random.poisson(5, 10000) == 7)/10000\n\n0.1024\n\npoisson.cdf(7, 5)\n\n0.8666283259299925\n\nsum(np.random.poisson(5, 10000) <= 7)/10000\n\n0.8662\n\n1-poisson.cdf(6, 5)\n\n0.2378165370270613\n\nsum(np.random.poisson(5, 10000) >= 7)/10000\n\n0.2369\n\n\n\n\n\n\n\n\nIND 163 - Semana 2"
  }
]